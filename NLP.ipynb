{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduction to NLP Fundamentals in TensorFlow\n",
    "\n",
    "# NLP has the goal of deriving information out of natural language (could be seqeuences text or speech)\n",
    "\n",
    "# Another common term for NLP problems is sequence to sequence problems (seq2seq).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX 1050 Ti (UUID: GPU-2e06f878-f5ca-9417-ddb2-c943c2dc6b73)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get helper functions \n",
    "\n",
    "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a text dataset\n",
    "\n",
    "# The dataset we're going to be using is Kaggle's introduction to NLP dataset (text samples \n",
    "# of Tweets labelled as disaster or not disaster).\n",
    "\n",
    "unzip_data(\"nlp_getting_started.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing a text dataset\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df  = pd.read_csv(\"test.csv\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle training dataframe\n",
    "\n",
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many examples of each class\n",
    "\n",
    "train_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 3263)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many total samples\n",
    "\n",
    "len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "I REALLY liked the first Hobbit movie. I saw it three times in theatres. But I saw Desolation of Smaug and came out with the same feeling-\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "My ears are bleeding  https://t.co/k5KnNwugwT\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "#handbag #fashion #style http://t.co/iPXpI3me16 Authentic Louis Vuitton Pochette Bosphore Shoulder Cross Body BagÛ_ http://t.co/RV0Fk7q4Y5\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "http://t.co/PmHMmkSPaQ -PANDEMONIUM! Playstation One PS1 Retro Classic Original Platform Platinum Rare#Deals_UK http://t.co/0gKNpy4lUA\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 real disaster\n",
      "Text:\n",
      "#ClimateChange Eyewitness to Extreme Weather: 11 Social Media Posts that Show Just How Crazy Things A... http://t.co/czpDn9oBiT #Anarchy\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's visualize some random training samples\n",
    "\n",
    "import random \n",
    "\n",
    "random_index = random.randint(0,len(train_df)-5) # create random indexes not higher than the total number of samples\n",
    "\n",
    "for row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
    "    _, text, target = row\n",
    "    print(f\"Target: {target}\",\"real disaster\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data into training and validation sets\n",
    "\n",
    "from sklearn.model_selection import  train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size =0.1,  # use  %10 of training data for validation\n",
    "    random_state =42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the lengths\n",
    "\n",
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the first 10 samples\n",
    "\n",
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting text into numbers\n",
    "\n",
    "# When dealing with a text problem, one of the first things you'll have to do before you can build\n",
    "# a model is to convert your text to numbers.\n",
    "\n",
    "# There are a few ways to do this, namely:\n",
    "\n",
    "# * Tokenization - direct mapping of token (a token could be a word or a character) to number\n",
    "# * Embedding - create a matrix of feature vector for each token (the size of the feature vector \n",
    "#   can be defined and this embedding can be learned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "       'Imagine getting flattened by Kurt Zouma',\n",
       "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text vectorization (tokenization)\n",
    "\n",
    "train_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the default TextVEctorization parameters\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=10000, # How many words in the vocabulary (automatically add <OOV>)\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    split=\"whitespace\",\n",
    "    ngrams=None, # Create group of n-words\n",
    "    output_mode=\"int\", # how to map tokens to numbers\n",
    "    output_sequence_length=None, # how long do you want your sequences to be\n",
    "    pad_to_max_tokens=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the average number of tokens (words) in the training tweets\n",
    "\n",
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup text vectorization variables\n",
    "\n",
    "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
    "max_length = 15          # max length our sequences will be (e.g. how many words from a Tweet does a model see)\n",
    "\n",
    "\n",
    "text_vectorizer = TextVectorization(\n",
    "    max_tokens=max_vocab_length,\n",
    "    output_mode = \"int\",\n",
    "    output_sequence_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the text vectorizer to the training text\n",
    "\n",
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample sentence and tokenize it\n",
    "\n",
    "sample_sentence = \"There's a flood in my street!\"\n",
    "\n",
    "text_vectorizer([sample_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text:\n",
      " @danagould @WaynesterAtl I agree with background checks. I just think guns or weapons in general are the great equalizer.     \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
       "array([[   1, 6893,    8, 1331,   14, 4120,    1,    8,   29,  125, 1667,\n",
       "          53,  258,    4, 1289]], dtype=int64)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a random sentence from the training dataset and tokenize it\n",
    "\n",
    "random_sentence = random.choice(train_sentences)\n",
    "\n",
    "print(f\"original text:\\n {random_sentence} \\\n",
    "    \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number ofwords in vocab: 10000\n",
      "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "# Get the unique words in the vocabulary\n",
    "\n",
    "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
    "top_5_words = words_in_vocab[:5] # get the most common words\n",
    "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
    "\n",
    "print(f\"Number ofwords in vocab: {len(words_in_vocab)}\")\n",
    "print(f\"5 most common words: {top_5_words}\")\n",
    "print(f\"5 least common words: {bottom_5_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an Embedding using an Embedding Layer\n",
    "\n",
    "# To make our embedding, we're going to use TensorFlow's embedding\n",
    "\n",
    "# The parameters we care most about for our embedding layer:\n",
    "\n",
    "# * 'input_dim' = the size of our vocabulary\n",
    "# * 'output_dim' = the size of the output embedding vector, for example, a value of 100 would\n",
    "#    mean each token gets represented by a vector 100 long\n",
    "# * 'input_length' = length of the sequences being passed to the embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x2458574c370>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = tf.keras.layers.Embedding(\n",
    "    input_dim=max_vocab_length, # set input shape\n",
    "    embeddings_initializer=\"uniform\",\n",
    "    output_dim=128, # output shape\n",
    "    input_length=max_length # how long is each input\n",
    ")\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      " If you did a cannon ball into the ocean then Japan would evacuate.     \n",
      "\n",
      "Embedded versionn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[-0.02411309, -0.02921152, -0.01958233, ..., -0.02010771,\n",
       "         -0.03973632, -0.01710546],\n",
       "        [-0.02340623,  0.00344784, -0.00804519, ...,  0.01703881,\n",
       "         -0.04800327,  0.03189624],\n",
       "        [-0.02600302, -0.01196394,  0.03763499, ...,  0.04331932,\n",
       "         -0.0035737 , -0.00575263],\n",
       "        ...,\n",
       "        [-0.04471886,  0.02751051,  0.02040395, ..., -0.02122251,\n",
       "          0.01744893,  0.03128901],\n",
       "        [-0.04612554,  0.02336564,  0.036761  , ...,  0.01378923,\n",
       "          0.00464702, -0.01332492],\n",
       "        [-0.04612554,  0.02336564,  0.036761  , ...,  0.01378923,\n",
       "          0.00464702, -0.01332492]]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a random sentence from the training set\n",
    "\n",
    "random_sentence = random.choice(train_sentences)\n",
    "print(f\"Original text:\\n {random_sentence} \\\n",
    "    \\n\\nEmbedded versionn\")\n",
    "\n",
    "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
    "\n",
    "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
    "sample_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       " array([-0.02411309, -0.02921152, -0.01958233,  0.02108118, -0.00357972,\n",
       "        -0.04437232, -0.0311355 ,  0.02597591,  0.03884191,  0.00956484,\n",
       "         0.03471178,  0.02391754, -0.01018227,  0.02368085, -0.00794274,\n",
       "         0.02586642, -0.00144466,  0.03603128,  0.04129206, -0.02491697,\n",
       "         0.00303694,  0.03139639,  0.01887378,  0.02805313,  0.03640491,\n",
       "         0.00049644, -0.03937178, -0.00030519,  0.03388346,  0.04675949,\n",
       "         0.00456053, -0.04372363, -0.0030399 ,  0.03901377, -0.03505849,\n",
       "        -0.03144195,  0.00897168,  0.00042968,  0.01331044,  0.03278471,\n",
       "         0.04804652, -0.03340448, -0.00758804, -0.04932898, -0.03740633,\n",
       "         0.01724828,  0.0029879 ,  0.01878351, -0.03199407, -0.02856854,\n",
       "         0.00633968,  0.02910924, -0.03311455, -0.02620183, -0.01474868,\n",
       "         0.01147667,  0.03026669, -0.03414981, -0.03426995, -0.00651689,\n",
       "         0.01027114,  0.00543156,  0.01537038, -0.04525594, -0.01924652,\n",
       "        -0.0105463 , -0.02148464, -0.00437919, -0.02836725,  0.04267154,\n",
       "         0.02854292,  0.02396038, -0.03415996,  0.04385528,  0.01695495,\n",
       "        -0.00249927,  0.04217419,  0.02905656,  0.02872344, -0.00092731,\n",
       "         0.00715598, -0.0315326 ,  0.03591825,  0.02716782,  0.01027523,\n",
       "        -0.01941258,  0.01638791, -0.01840248, -0.03276582, -0.00680971,\n",
       "        -0.02136506,  0.04226056,  0.03971395,  0.01167194,  0.02321589,\n",
       "         0.00602844, -0.04268879,  0.03533505, -0.03100066,  0.00575694,\n",
       "        -0.00340249,  0.04039879,  0.00104173,  0.03603221,  0.02965453,\n",
       "        -0.02750673, -0.04305775, -0.04030045, -0.00864465, -0.01952581,\n",
       "         0.0330066 ,  0.04377525, -0.04079397, -0.02233526,  0.01179607,\n",
       "         0.03107229, -0.01771091,  0.04692351, -0.03300744,  0.02757302,\n",
       "        -0.01995205,  0.04054021, -0.02350868,  0.03537058, -0.04088448,\n",
       "        -0.02010771, -0.03973632, -0.01710546], dtype=float32)>,\n",
       " TensorShape([128]),\n",
       " 'If you did a cannon ball into the ocean then Japan would evacuate.')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out single token's embedding\n",
    "\n",
    "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modelling a text dataset (running a series of experiments)\n",
    "\n",
    "# Now we've a got way to turn our text sequences into numbers, it's time to start building a\n",
    "# series of modelling experiments.\n",
    "\n",
    "# We'll start with a baseline and move on from there.\n",
    "\n",
    "# * Model 0: Naive Bayes (baseline)\n",
    "# * Model 1: Feed-forward neural network (dense model)\n",
    "# * Model 2: LSTM (RNN)\n",
    "# * Model 3: GRU model (RNN)\n",
    "# * Model 4: Bidirectional-LSTM model (RNN\n",
    "# * Model 5: 1D Convolutional Neural Network (CNN)\n",
    "# * Model 6: TensorFlow Hub Pretrained Feature Extractor (using transfer learnin for NLP)\n",
    "# * Model 7: Same as model 6 with 10% of training data\n",
    "\n",
    "\n",
    "# How are we going to approach all of these\n",
    "\n",
    "# Use the standard steps in modelling with tensorflow:\n",
    "\n",
    "# * Create a model\n",
    "# * Build a model\n",
    "# * Fit a model\n",
    "# * Evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 0: Getting a baseline\n",
    "\n",
    "# As with all machine learning modelling experiments, it's important to create a baseline model\n",
    "# so you've got a benchmark for future experiments to build upon.\n",
    "\n",
    "# To create our baseline, we'll use Sklearn's Multinominal Naive Bayes using the TF-IDF formula\n",
    "# to convert our words to numbers.\n",
    "\n",
    "# Note: It's common practice to use non-DL (non deep learning) algorithms as a baseline because of\n",
    "#       their speed and then later using DL to see if you can improve upon them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import  Pipeline\n",
    "\n",
    "# Create tokenization and modelling pipeline\n",
    "\n",
    "model_0 = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "\n",
    "model_0.fit(train_sentences,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline model achieves an accuracy of: 79.27%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate our baseline model\n",
    "\n",
    "baseline_score = model_0.score(val_sentences, val_labels)\n",
    "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "\n",
    "baseline_preds = model_0.predict(val_sentences)\n",
    "baseline_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating an evaluation function for our model experiments\n",
    "\n",
    "# We could evaluate all of our model's predictions with different metrics every time, however,\n",
    "# this will be cumbersome and could easily be fixed with a function.\n",
    "\n",
    "# Let's create one to compare our model's predictions with the truth labels using the following metrics:\n",
    "\n",
    "# * Accuracy\n",
    "# * Presicion\n",
    "# * Recall\n",
    "# * F1-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate: accuracy, precision, recall, f1-score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def calculate_results(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate model accuracy\n",
    "\n",
    "    model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
    "\n",
    "    # Calculate model precision, recall and f1-score using 'weighted' average\n",
    "\n",
    "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
    "    model_results = {\n",
    "        \"accuracy\": model_accuracy,\n",
    "        \"precision\": model_precision,\n",
    "        \"recall\": model_recall,\n",
    "        \"f1\": model_f1\n",
    "    }\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get baseline results\n",
    "\n",
    "baseline_results = calculate_results(\n",
    "    y_true=val_labels,\n",
    "    y_pred=baseline_preds\n",
    ")\n",
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: A simple dense model\n",
    "\n",
    "# Create a tensorboard callback (need to create a new one for each model)\n",
    "\n",
    "from helper_functions import create_tensorboard_callback\n",
    "\n",
    "# Create a directory to save TensorBoadr logs\n",
    "\n",
    "SAVE_DIR = \"model_logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with the Functional API\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
    "\n",
    "x = text_vectorizer(inputs) # turn the input text into numbers\n",
    "\n",
    "x = embedding(x) # create an embedding of the numberized inputs\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x) # Condense the feature vector for eaxh token to one vector\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs so use sigmoid activation function \n",
    "\n",
    "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "model_1.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer =tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_1_dense/20220808-145936\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 3s 11ms/step - loss: 0.5721 - accuracy: 0.7757 - val_loss: 0.5275 - val_accuracy: 0.7756\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.4081 - accuracy: 0.8473 - val_loss: 0.4692 - val_accuracy: 0.7835\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 9ms/step - loss: 0.3222 - accuracy: 0.8793 - val_loss: 0.4617 - val_accuracy: 0.7979\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2673 - accuracy: 0.9013 - val_loss: 0.4648 - val_accuracy: 0.7913\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 8ms/step - loss: 0.2266 - accuracy: 0.9172 - val_loss: 0.4899 - val_accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "model_1_history = model_1.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data =(val_sentences,val_labels),\n",
    "    callbacks = [create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_1_dense\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(762, 1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs = model_1.predict(val_sentences)\n",
    "model_1_pred_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3119057], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3119057 ],\n",
       "       [0.74217385],\n",
       "       [0.9973756 ],\n",
       "       [0.12079117],\n",
       "       [0.07571841],\n",
       "       [0.91615146],\n",
       "       [0.90073013],\n",
       "       [0.99291295],\n",
       "       [0.96224207],\n",
       "       [0.2637214 ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert model prediction probabilities to label format\n",
    "\n",
    "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 78.74015748031496,\n",
       " 'precision': 0.7947430484232949,\n",
       " 'recall': 0.7874015748031497,\n",
       " 'f1': 0.783640218049667}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our model_1 results\n",
    "\n",
    "model_1_results = calculate_results(y_true=val_labels,y_pred=model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing learned embeddings\n",
    "\n",
    "# Get the vocabulary from the text vectorization layer\n",
    "\n",
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "len(words_in_vocab), words_in_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1_dense\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 128)              0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,280,129\n",
      "Trainable params: 1,280,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model 1 summary\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128)\n"
     ]
    }
   ],
   "source": [
    "# Get the weight matrix of embedding layer\n",
    "\n",
    "# (these are the numerical representations of each token in our training data, which have been learned for 5 epochs)\n",
    "\n",
    "\n",
    "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
    "print(embed_weights.shape) # same size as vocab size and embedding_dim (output_dim of our embedding layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've got the embedding matrix our model has learned to represent our tokens, let's see\n",
    "# how we can visualize it.\n",
    "\n",
    "# To do so, TensorFlow has a handy tool called projector: http://projector.tensorflow.org/\n",
    "\n",
    "# And TensorFlow also has an incredible guide on word embeddings themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddig files (we got this from TensorFlow's word embeddings documentation)\n",
    "\n",
    "import io\n",
    "\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "    if index == 0:\n",
    "        continue\n",
    "    vec = embed_weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + '\\n')\n",
    "    out_m.write(word + '\\n')\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Recurrent Neural Networks (RNN's)\n",
    "\n",
    "# RRN's are useful for sequence data.\n",
    "\n",
    "# The premise of a recurrent neural network is to use the representation of a previous input to \n",
    "# aid the representation of a later input.\n",
    "\n",
    "# If you want an overview of the internals of a recurrent neural network, see the following:\n",
    "\n",
    "# - MIT'S sequence modelling lecture https://youtu.be/gjrad0V0uJE\n",
    "\n",
    "# - Chris Olah's intro to LSTMs: https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "# - Andrej Karpathy's the unreasonable effectivenes of recurrent neural networks: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 2: LSTM\n",
    "\n",
    "# LSTM = long short term memory (one of the most popular LSTM cells)\n",
    "\n",
    "# Our structure of an RRN typically looks like this:\n",
    "\n",
    "# Input (text) -> Tokenize -> Embedding -> Layers (RRNs/dense) -> Output (label probability)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LSTM model\n",
    "\n",
    "inputs = tf.keras.Input(shape=(1,),dtype=tf.string)\n",
    "\n",
    "x = text_vectorizer(inputs)\n",
    "\n",
    "x = embedding(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need to return_sequences = True\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.LSTM(64)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "# print(x.shape)\n",
    "outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "# print(outputs.shape)\n",
    "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329,473\n",
      "Trainable params: 1,329,473\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_2_LSTM/20220808-162235\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 10s 23ms/step - loss: 0.2038 - accuracy: 0.9301 - val_loss: 0.6122 - val_accuracy: 0.7703\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.1329 - accuracy: 0.9515 - val_loss: 0.6347 - val_accuracy: 0.7625\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.1032 - accuracy: 0.9596 - val_loss: 0.7286 - val_accuracy: 0.7664\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 13ms/step - loss: 0.0771 - accuracy: 0.9723 - val_loss: 0.9059 - val_accuracy: 0.7730\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0598 - accuracy: 0.9752 - val_loss: 0.9805 - val_accuracy: 0.7677\n"
     ]
    }
   ],
   "source": [
    "model_2_history = model_2.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks = [create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_2_LSTM\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.0292413e-03],\n",
       "       [7.7285248e-01],\n",
       "       [9.9967396e-01],\n",
       "       [3.9707974e-02],\n",
       "       [4.2468921e-04],\n",
       "       [9.9920171e-01],\n",
       "       [9.8154885e-01],\n",
       "       [9.9977940e-01],\n",
       "       [9.9972349e-01],\n",
       "       [1.3556980e-01]], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with LSTM model\n",
    "\n",
    "model_2_pred_probs = model_2.predict(val_sentences)\n",
    "model_2_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert model 2 pred probs to labels\n",
    "\n",
    "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
    "model_2_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results = calculate_results(y_true=val_labels,y_pred=model_2_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 76.77165354330708,\n",
       " 'precision': 0.7702262582836057,\n",
       " 'recall': 0.7677165354330708,\n",
       " 'f1': 0.7651303822545579}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 3: GRU\n",
    "\n",
    "# Another popular and effective RNN component is the GRU or gated recurrent unit.\n",
    "\n",
    "# The GRU cell has similar features to an LSTM cell but has less parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(1,),dtype=tf.string)\n",
    "\n",
    "x = text_vectorizer(inputs)\n",
    "\n",
    "x = embedding(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.GRU(64,return_sequences=True)(x) # if you want to stack recurrent layers on top of each other, you need return_sequences = True\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.LSTM(64,return_sequences=True)(x)\n",
    "# print(x.shape)\n",
    "x = tf.keras.layers.GRU(64)(x)\n",
    "# print(x.shape)\n",
    "# x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "# print(x.shape)\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "# print(outputs.shape)\n",
    "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_3_GRU/20220808-163800\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 16ms/step - loss: 0.1701 - accuracy: 0.9295 - val_loss: 0.8149 - val_accuracy: 0.7638\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.0815 - accuracy: 0.9692 - val_loss: 1.0613 - val_accuracy: 0.7717\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 12ms/step - loss: 0.0644 - accuracy: 0.9742 - val_loss: 0.9290 - val_accuracy: 0.7664\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 2s 11ms/step - loss: 0.0529 - accuracy: 0.9787 - val_loss: 1.2083 - val_accuracy: 0.7612\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 12ms/step - loss: 0.0443 - accuracy: 0.9777 - val_loss: 1.1554 - val_accuracy: 0.7769\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_3_history = model_3.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data = (val_sentences,val_labels),\n",
    "    callbacks = [create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_3_GRU\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.78100411e-03],\n",
       "       [9.00014222e-01],\n",
       "       [9.99877810e-01],\n",
       "       [1.72411576e-01],\n",
       "       [1.28208048e-04],\n",
       "       [9.99354184e-01],\n",
       "       [9.77867365e-01],\n",
       "       [9.99910235e-01],\n",
       "       [9.99851108e-01],\n",
       "       [2.56809711e-01],\n",
       "       [7.38872739e-04],\n",
       "       [7.27820396e-01],\n",
       "       [3.77286022e-04],\n",
       "       [1.06840223e-01],\n",
       "       [8.54903410e-05],\n",
       "       [1.35841239e-02],\n",
       "       [1.93616317e-04],\n",
       "       [3.12122953e-04],\n",
       "       [5.04473411e-03],\n",
       "       [9.99687433e-01],\n",
       "       [9.75624621e-01],\n",
       "       [7.15063143e-05],\n",
       "       [9.77486372e-01],\n",
       "       [1.34887977e-03],\n",
       "       [9.99807060e-01],\n",
       "       [9.99870300e-01],\n",
       "       [6.04694127e-04],\n",
       "       [5.43411123e-04],\n",
       "       [1.37415409e-04],\n",
       "       [4.15411621e-01],\n",
       "       [9.39465821e-01],\n",
       "       [8.12976854e-04],\n",
       "       [3.45885102e-03],\n",
       "       [3.14829638e-03],\n",
       "       [7.14848459e-01],\n",
       "       [2.55738258e-01],\n",
       "       [9.99689817e-01],\n",
       "       [2.48975679e-01],\n",
       "       [2.37854645e-02],\n",
       "       [9.99892116e-01],\n",
       "       [2.21390024e-01],\n",
       "       [1.29061504e-04],\n",
       "       [1.25525310e-03],\n",
       "       [2.97494931e-04],\n",
       "       [9.49442804e-01],\n",
       "       [9.99761641e-01],\n",
       "       [6.83239996e-01],\n",
       "       [9.72932994e-01],\n",
       "       [1.07379619e-03],\n",
       "       [8.33046556e-01],\n",
       "       [2.43771099e-03],\n",
       "       [3.45171094e-01],\n",
       "       [6.91161752e-01],\n",
       "       [7.64235854e-03],\n",
       "       [2.10019965e-02],\n",
       "       [6.04092963e-02],\n",
       "       [5.66839753e-03],\n",
       "       [9.99785960e-01],\n",
       "       [3.77350749e-04],\n",
       "       [1.38957088e-03],\n",
       "       [1.99465267e-03],\n",
       "       [9.99798477e-01],\n",
       "       [9.95082378e-01],\n",
       "       [6.66630513e-04],\n",
       "       [9.99755681e-01],\n",
       "       [9.99916196e-01],\n",
       "       [9.82532620e-01],\n",
       "       [5.75281214e-03],\n",
       "       [7.92552412e-01],\n",
       "       [5.14071286e-01],\n",
       "       [1.33497203e-02],\n",
       "       [3.79056744e-02],\n",
       "       [9.99787509e-01],\n",
       "       [2.28800796e-04],\n",
       "       [6.14345819e-03],\n",
       "       [9.81725991e-01],\n",
       "       [8.86601105e-04],\n",
       "       [9.99363720e-01],\n",
       "       [1.34449705e-01],\n",
       "       [5.09007812e-01],\n",
       "       [6.25602726e-04],\n",
       "       [1.64059475e-01],\n",
       "       [9.99877214e-01],\n",
       "       [4.71778854e-04],\n",
       "       [1.38445105e-03],\n",
       "       [3.67074274e-04],\n",
       "       [2.42940121e-04],\n",
       "       [1.28190417e-03],\n",
       "       [5.14029234e-04],\n",
       "       [9.99723732e-01],\n",
       "       [9.99779046e-01],\n",
       "       [8.42600566e-05],\n",
       "       [1.27169788e-01],\n",
       "       [1.65080550e-04],\n",
       "       [9.99867678e-01],\n",
       "       [8.16936016e-01],\n",
       "       [4.58220810e-01],\n",
       "       [9.99785006e-01],\n",
       "       [9.99665260e-01],\n",
       "       [9.78164434e-01],\n",
       "       [9.99963760e-01],\n",
       "       [1.02483889e-03],\n",
       "       [1.34275775e-04],\n",
       "       [9.96620059e-01],\n",
       "       [9.99455750e-01],\n",
       "       [6.14827918e-03],\n",
       "       [9.27716970e-01],\n",
       "       [9.98691857e-01],\n",
       "       [7.78076705e-04],\n",
       "       [9.99333084e-01],\n",
       "       [9.67029333e-01],\n",
       "       [1.97212285e-04],\n",
       "       [1.59432113e-01],\n",
       "       [3.21733620e-04],\n",
       "       [3.60666891e-04],\n",
       "       [2.33435240e-02],\n",
       "       [5.26239455e-01],\n",
       "       [9.98360336e-01],\n",
       "       [8.66325165e-04],\n",
       "       [1.19169286e-04],\n",
       "       [9.99919176e-01],\n",
       "       [1.17676907e-04],\n",
       "       [1.42365054e-04],\n",
       "       [9.54467118e-01],\n",
       "       [4.56654131e-02],\n",
       "       [2.38673441e-04],\n",
       "       [9.93413985e-01],\n",
       "       [9.68453751e-05],\n",
       "       [6.38726517e-04],\n",
       "       [9.97924924e-01],\n",
       "       [3.51216906e-04],\n",
       "       [9.99919176e-01],\n",
       "       [9.99932051e-01],\n",
       "       [9.99870300e-01],\n",
       "       [9.99771893e-01],\n",
       "       [2.05181935e-03],\n",
       "       [9.99810398e-01],\n",
       "       [1.32813185e-01],\n",
       "       [1.77637476e-03],\n",
       "       [1.70565603e-04],\n",
       "       [9.99926329e-01],\n",
       "       [9.38461483e-01],\n",
       "       [1.06840223e-01],\n",
       "       [9.97045696e-01],\n",
       "       [6.34195581e-02],\n",
       "       [1.37681572e-03],\n",
       "       [1.01974067e-04],\n",
       "       [6.36434561e-05],\n",
       "       [1.09027827e-03],\n",
       "       [9.99735892e-01],\n",
       "       [3.20993713e-04],\n",
       "       [7.50281960e-02],\n",
       "       [1.16506324e-03],\n",
       "       [2.89212156e-04],\n",
       "       [2.80194945e-04],\n",
       "       [9.99625564e-01],\n",
       "       [9.85635996e-01],\n",
       "       [1.16476811e-01],\n",
       "       [9.99353826e-01],\n",
       "       [1.88765960e-04],\n",
       "       [9.99704778e-01],\n",
       "       [2.79276283e-03],\n",
       "       [4.46507126e-01],\n",
       "       [9.97858584e-01],\n",
       "       [7.42837274e-03],\n",
       "       [8.89407092e-05],\n",
       "       [9.99866128e-01],\n",
       "       [6.31269650e-04],\n",
       "       [9.99756038e-01],\n",
       "       [6.22684360e-01],\n",
       "       [9.99855280e-01],\n",
       "       [9.99321103e-01],\n",
       "       [9.99622583e-01],\n",
       "       [2.43807284e-04],\n",
       "       [9.99942422e-01],\n",
       "       [3.08656570e-04],\n",
       "       [7.12244725e-03],\n",
       "       [2.60922015e-02],\n",
       "       [2.53758505e-02],\n",
       "       [9.99842644e-01],\n",
       "       [4.80256713e-04],\n",
       "       [9.76537645e-01],\n",
       "       [9.99732554e-01],\n",
       "       [9.99896049e-01],\n",
       "       [9.99752462e-01],\n",
       "       [3.08234914e-04],\n",
       "       [2.03710559e-04],\n",
       "       [9.99968529e-01],\n",
       "       [1.12318681e-04],\n",
       "       [7.43626661e-05],\n",
       "       [3.80129297e-03],\n",
       "       [1.79965436e-01],\n",
       "       [4.51013009e-04],\n",
       "       [2.26400458e-04],\n",
       "       [1.65793404e-04],\n",
       "       [8.24426708e-04],\n",
       "       [1.88962222e-04],\n",
       "       [5.07258577e-03],\n",
       "       [9.99699950e-01],\n",
       "       [9.98455682e-04],\n",
       "       [1.10342074e-03],\n",
       "       [9.99805272e-01],\n",
       "       [9.99827206e-01],\n",
       "       [3.80966105e-02],\n",
       "       [3.28219525e-04],\n",
       "       [9.99848247e-01],\n",
       "       [9.99570787e-01],\n",
       "       [9.98507202e-01],\n",
       "       [9.97030139e-01],\n",
       "       [9.96333122e-01],\n",
       "       [2.90273279e-02],\n",
       "       [9.99789178e-01],\n",
       "       [3.05319816e-04],\n",
       "       [1.25539291e-03],\n",
       "       [2.41609843e-04],\n",
       "       [1.48237232e-04],\n",
       "       [9.99847531e-01],\n",
       "       [9.86808777e-01],\n",
       "       [9.73698676e-01],\n",
       "       [4.58347082e-01],\n",
       "       [1.28715308e-02],\n",
       "       [7.11904513e-03],\n",
       "       [1.36381052e-02],\n",
       "       [1.64816820e-03],\n",
       "       [9.99800503e-01],\n",
       "       [1.32444277e-02],\n",
       "       [1.71949603e-02],\n",
       "       [9.99948978e-01],\n",
       "       [9.99378204e-01],\n",
       "       [9.77004647e-01],\n",
       "       [2.51479389e-04],\n",
       "       [7.28425849e-03],\n",
       "       [9.96846139e-01],\n",
       "       [2.70755123e-02],\n",
       "       [4.00273710e-01],\n",
       "       [1.38943410e-03],\n",
       "       [1.21414214e-01],\n",
       "       [9.85919498e-04],\n",
       "       [2.75695510e-03],\n",
       "       [3.08528892e-04],\n",
       "       [9.97672260e-01],\n",
       "       [2.86228564e-02],\n",
       "       [9.99850035e-01],\n",
       "       [9.99797046e-01],\n",
       "       [3.42524698e-04],\n",
       "       [1.65605699e-04],\n",
       "       [9.99748528e-01],\n",
       "       [2.27791417e-04],\n",
       "       [1.54287247e-02],\n",
       "       [3.12065542e-01],\n",
       "       [2.06751210e-04],\n",
       "       [9.99138951e-01],\n",
       "       [1.14255658e-04],\n",
       "       [5.17414999e-04],\n",
       "       [9.99711096e-01],\n",
       "       [5.76556548e-02],\n",
       "       [9.99625206e-01],\n",
       "       [9.99939442e-01],\n",
       "       [7.59358332e-02],\n",
       "       [2.61218695e-04],\n",
       "       [2.39842077e-04],\n",
       "       [7.60184717e-04],\n",
       "       [6.26080218e-05],\n",
       "       [9.99392867e-01],\n",
       "       [9.99770939e-01],\n",
       "       [1.16151283e-02],\n",
       "       [9.99711096e-01],\n",
       "       [2.23358016e-04],\n",
       "       [5.09579375e-04],\n",
       "       [3.06168367e-04],\n",
       "       [4.86958335e-04],\n",
       "       [2.05365912e-04],\n",
       "       [9.99786079e-01],\n",
       "       [3.22405784e-03],\n",
       "       [1.78098679e-04],\n",
       "       [9.99744475e-01],\n",
       "       [9.56806907e-05],\n",
       "       [1.07926709e-04],\n",
       "       [9.99618411e-01],\n",
       "       [9.82640922e-05],\n",
       "       [4.13551740e-03],\n",
       "       [2.23524170e-04],\n",
       "       [9.99787748e-01],\n",
       "       [8.82867396e-01],\n",
       "       [5.10663092e-01],\n",
       "       [4.75486457e-01],\n",
       "       [9.98922765e-01],\n",
       "       [1.86158027e-02],\n",
       "       [9.98176098e-01],\n",
       "       [9.98645462e-03],\n",
       "       [9.91115451e-01],\n",
       "       [4.81605023e-01],\n",
       "       [9.68409479e-01],\n",
       "       [4.25026305e-02],\n",
       "       [1.07966445e-03],\n",
       "       [7.03751385e-01],\n",
       "       [1.92234721e-02],\n",
       "       [1.40786183e-03],\n",
       "       [3.09643656e-04],\n",
       "       [1.47165239e-01],\n",
       "       [6.19813072e-05],\n",
       "       [2.78926775e-04],\n",
       "       [5.30007370e-02],\n",
       "       [9.99840379e-01],\n",
       "       [4.29970998e-04],\n",
       "       [5.37480554e-03],\n",
       "       [4.54740562e-02],\n",
       "       [1.18331604e-01],\n",
       "       [2.63837585e-03],\n",
       "       [2.92563956e-04],\n",
       "       [2.17308916e-04],\n",
       "       [9.99686599e-01],\n",
       "       [1.74662732e-02],\n",
       "       [3.06892127e-01],\n",
       "       [9.99951601e-01],\n",
       "       [1.88629041e-04],\n",
       "       [6.54024899e-01],\n",
       "       [2.51959600e-02],\n",
       "       [1.14723272e-03],\n",
       "       [4.70866710e-02],\n",
       "       [3.93357681e-04],\n",
       "       [2.49011349e-03],\n",
       "       [9.98313546e-01],\n",
       "       [1.31975132e-04],\n",
       "       [9.99794424e-01],\n",
       "       [1.69777662e-01],\n",
       "       [2.05583769e-04],\n",
       "       [9.99809563e-01],\n",
       "       [4.81909228e-04],\n",
       "       [9.99833107e-01],\n",
       "       [1.39038649e-03],\n",
       "       [2.52555823e-04],\n",
       "       [9.99796927e-01],\n",
       "       [4.94690205e-04],\n",
       "       [1.88677252e-04],\n",
       "       [9.99758422e-01],\n",
       "       [2.42840790e-04],\n",
       "       [9.64797102e-03],\n",
       "       [4.81429011e-01],\n",
       "       [9.57785368e-01],\n",
       "       [1.87083424e-04],\n",
       "       [1.08054781e-03],\n",
       "       [9.99784529e-01],\n",
       "       [9.99859691e-01],\n",
       "       [9.99054492e-01],\n",
       "       [7.62213543e-02],\n",
       "       [9.81248021e-01],\n",
       "       [9.83769894e-01],\n",
       "       [2.73357369e-02],\n",
       "       [6.22385647e-04],\n",
       "       [1.22794166e-01],\n",
       "       [1.70850288e-02],\n",
       "       [1.67092730e-04],\n",
       "       [2.46603158e-03],\n",
       "       [1.69038388e-03],\n",
       "       [2.28735982e-04],\n",
       "       [9.99742806e-01],\n",
       "       [9.99870300e-01],\n",
       "       [9.99884009e-01],\n",
       "       [5.77403931e-04],\n",
       "       [2.34085143e-01],\n",
       "       [2.57870667e-02],\n",
       "       [6.19522855e-02],\n",
       "       [9.68862116e-01],\n",
       "       [2.99533248e-01],\n",
       "       [1.30169763e-04],\n",
       "       [2.10627652e-04],\n",
       "       [9.42586805e-04],\n",
       "       [9.97576654e-01],\n",
       "       [5.90369338e-04],\n",
       "       [8.16859398e-03],\n",
       "       [2.61527952e-04],\n",
       "       [4.94048174e-04],\n",
       "       [2.56298572e-01],\n",
       "       [6.84054792e-01],\n",
       "       [1.08688794e-01],\n",
       "       [8.31946265e-04],\n",
       "       [3.94313643e-03],\n",
       "       [1.51323315e-04],\n",
       "       [9.99903440e-01],\n",
       "       [9.99710500e-01],\n",
       "       [2.39866510e-01],\n",
       "       [1.92050844e-01],\n",
       "       [1.53306508e-04],\n",
       "       [9.96395767e-01],\n",
       "       [9.99861479e-01],\n",
       "       [8.42048526e-01],\n",
       "       [3.90545338e-01],\n",
       "       [9.99091864e-01],\n",
       "       [1.15293460e-02],\n",
       "       [9.99908686e-01],\n",
       "       [8.74148216e-03],\n",
       "       [9.78190219e-04],\n",
       "       [4.88138318e-01],\n",
       "       [2.69273426e-02],\n",
       "       [9.99675035e-01],\n",
       "       [2.28695702e-02],\n",
       "       [6.59272337e-05],\n",
       "       [1.09643433e-02],\n",
       "       [2.99533248e-01],\n",
       "       [9.99964714e-01],\n",
       "       [1.38846342e-04],\n",
       "       [1.69426482e-02],\n",
       "       [9.99846339e-01],\n",
       "       [7.38071685e-05],\n",
       "       [9.99919176e-01],\n",
       "       [2.07871592e-04],\n",
       "       [7.01670418e-04],\n",
       "       [1.70874584e-04],\n",
       "       [9.99569833e-01],\n",
       "       [9.98346090e-01],\n",
       "       [4.26830520e-04],\n",
       "       [3.76646523e-04],\n",
       "       [9.75453675e-01],\n",
       "       [9.99802053e-01],\n",
       "       [5.57566822e-01],\n",
       "       [1.97136891e-04],\n",
       "       [3.46797742e-02],\n",
       "       [2.80921102e-01],\n",
       "       [3.79995734e-04],\n",
       "       [9.99906778e-01],\n",
       "       [7.42406487e-01],\n",
       "       [9.99893546e-01],\n",
       "       [9.99665618e-01],\n",
       "       [2.15137075e-03],\n",
       "       [4.67980484e-04],\n",
       "       [2.70389195e-04],\n",
       "       [9.99354303e-01],\n",
       "       [6.09948695e-01],\n",
       "       [7.82545269e-01],\n",
       "       [9.62715130e-04],\n",
       "       [9.45789814e-02],\n",
       "       [3.30818468e-04],\n",
       "       [1.50125430e-04],\n",
       "       [1.07141323e-02],\n",
       "       [6.58430683e-04],\n",
       "       [9.98731077e-01],\n",
       "       [1.69718266e-03],\n",
       "       [9.99918938e-01],\n",
       "       [9.99870300e-01],\n",
       "       [5.09188569e-04],\n",
       "       [9.00014222e-01],\n",
       "       [1.15573069e-03],\n",
       "       [4.75753652e-04],\n",
       "       [5.01187503e-01],\n",
       "       [9.96247709e-01],\n",
       "       [1.11458004e-02],\n",
       "       [1.61174638e-03],\n",
       "       [1.94909939e-04],\n",
       "       [1.50978228e-03],\n",
       "       [3.52745810e-05],\n",
       "       [9.99754727e-01],\n",
       "       [9.99317527e-01],\n",
       "       [9.99837756e-01],\n",
       "       [9.95849133e-01],\n",
       "       [8.13797712e-01],\n",
       "       [6.07266314e-02],\n",
       "       [1.50117281e-04],\n",
       "       [9.98109341e-01],\n",
       "       [9.99058545e-01],\n",
       "       [9.99859333e-01],\n",
       "       [1.05162535e-03],\n",
       "       [1.64641980e-02],\n",
       "       [3.41315055e-04],\n",
       "       [9.99861717e-01],\n",
       "       [9.99827206e-01],\n",
       "       [8.82293156e-04],\n",
       "       [2.26461161e-02],\n",
       "       [9.99926329e-01],\n",
       "       [3.20550636e-03],\n",
       "       [4.57060116e-04],\n",
       "       [9.98144388e-01],\n",
       "       [2.63819209e-04],\n",
       "       [2.90299475e-04],\n",
       "       [9.96183336e-01],\n",
       "       [3.72460842e-01],\n",
       "       [2.04672255e-02],\n",
       "       [9.99937654e-01],\n",
       "       [3.48796748e-04],\n",
       "       [8.01091432e-04],\n",
       "       [5.35471663e-05],\n",
       "       [2.00588125e-04],\n",
       "       [4.12421097e-04],\n",
       "       [9.99798596e-01],\n",
       "       [1.79399984e-04],\n",
       "       [7.57164717e-01],\n",
       "       [9.47883546e-01],\n",
       "       [9.86885279e-03],\n",
       "       [5.38716204e-02],\n",
       "       [1.24902741e-04],\n",
       "       [1.06364861e-03],\n",
       "       [9.99879837e-01],\n",
       "       [9.99647856e-01],\n",
       "       [4.56801709e-03],\n",
       "       [2.44383031e-04],\n",
       "       [2.58797751e-04],\n",
       "       [2.11055230e-04],\n",
       "       [9.99469221e-01],\n",
       "       [4.36093222e-04],\n",
       "       [9.98315811e-01],\n",
       "       [9.94037151e-01],\n",
       "       [8.33854079e-01],\n",
       "       [9.83413875e-01],\n",
       "       [3.28121692e-01],\n",
       "       [1.53931568e-03],\n",
       "       [2.91509816e-04],\n",
       "       [2.79534668e-01],\n",
       "       [8.49698961e-01],\n",
       "       [8.70468915e-01],\n",
       "       [4.21283208e-02],\n",
       "       [7.00430013e-04],\n",
       "       [9.69294488e-05],\n",
       "       [5.52416255e-04],\n",
       "       [1.64023191e-02],\n",
       "       [2.75721755e-02],\n",
       "       [1.71483815e-01],\n",
       "       [9.99896049e-01],\n",
       "       [9.99714434e-01],\n",
       "       [8.16936016e-01],\n",
       "       [9.99549091e-01],\n",
       "       [3.29908356e-02],\n",
       "       [4.29556589e-04],\n",
       "       [9.99705851e-01],\n",
       "       [4.69661737e-03],\n",
       "       [2.81126914e-03],\n",
       "       [1.19582377e-01],\n",
       "       [9.95633781e-01],\n",
       "       [1.15774514e-04],\n",
       "       [7.36557722e-01],\n",
       "       [9.87285078e-01],\n",
       "       [9.98966217e-01],\n",
       "       [9.99508023e-01],\n",
       "       [2.84315087e-04],\n",
       "       [8.55118502e-04],\n",
       "       [9.85220551e-01],\n",
       "       [1.44738122e-04],\n",
       "       [9.60088801e-03],\n",
       "       [4.31560837e-02],\n",
       "       [9.58302140e-01],\n",
       "       [9.91603792e-01],\n",
       "       [1.42830086e-03],\n",
       "       [3.08981049e-04],\n",
       "       [9.65033650e-01],\n",
       "       [3.66853492e-04],\n",
       "       [5.93091419e-04],\n",
       "       [9.77272430e-05],\n",
       "       [3.51282150e-01],\n",
       "       [9.99900937e-01],\n",
       "       [9.99302864e-01],\n",
       "       [1.22917011e-01],\n",
       "       [9.97311831e-01],\n",
       "       [9.99849558e-01],\n",
       "       [1.08099550e-04],\n",
       "       [9.99786198e-01],\n",
       "       [2.94891652e-02],\n",
       "       [9.73101735e-01],\n",
       "       [4.77681346e-02],\n",
       "       [1.58085884e-03],\n",
       "       [2.09601902e-04],\n",
       "       [1.92162639e-04],\n",
       "       [1.30132923e-03],\n",
       "       [7.28551677e-05],\n",
       "       [9.24421072e-01],\n",
       "       [5.91070333e-04],\n",
       "       [9.99825656e-01],\n",
       "       [6.33206568e-04],\n",
       "       [9.97216463e-01],\n",
       "       [1.09627172e-01],\n",
       "       [1.89002708e-03],\n",
       "       [2.55038001e-04],\n",
       "       [9.99931216e-01],\n",
       "       [3.65091464e-03],\n",
       "       [9.99764979e-01],\n",
       "       [2.24664077e-01],\n",
       "       [3.02524655e-03],\n",
       "       [1.25997677e-01],\n",
       "       [4.02290985e-04],\n",
       "       [9.55949910e-03],\n",
       "       [9.99849558e-01],\n",
       "       [2.09661681e-04],\n",
       "       [2.98128958e-04],\n",
       "       [5.49515290e-03],\n",
       "       [9.99867082e-01],\n",
       "       [5.08218817e-02],\n",
       "       [2.78666266e-04],\n",
       "       [9.97404635e-01],\n",
       "       [1.49094732e-04],\n",
       "       [2.03784963e-04],\n",
       "       [2.85061513e-04],\n",
       "       [5.58264591e-02],\n",
       "       [5.68471034e-04],\n",
       "       [2.88029492e-01],\n",
       "       [2.71012378e-03],\n",
       "       [6.70539401e-03],\n",
       "       [2.08810408e-04],\n",
       "       [7.13878637e-03],\n",
       "       [1.90217528e-04],\n",
       "       [9.94491220e-01],\n",
       "       [9.94298041e-01],\n",
       "       [3.63337900e-03],\n",
       "       [1.58996030e-04],\n",
       "       [6.54417789e-04],\n",
       "       [9.99808729e-01],\n",
       "       [9.38815057e-01],\n",
       "       [9.99926805e-01],\n",
       "       [3.41086183e-04],\n",
       "       [9.99401927e-01],\n",
       "       [2.09737831e-04],\n",
       "       [7.60103524e-01],\n",
       "       [9.47244525e-01],\n",
       "       [1.60125390e-04],\n",
       "       [9.99880552e-01],\n",
       "       [6.79741788e-04],\n",
       "       [9.85109448e-01],\n",
       "       [9.99923944e-01],\n",
       "       [3.31573980e-03],\n",
       "       [1.07906431e-04],\n",
       "       [8.00556481e-01],\n",
       "       [1.69138628e-04],\n",
       "       [2.21261084e-01],\n",
       "       [9.99848247e-01],\n",
       "       [2.49693528e-01],\n",
       "       [9.98614073e-01],\n",
       "       [2.09722534e-01],\n",
       "       [9.99729693e-01],\n",
       "       [9.84877110e-01],\n",
       "       [4.37119091e-03],\n",
       "       [1.50223088e-04],\n",
       "       [7.29232550e-01],\n",
       "       [1.08819688e-04],\n",
       "       [2.58229613e-01],\n",
       "       [9.99671459e-01],\n",
       "       [9.96483207e-01],\n",
       "       [9.99893904e-01],\n",
       "       [9.99465764e-01],\n",
       "       [1.03308856e-01],\n",
       "       [6.64414227e-01],\n",
       "       [1.67915598e-04],\n",
       "       [5.40734529e-01],\n",
       "       [9.98929203e-01],\n",
       "       [9.99676943e-01],\n",
       "       [2.03442891e-04],\n",
       "       [9.79349434e-01],\n",
       "       [9.99692678e-01],\n",
       "       [4.48144885e-04],\n",
       "       [4.69382759e-03],\n",
       "       [4.21283208e-02],\n",
       "       [1.87159062e-03],\n",
       "       [7.35127449e-01],\n",
       "       [9.96341288e-01],\n",
       "       [9.99829769e-01],\n",
       "       [1.10370934e-03],\n",
       "       [1.92952299e-04],\n",
       "       [2.61475856e-04],\n",
       "       [2.37939298e-01],\n",
       "       [1.68282317e-03],\n",
       "       [5.88825904e-02],\n",
       "       [9.86110210e-01],\n",
       "       [1.87011363e-04],\n",
       "       [1.61926672e-02],\n",
       "       [4.56739683e-03],\n",
       "       [1.95551097e-01],\n",
       "       [9.98785675e-01],\n",
       "       [8.12153448e-04],\n",
       "       [9.98349309e-01],\n",
       "       [5.28521556e-03],\n",
       "       [6.80343728e-05],\n",
       "       [3.61120328e-04],\n",
       "       [9.99887943e-01],\n",
       "       [4.95415270e-01],\n",
       "       [1.57293412e-04],\n",
       "       [6.77637577e-01],\n",
       "       [1.51090007e-02],\n",
       "       [1.98398222e-04],\n",
       "       [9.99783695e-01],\n",
       "       [8.70864722e-04],\n",
       "       [9.74680722e-01],\n",
       "       [2.56462812e-01],\n",
       "       [2.81400717e-04],\n",
       "       [6.93318367e-01],\n",
       "       [7.18209296e-02],\n",
       "       [4.43915045e-03],\n",
       "       [9.99585092e-01],\n",
       "       [6.86019957e-02],\n",
       "       [3.00610870e-01],\n",
       "       [9.99925494e-01],\n",
       "       [3.47712994e-01],\n",
       "       [5.77385677e-03],\n",
       "       [1.15774514e-04],\n",
       "       [2.40229160e-01],\n",
       "       [9.74789977e-01],\n",
       "       [9.99919176e-01],\n",
       "       [9.83012259e-01],\n",
       "       [1.03930794e-01],\n",
       "       [9.99166608e-01],\n",
       "       [3.18361789e-01],\n",
       "       [9.99607384e-01],\n",
       "       [3.18361789e-01],\n",
       "       [9.99879599e-01],\n",
       "       [1.09197434e-04],\n",
       "       [8.79876595e-03],\n",
       "       [1.68169077e-04],\n",
       "       [9.99918461e-01],\n",
       "       [8.78819637e-03],\n",
       "       [1.19677493e-02],\n",
       "       [1.56399969e-04],\n",
       "       [1.76593836e-03],\n",
       "       [3.11217882e-04],\n",
       "       [7.07742816e-04],\n",
       "       [1.12581261e-01],\n",
       "       [2.58452771e-03],\n",
       "       [3.92006652e-04],\n",
       "       [9.86382723e-01],\n",
       "       [8.32005404e-04],\n",
       "       [3.01119615e-03],\n",
       "       [6.36355893e-04],\n",
       "       [1.32354980e-04],\n",
       "       [5.43663371e-03],\n",
       "       [9.82208788e-01],\n",
       "       [1.81639846e-03],\n",
       "       [7.93144281e-04],\n",
       "       [6.12674328e-03],\n",
       "       [9.87768114e-01],\n",
       "       [9.99771893e-01],\n",
       "       [2.48886325e-04],\n",
       "       [1.74829998e-04],\n",
       "       [1.81208030e-04],\n",
       "       [4.49399085e-05],\n",
       "       [9.99788702e-01],\n",
       "       [1.32354980e-04],\n",
       "       [1.87687133e-03],\n",
       "       [9.99401331e-01],\n",
       "       [9.99833822e-01],\n",
       "       [9.99834418e-01],\n",
       "       [9.99940395e-01],\n",
       "       [9.99980807e-01],\n",
       "       [5.94668381e-04],\n",
       "       [7.18274387e-04],\n",
       "       [4.66035353e-03],\n",
       "       [9.96640205e-01],\n",
       "       [9.99851108e-01],\n",
       "       [9.57846701e-01],\n",
       "       [6.42440980e-03],\n",
       "       [9.98515427e-01],\n",
       "       [9.36801732e-01],\n",
       "       [1.26759391e-04],\n",
       "       [2.81039043e-04],\n",
       "       [7.69072864e-03],\n",
       "       [6.12494629e-03],\n",
       "       [1.26535248e-04],\n",
       "       [3.75090691e-04],\n",
       "       [5.94963133e-01],\n",
       "       [9.99926567e-01],\n",
       "       [2.03274787e-04],\n",
       "       [9.99837279e-01],\n",
       "       [9.83881354e-01],\n",
       "       [3.79223749e-03],\n",
       "       [1.76294018e-02],\n",
       "       [3.38051915e-02],\n",
       "       [8.01822901e-01],\n",
       "       [5.22550285e-01],\n",
       "       [2.34856401e-04]], dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_pred_probs = model_3.predict(val_sentences)\n",
    "model_3_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
    "model_3_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_results = calculate_results(y_true=val_labels,y_pred=model_3_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.69028871391076,\n",
       " 'precision': 0.7798819103655997,\n",
       " 'recall': 0.7769028871391076,\n",
       " 'f1': 0.7743498017353971}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model 4: Bidirectional RNN\n",
    "\n",
    "# Normal RNN's go from left to right (just like you'd read an English sentence) however, a \n",
    "# bidirectional RNN goes from right to left as well as left to right.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(1,),dtype=tf.string)\n",
    "\n",
    "x = text_vectorizer(inputs)\n",
    "\n",
    "x = embedding(x)\n",
    "\n",
    "#x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(x)\n",
    "\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64))(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4_Bidirectional\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 1)]               0         \n",
      "                                                                 \n",
      " text_vectorization_1 (TextV  (None, 15)               0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 128)              98816     \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,378,945\n",
      "Trainable params: 1,378,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get a summary\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_4_Bidirectional/20220808-170854\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 9s 21ms/step - loss: 0.1108 - accuracy: 0.9623 - val_loss: 0.8567 - val_accuracy: 0.7428\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0497 - accuracy: 0.9781 - val_loss: 1.1951 - val_accuracy: 0.7651\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0418 - accuracy: 0.9813 - val_loss: 1.3618 - val_accuracy: 0.7612\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 15ms/step - loss: 0.0408 - accuracy: 0.9804 - val_loss: 1.2175 - val_accuracy: 0.7559\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0379 - accuracy: 0.9818 - val_loss: 1.5208 - val_accuracy: 0.7559\n"
     ]
    }
   ],
   "source": [
    "model_4.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_model_4 = model_4.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences,val_labels),\n",
    "    callbacks = [create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_4_Bidirectional\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 7ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.62381625e-04],\n",
       "       [7.53144205e-01],\n",
       "       [9.99988079e-01],\n",
       "       [3.38976145e-01],\n",
       "       [2.22556901e-05],\n",
       "       [9.99832153e-01],\n",
       "       [9.99605715e-01],\n",
       "       [9.99993205e-01],\n",
       "       [9.99992132e-01],\n",
       "       [9.73126113e-01],\n",
       "       [1.09010158e-04],\n",
       "       [9.87559259e-01],\n",
       "       [3.60095837e-05],\n",
       "       [3.53299946e-01],\n",
       "       [2.78410098e-05],\n",
       "       [2.62815808e-03],\n",
       "       [8.60873770e-05],\n",
       "       [2.03030340e-05],\n",
       "       [1.00080657e-03],\n",
       "       [9.99771893e-01],\n",
       "       [9.99950767e-01],\n",
       "       [2.36692758e-05],\n",
       "       [9.99385953e-01],\n",
       "       [2.01328337e-04],\n",
       "       [9.99981999e-01],\n",
       "       [9.99995351e-01],\n",
       "       [1.19694865e-04],\n",
       "       [7.20845186e-04],\n",
       "       [3.24291614e-05],\n",
       "       [9.56143677e-01],\n",
       "       [9.99386787e-01],\n",
       "       [2.23988644e-03],\n",
       "       [2.11666847e-04],\n",
       "       [4.84255003e-03],\n",
       "       [1.13061868e-01],\n",
       "       [9.26920772e-01],\n",
       "       [9.99987960e-01],\n",
       "       [3.12545925e-01],\n",
       "       [7.27767358e-04],\n",
       "       [9.99980092e-01],\n",
       "       [6.70112729e-01],\n",
       "       [1.11312966e-05],\n",
       "       [4.32647765e-04],\n",
       "       [2.08669589e-05],\n",
       "       [9.45174277e-01],\n",
       "       [9.99986410e-01],\n",
       "       [9.96834219e-01],\n",
       "       [9.95033622e-01],\n",
       "       [2.80825829e-04],\n",
       "       [9.83551443e-01],\n",
       "       [8.47919087e-04],\n",
       "       [5.04492342e-01],\n",
       "       [9.81708288e-01],\n",
       "       [3.04329675e-04],\n",
       "       [7.65685201e-01],\n",
       "       [1.67045444e-01],\n",
       "       [4.83646197e-03],\n",
       "       [9.99983668e-01],\n",
       "       [5.11978542e-05],\n",
       "       [4.17680640e-05],\n",
       "       [5.98888204e-04],\n",
       "       [9.99989152e-01],\n",
       "       [9.99636889e-01],\n",
       "       [1.11129957e-04],\n",
       "       [9.99977827e-01],\n",
       "       [9.99990940e-01],\n",
       "       [9.99624729e-01],\n",
       "       [8.86376321e-01],\n",
       "       [9.98903275e-01],\n",
       "       [6.97733223e-01],\n",
       "       [6.31192583e-04],\n",
       "       [1.46860899e-02],\n",
       "       [9.99982595e-01],\n",
       "       [2.12935251e-04],\n",
       "       [8.08859229e-01],\n",
       "       [9.57588255e-01],\n",
       "       [5.85989153e-04],\n",
       "       [9.99988675e-01],\n",
       "       [3.40870291e-01],\n",
       "       [1.29919156e-01],\n",
       "       [2.16811779e-04],\n",
       "       [6.63668197e-03],\n",
       "       [9.99994636e-01],\n",
       "       [3.01309865e-05],\n",
       "       [8.42678492e-05],\n",
       "       [1.38783609e-04],\n",
       "       [4.27803789e-05],\n",
       "       [9.17550642e-05],\n",
       "       [7.15066490e-05],\n",
       "       [9.99982834e-01],\n",
       "       [9.99991417e-01],\n",
       "       [9.65530307e-06],\n",
       "       [9.94023383e-01],\n",
       "       [2.43324266e-05],\n",
       "       [9.99995232e-01],\n",
       "       [7.24946856e-01],\n",
       "       [9.66526508e-01],\n",
       "       [9.99961972e-01],\n",
       "       [9.99957561e-01],\n",
       "       [9.95944202e-01],\n",
       "       [9.99990582e-01],\n",
       "       [3.64170963e-04],\n",
       "       [1.64139637e-05],\n",
       "       [9.99906659e-01],\n",
       "       [9.99922991e-01],\n",
       "       [5.89535594e-01],\n",
       "       [9.95386302e-01],\n",
       "       [9.99982119e-01],\n",
       "       [2.85940550e-05],\n",
       "       [9.99633908e-01],\n",
       "       [9.89114165e-01],\n",
       "       [1.67976439e-04],\n",
       "       [4.62970853e-01],\n",
       "       [1.02954749e-04],\n",
       "       [4.77147623e-05],\n",
       "       [2.06950563e-03],\n",
       "       [1.14430167e-01],\n",
       "       [9.99745905e-01],\n",
       "       [9.81531921e-04],\n",
       "       [7.02562829e-05],\n",
       "       [9.99994159e-01],\n",
       "       [1.73955432e-05],\n",
       "       [2.21563278e-05],\n",
       "       [9.44311619e-01],\n",
       "       [1.34417228e-02],\n",
       "       [3.41057748e-04],\n",
       "       [9.99603450e-01],\n",
       "       [1.53457058e-05],\n",
       "       [1.65505160e-04],\n",
       "       [9.99908566e-01],\n",
       "       [1.62424505e-04],\n",
       "       [9.99994159e-01],\n",
       "       [9.99994040e-01],\n",
       "       [9.99995351e-01],\n",
       "       [9.99991536e-01],\n",
       "       [1.85283308e-04],\n",
       "       [9.99992490e-01],\n",
       "       [2.86358260e-02],\n",
       "       [1.98225403e-04],\n",
       "       [4.16308649e-05],\n",
       "       [9.99996781e-01],\n",
       "       [9.95589972e-01],\n",
       "       [3.53299946e-01],\n",
       "       [9.99916792e-01],\n",
       "       [1.36300409e-03],\n",
       "       [7.76812085e-04],\n",
       "       [3.00364809e-05],\n",
       "       [1.23480977e-05],\n",
       "       [2.49532139e-04],\n",
       "       [9.99989629e-01],\n",
       "       [2.97926337e-04],\n",
       "       [2.43986383e-01],\n",
       "       [3.00678250e-04],\n",
       "       [4.26390943e-05],\n",
       "       [1.46571954e-04],\n",
       "       [9.99984622e-01],\n",
       "       [9.89745498e-01],\n",
       "       [9.99548356e-04],\n",
       "       [9.99989629e-01],\n",
       "       [2.98554532e-05],\n",
       "       [9.99617696e-01],\n",
       "       [1.31259396e-04],\n",
       "       [4.44639891e-01],\n",
       "       [9.98830259e-01],\n",
       "       [1.95553759e-03],\n",
       "       [1.27904250e-05],\n",
       "       [9.99991417e-01],\n",
       "       [7.48826074e-04],\n",
       "       [9.99988914e-01],\n",
       "       [9.95365024e-01],\n",
       "       [9.99986410e-01],\n",
       "       [9.99935746e-01],\n",
       "       [9.99738038e-01],\n",
       "       [3.94669296e-05],\n",
       "       [9.99980688e-01],\n",
       "       [1.12207767e-04],\n",
       "       [4.73836763e-03],\n",
       "       [1.39848108e-03],\n",
       "       [2.15180889e-02],\n",
       "       [9.99988675e-01],\n",
       "       [1.64582543e-02],\n",
       "       [9.99188006e-01],\n",
       "       [9.99777973e-01],\n",
       "       [9.99990940e-01],\n",
       "       [9.99665856e-01],\n",
       "       [3.13931996e-05],\n",
       "       [1.03475912e-04],\n",
       "       [9.99995112e-01],\n",
       "       [1.92122279e-05],\n",
       "       [1.94436434e-05],\n",
       "       [1.34400756e-03],\n",
       "       [9.99778092e-01],\n",
       "       [5.76497841e-05],\n",
       "       [7.43871351e-05],\n",
       "       [2.56262447e-05],\n",
       "       [7.56395821e-05],\n",
       "       [4.18812961e-05],\n",
       "       [2.22646398e-03],\n",
       "       [9.99914527e-01],\n",
       "       [8.07212491e-05],\n",
       "       [9.44656879e-03],\n",
       "       [9.99986887e-01],\n",
       "       [9.99929309e-01],\n",
       "       [9.46466267e-01],\n",
       "       [3.43652609e-05],\n",
       "       [9.99996543e-01],\n",
       "       [9.99966264e-01],\n",
       "       [9.99809206e-01],\n",
       "       [9.99350846e-01],\n",
       "       [9.98273134e-01],\n",
       "       [1.46491334e-01],\n",
       "       [9.99990940e-01],\n",
       "       [4.06108011e-05],\n",
       "       [1.50767609e-03],\n",
       "       [2.47857006e-05],\n",
       "       [1.43790758e-05],\n",
       "       [9.99969721e-01],\n",
       "       [9.97771502e-01],\n",
       "       [9.99420047e-01],\n",
       "       [9.37603712e-01],\n",
       "       [7.03625023e-01],\n",
       "       [7.68410554e-03],\n",
       "       [1.88609306e-03],\n",
       "       [1.50041567e-04],\n",
       "       [9.99992967e-01],\n",
       "       [5.05767483e-03],\n",
       "       [3.21870466e-04],\n",
       "       [9.99995470e-01],\n",
       "       [9.99754369e-01],\n",
       "       [9.90572631e-01],\n",
       "       [3.54881631e-05],\n",
       "       [1.29188632e-03],\n",
       "       [9.99913812e-01],\n",
       "       [2.36679427e-02],\n",
       "       [6.56055391e-01],\n",
       "       [4.59276140e-04],\n",
       "       [1.60180274e-02],\n",
       "       [7.41709722e-04],\n",
       "       [1.13774135e-04],\n",
       "       [1.14190421e-04],\n",
       "       [9.99634504e-01],\n",
       "       [1.83696188e-02],\n",
       "       [9.99996424e-01],\n",
       "       [9.99981284e-01],\n",
       "       [8.52520607e-05],\n",
       "       [2.23935203e-05],\n",
       "       [9.99972105e-01],\n",
       "       [2.67912183e-05],\n",
       "       [6.67126328e-02],\n",
       "       [3.73701960e-01],\n",
       "       [5.38662389e-05],\n",
       "       [9.99713480e-01],\n",
       "       [1.55643520e-05],\n",
       "       [1.47431478e-04],\n",
       "       [9.99988556e-01],\n",
       "       [8.90789262e-04],\n",
       "       [9.99989986e-01],\n",
       "       [9.99995947e-01],\n",
       "       [6.40554652e-02],\n",
       "       [2.45515548e-05],\n",
       "       [3.37182792e-05],\n",
       "       [1.00772515e-04],\n",
       "       [8.33071590e-06],\n",
       "       [9.99987960e-01],\n",
       "       [9.99983668e-01],\n",
       "       [2.94866809e-03],\n",
       "       [9.99982357e-01],\n",
       "       [6.50136571e-05],\n",
       "       [4.61252232e-04],\n",
       "       [4.18229429e-05],\n",
       "       [6.68232387e-05],\n",
       "       [4.07113439e-05],\n",
       "       [9.99986172e-01],\n",
       "       [2.75124592e-04],\n",
       "       [1.94206441e-05],\n",
       "       [9.99987960e-01],\n",
       "       [2.54991864e-05],\n",
       "       [1.06149324e-04],\n",
       "       [9.99969244e-01],\n",
       "       [2.16807057e-05],\n",
       "       [1.51819745e-02],\n",
       "       [1.38653768e-05],\n",
       "       [9.99989629e-01],\n",
       "       [9.93214965e-01],\n",
       "       [6.82508051e-01],\n",
       "       [8.52707028e-01],\n",
       "       [9.99977827e-01],\n",
       "       [4.98095453e-02],\n",
       "       [9.98344302e-01],\n",
       "       [7.41939526e-03],\n",
       "       [9.99792635e-01],\n",
       "       [9.95839834e-01],\n",
       "       [9.99177039e-01],\n",
       "       [9.38569382e-02],\n",
       "       [7.51320331e-04],\n",
       "       [1.06615312e-01],\n",
       "       [3.07226018e-03],\n",
       "       [5.93883917e-04],\n",
       "       [2.44386290e-04],\n",
       "       [2.06253920e-02],\n",
       "       [1.12244416e-05],\n",
       "       [1.02464357e-04],\n",
       "       [4.19998057e-02],\n",
       "       [9.99989629e-01],\n",
       "       [1.76682122e-04],\n",
       "       [6.62876468e-04],\n",
       "       [1.99848856e-03],\n",
       "       [4.90881689e-02],\n",
       "       [2.99751502e-03],\n",
       "       [7.46707810e-05],\n",
       "       [2.47384942e-05],\n",
       "       [9.99981403e-01],\n",
       "       [1.69205992e-03],\n",
       "       [4.88004833e-01],\n",
       "       [9.99994516e-01],\n",
       "       [2.90342523e-05],\n",
       "       [9.95392799e-01],\n",
       "       [1.79475686e-03],\n",
       "       [4.94766166e-04],\n",
       "       [6.12141751e-03],\n",
       "       [2.69984066e-05],\n",
       "       [4.01030644e-04],\n",
       "       [9.99928117e-01],\n",
       "       [3.63900072e-05],\n",
       "       [9.99992728e-01],\n",
       "       [3.73230189e-01],\n",
       "       [2.10541348e-05],\n",
       "       [9.99994397e-01],\n",
       "       [4.49224244e-05],\n",
       "       [9.99990582e-01],\n",
       "       [2.75008410e-04],\n",
       "       [1.24885846e-04],\n",
       "       [9.99989390e-01],\n",
       "       [5.49467222e-05],\n",
       "       [2.58552736e-05],\n",
       "       [9.99949455e-01],\n",
       "       [2.42855294e-05],\n",
       "       [8.51704826e-05],\n",
       "       [9.67943192e-01],\n",
       "       [9.99399662e-01],\n",
       "       [3.50791408e-04],\n",
       "       [1.75895672e-02],\n",
       "       [9.99991894e-01],\n",
       "       [9.99954820e-01],\n",
       "       [9.99802887e-01],\n",
       "       [7.29252119e-03],\n",
       "       [9.99497890e-01],\n",
       "       [3.42327684e-01],\n",
       "       [3.93314427e-03],\n",
       "       [5.71417477e-05],\n",
       "       [1.03275536e-03],\n",
       "       [1.87219633e-03],\n",
       "       [2.62583653e-05],\n",
       "       [4.82380204e-02],\n",
       "       [4.16212482e-04],\n",
       "       [2.19729063e-05],\n",
       "       [9.99989748e-01],\n",
       "       [9.99995351e-01],\n",
       "       [9.99992132e-01],\n",
       "       [7.31788095e-05],\n",
       "       [2.52128839e-01],\n",
       "       [9.37513337e-02],\n",
       "       [7.70806102e-04],\n",
       "       [9.99292254e-01],\n",
       "       [4.11118805e-01],\n",
       "       [3.22932174e-05],\n",
       "       [1.22647325e-04],\n",
       "       [1.73558685e-04],\n",
       "       [9.99672174e-01],\n",
       "       [7.23248595e-05],\n",
       "       [4.30229567e-02],\n",
       "       [4.52113563e-05],\n",
       "       [7.90921767e-05],\n",
       "       [1.13459408e-01],\n",
       "       [9.98819292e-01],\n",
       "       [1.10553077e-03],\n",
       "       [4.27869891e-05],\n",
       "       [1.80589326e-04],\n",
       "       [2.32184775e-05],\n",
       "       [9.99993324e-01],\n",
       "       [9.99979377e-01],\n",
       "       [7.32755601e-01],\n",
       "       [8.38335603e-02],\n",
       "       [1.66335321e-05],\n",
       "       [9.99191105e-01],\n",
       "       [9.99995470e-01],\n",
       "       [7.67982304e-01],\n",
       "       [9.53414261e-01],\n",
       "       [9.99961495e-01],\n",
       "       [8.82543344e-03],\n",
       "       [9.99988675e-01],\n",
       "       [2.31866981e-03],\n",
       "       [9.64537356e-03],\n",
       "       [6.45582855e-01],\n",
       "       [9.92862761e-01],\n",
       "       [9.99991536e-01],\n",
       "       [3.77709419e-02],\n",
       "       [9.77328091e-06],\n",
       "       [2.48527766e-04],\n",
       "       [4.11118805e-01],\n",
       "       [9.99991655e-01],\n",
       "       [1.39794656e-05],\n",
       "       [8.05697031e-03],\n",
       "       [9.99979973e-01],\n",
       "       [1.53895980e-05],\n",
       "       [9.99994159e-01],\n",
       "       [3.80930796e-05],\n",
       "       [1.21992758e-04],\n",
       "       [2.29392517e-05],\n",
       "       [9.99869585e-01],\n",
       "       [9.99952555e-01],\n",
       "       [6.64131003e-05],\n",
       "       [4.41054581e-05],\n",
       "       [9.96405363e-01],\n",
       "       [9.99988317e-01],\n",
       "       [7.35196471e-01],\n",
       "       [9.05458437e-05],\n",
       "       [3.76929017e-03],\n",
       "       [1.47750393e-01],\n",
       "       [1.19545897e-04],\n",
       "       [9.99994636e-01],\n",
       "       [6.47249937e-01],\n",
       "       [9.99995828e-01],\n",
       "       [9.99977946e-01],\n",
       "       [1.98617970e-04],\n",
       "       [1.67190877e-03],\n",
       "       [3.20038380e-05],\n",
       "       [9.99973059e-01],\n",
       "       [1.48209244e-01],\n",
       "       [7.59695292e-01],\n",
       "       [4.30664455e-04],\n",
       "       [4.84876521e-03],\n",
       "       [2.38658176e-04],\n",
       "       [2.74405847e-05],\n",
       "       [4.67995589e-04],\n",
       "       [1.76684465e-04],\n",
       "       [9.99513865e-01],\n",
       "       [1.00100944e-04],\n",
       "       [9.99992967e-01],\n",
       "       [9.99988914e-01],\n",
       "       [3.74597766e-05],\n",
       "       [7.53144205e-01],\n",
       "       [1.99821880e-04],\n",
       "       [5.64177644e-05],\n",
       "       [5.09575486e-01],\n",
       "       [9.98017550e-01],\n",
       "       [5.54248225e-03],\n",
       "       [7.07006606e-04],\n",
       "       [2.19472931e-05],\n",
       "       [2.62981688e-04],\n",
       "       [1.43149737e-05],\n",
       "       [9.99960780e-01],\n",
       "       [9.99902010e-01],\n",
       "       [9.99994874e-01],\n",
       "       [9.99230742e-01],\n",
       "       [7.99948201e-02],\n",
       "       [2.77974713e-03],\n",
       "       [3.13653363e-05],\n",
       "       [9.99300718e-01],\n",
       "       [9.99938250e-01],\n",
       "       [9.99995828e-01],\n",
       "       [1.82893255e-03],\n",
       "       [2.65847892e-03],\n",
       "       [6.09816889e-05],\n",
       "       [9.99996305e-01],\n",
       "       [9.99992132e-01],\n",
       "       [8.24053277e-05],\n",
       "       [5.71014285e-02],\n",
       "       [9.99979496e-01],\n",
       "       [2.24954085e-04],\n",
       "       [4.61822405e-04],\n",
       "       [9.99986887e-01],\n",
       "       [8.37695043e-05],\n",
       "       [7.96873719e-05],\n",
       "       [9.99929667e-01],\n",
       "       [3.56408894e-01],\n",
       "       [5.73636055e-01],\n",
       "       [9.99982357e-01],\n",
       "       [3.14428144e-05],\n",
       "       [4.32677589e-05],\n",
       "       [1.41646333e-05],\n",
       "       [2.91541146e-05],\n",
       "       [6.26163237e-05],\n",
       "       [9.99988556e-01],\n",
       "       [3.21374609e-05],\n",
       "       [9.87963080e-01],\n",
       "       [9.97616172e-01],\n",
       "       [1.84754818e-03],\n",
       "       [4.01965529e-01],\n",
       "       [1.69278701e-05],\n",
       "       [1.15433009e-04],\n",
       "       [9.99993682e-01],\n",
       "       [9.99986053e-01],\n",
       "       [2.36610460e-04],\n",
       "       [4.66159472e-05],\n",
       "       [8.76570848e-05],\n",
       "       [1.84399440e-04],\n",
       "       [9.99939561e-01],\n",
       "       [5.66168565e-05],\n",
       "       [9.99833107e-01],\n",
       "       [9.98743951e-01],\n",
       "       [8.51107299e-01],\n",
       "       [9.99395490e-01],\n",
       "       [2.09921658e-01],\n",
       "       [1.51660130e-03],\n",
       "       [3.23799613e-04],\n",
       "       [3.77970457e-01],\n",
       "       [7.25782096e-01],\n",
       "       [6.10688508e-01],\n",
       "       [1.83746568e-03],\n",
       "       [3.12004267e-04],\n",
       "       [2.38899265e-05],\n",
       "       [2.54414364e-04],\n",
       "       [4.03938890e-01],\n",
       "       [1.17478356e-01],\n",
       "       [2.38373384e-01],\n",
       "       [9.99989867e-01],\n",
       "       [9.99977469e-01],\n",
       "       [7.24946856e-01],\n",
       "       [9.99923468e-01],\n",
       "       [6.03713514e-03],\n",
       "       [1.04862382e-04],\n",
       "       [9.99954462e-01],\n",
       "       [8.42609070e-03],\n",
       "       [3.39295119e-02],\n",
       "       [3.18840772e-01],\n",
       "       [9.99300003e-01],\n",
       "       [1.59141891e-05],\n",
       "       [8.09664130e-01],\n",
       "       [9.98567581e-01],\n",
       "       [9.99917626e-01],\n",
       "       [9.99946117e-01],\n",
       "       [4.63332835e-04],\n",
       "       [6.97984244e-04],\n",
       "       [9.91456926e-01],\n",
       "       [1.98455709e-05],\n",
       "       [6.77819888e-04],\n",
       "       [9.80508387e-01],\n",
       "       [9.99862313e-01],\n",
       "       [9.93163764e-01],\n",
       "       [2.10809652e-04],\n",
       "       [3.03567867e-05],\n",
       "       [9.99556005e-01],\n",
       "       [1.01144113e-04],\n",
       "       [2.29377198e-04],\n",
       "       [3.44794971e-05],\n",
       "       [4.37550098e-01],\n",
       "       [9.99994755e-01],\n",
       "       [9.99959350e-01],\n",
       "       [8.13711807e-03],\n",
       "       [9.99856830e-01],\n",
       "       [9.99992371e-01],\n",
       "       [2.14950105e-05],\n",
       "       [9.99992967e-01],\n",
       "       [3.19249835e-03],\n",
       "       [9.98801470e-01],\n",
       "       [2.29182057e-02],\n",
       "       [4.21758770e-04],\n",
       "       [1.32342233e-04],\n",
       "       [3.86069078e-05],\n",
       "       [2.69378710e-04],\n",
       "       [3.54370277e-05],\n",
       "       [9.74297762e-01],\n",
       "       [1.21517442e-04],\n",
       "       [9.99994755e-01],\n",
       "       [2.52720609e-04],\n",
       "       [9.92467225e-01],\n",
       "       [1.86183497e-01],\n",
       "       [1.03108212e-03],\n",
       "       [3.00079373e-05],\n",
       "       [9.99986768e-01],\n",
       "       [3.55341210e-04],\n",
       "       [9.99988317e-01],\n",
       "       [4.10309464e-01],\n",
       "       [1.20488803e-04],\n",
       "       [6.01507910e-02],\n",
       "       [1.71379914e-04],\n",
       "       [1.25241908e-03],\n",
       "       [9.99992371e-01],\n",
       "       [1.95419434e-05],\n",
       "       [3.87891050e-05],\n",
       "       [2.82052271e-02],\n",
       "       [9.99995947e-01],\n",
       "       [1.23059889e-02],\n",
       "       [5.94112535e-05],\n",
       "       [9.99840140e-01],\n",
       "       [3.17194681e-05],\n",
       "       [2.40406676e-04],\n",
       "       [1.84895063e-04],\n",
       "       [2.72971895e-02],\n",
       "       [2.23348834e-04],\n",
       "       [4.69445765e-01],\n",
       "       [6.66095177e-04],\n",
       "       [8.60243395e-04],\n",
       "       [1.31175102e-05],\n",
       "       [9.78233516e-02],\n",
       "       [1.77154743e-05],\n",
       "       [9.99919415e-01],\n",
       "       [9.97744083e-01],\n",
       "       [6.49371231e-03],\n",
       "       [1.90013197e-05],\n",
       "       [9.41259641e-05],\n",
       "       [9.99979734e-01],\n",
       "       [9.97596920e-01],\n",
       "       [9.99980807e-01],\n",
       "       [1.82143121e-04],\n",
       "       [9.99871612e-01],\n",
       "       [2.33228799e-04],\n",
       "       [9.75100458e-01],\n",
       "       [9.99592841e-01],\n",
       "       [2.23249681e-05],\n",
       "       [9.99991655e-01],\n",
       "       [4.08159656e-04],\n",
       "       [9.99733269e-01],\n",
       "       [9.99979734e-01],\n",
       "       [2.31874481e-04],\n",
       "       [1.69357172e-05],\n",
       "       [9.91790175e-01],\n",
       "       [2.44702824e-05],\n",
       "       [8.79724622e-01],\n",
       "       [9.99996543e-01],\n",
       "       [4.20685083e-01],\n",
       "       [9.99749124e-01],\n",
       "       [4.04807568e-01],\n",
       "       [9.99987841e-01],\n",
       "       [9.99438226e-01],\n",
       "       [6.76557538e-04],\n",
       "       [2.29443704e-05],\n",
       "       [9.69092965e-01],\n",
       "       [3.22509040e-05],\n",
       "       [3.53821546e-01],\n",
       "       [9.99962449e-01],\n",
       "       [9.99822795e-01],\n",
       "       [9.99993920e-01],\n",
       "       [9.99948263e-01],\n",
       "       [3.69589537e-01],\n",
       "       [9.99486327e-01],\n",
       "       [1.83512457e-04],\n",
       "       [9.98866320e-01],\n",
       "       [9.98930752e-01],\n",
       "       [9.99963999e-01],\n",
       "       [4.69724509e-05],\n",
       "       [9.84697819e-01],\n",
       "       [9.99949217e-01],\n",
       "       [4.18821990e-04],\n",
       "       [5.28068235e-03],\n",
       "       [1.83746568e-03],\n",
       "       [3.84607643e-04],\n",
       "       [9.99417782e-01],\n",
       "       [9.99753296e-01],\n",
       "       [9.99995351e-01],\n",
       "       [1.18315378e-02],\n",
       "       [2.18505193e-05],\n",
       "       [2.49216282e-05],\n",
       "       [8.71723354e-01],\n",
       "       [1.71193050e-03],\n",
       "       [1.38568893e-01],\n",
       "       [9.99611437e-01],\n",
       "       [1.92757270e-05],\n",
       "       [1.83948800e-02],\n",
       "       [8.77196249e-03],\n",
       "       [1.81026454e-03],\n",
       "       [9.99927878e-01],\n",
       "       [1.23208694e-04],\n",
       "       [9.98597920e-01],\n",
       "       [8.23738461e-04],\n",
       "       [1.40873208e-05],\n",
       "       [6.66871347e-05],\n",
       "       [9.99995351e-01],\n",
       "       [9.98983562e-01],\n",
       "       [1.96062119e-05],\n",
       "       [6.13083899e-01],\n",
       "       [7.17928037e-02],\n",
       "       [2.32090042e-05],\n",
       "       [9.99981523e-01],\n",
       "       [1.09395456e-04],\n",
       "       [9.97963667e-01],\n",
       "       [6.82077289e-01],\n",
       "       [4.09823006e-05],\n",
       "       [9.12155211e-01],\n",
       "       [1.86812147e-01],\n",
       "       [2.09471662e-04],\n",
       "       [9.99538541e-01],\n",
       "       [1.62242595e-02],\n",
       "       [9.96877193e-01],\n",
       "       [9.99966025e-01],\n",
       "       [5.51442027e-01],\n",
       "       [1.94064365e-03],\n",
       "       [1.59141891e-05],\n",
       "       [5.28286874e-01],\n",
       "       [9.59120929e-01],\n",
       "       [9.99994159e-01],\n",
       "       [9.95928943e-01],\n",
       "       [1.57868534e-01],\n",
       "       [9.99957681e-01],\n",
       "       [2.52863407e-01],\n",
       "       [9.99981403e-01],\n",
       "       [2.52863407e-01],\n",
       "       [9.99991298e-01],\n",
       "       [2.01797448e-05],\n",
       "       [2.26268079e-03],\n",
       "       [2.30033729e-05],\n",
       "       [9.99992132e-01],\n",
       "       [8.89694202e-04],\n",
       "       [5.32285558e-05],\n",
       "       [3.50462724e-05],\n",
       "       [9.63304119e-05],\n",
       "       [3.79449339e-05],\n",
       "       [8.65384136e-05],\n",
       "       [2.80890577e-02],\n",
       "       [1.24600119e-04],\n",
       "       [1.82002332e-04],\n",
       "       [9.98248219e-01],\n",
       "       [1.06460205e-03],\n",
       "       [2.90899596e-04],\n",
       "       [7.60858602e-05],\n",
       "       [1.78619430e-05],\n",
       "       [8.64631459e-02],\n",
       "       [9.99853730e-01],\n",
       "       [2.18184025e-04],\n",
       "       [1.54949856e-04],\n",
       "       [6.23562895e-02],\n",
       "       [9.99525189e-01],\n",
       "       [9.99986887e-01],\n",
       "       [5.43291426e-05],\n",
       "       [3.68135043e-05],\n",
       "       [3.59233200e-05],\n",
       "       [9.36622473e-06],\n",
       "       [9.99977946e-01],\n",
       "       [1.78619430e-05],\n",
       "       [1.64569472e-03],\n",
       "       [9.93071020e-01],\n",
       "       [9.99991059e-01],\n",
       "       [9.99992967e-01],\n",
       "       [9.99974966e-01],\n",
       "       [9.99973059e-01],\n",
       "       [4.06145591e-05],\n",
       "       [3.14251549e-04],\n",
       "       [1.56967081e-02],\n",
       "       [9.99361694e-01],\n",
       "       [9.99994993e-01],\n",
       "       [9.75404441e-01],\n",
       "       [9.05956200e-04],\n",
       "       [9.99711215e-01],\n",
       "       [9.56691384e-01],\n",
       "       [1.70042549e-05],\n",
       "       [2.17497909e-05],\n",
       "       [1.45406916e-03],\n",
       "       [3.96974268e-04],\n",
       "       [1.85631270e-05],\n",
       "       [4.19617107e-04],\n",
       "       [5.30443311e-01],\n",
       "       [9.99989510e-01],\n",
       "       [3.30795992e-05],\n",
       "       [9.99989867e-01],\n",
       "       [9.98637259e-01],\n",
       "       [2.98535675e-02],\n",
       "       [5.99252852e-03],\n",
       "       [9.59288001e-01],\n",
       "       [7.35405028e-01],\n",
       "       [6.11818850e-01],\n",
       "       [3.56521705e-05]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_pred_probs = model_4.predict(val_sentences)\n",
    "model_4_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
    "model_4_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.59055118110236,\n",
       " 'precision': 0.7557293707913207,\n",
       " 'recall': 0.7559055118110236,\n",
       " 'f1': 0.7547819586377322}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results = calculate_results(y_true=val_labels,y_pred=model_4_preds)\n",
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Convolutional Neural Networks for Text (and other types of sequences)\n",
    "\n",
    "# We've used CNNs for images but images are typically 2D (height x width)... however, our text data is 1D.\n",
    "\n",
    "# Previously we've Conv2D for our image data but now we're going to use Conv1D.\n",
    "\n",
    "# The typical structure of a Conv1D model for sequences (in our case, text):\n",
    "\n",
    "# Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + pooling) -> outputs (class probabilities)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test out our embedding layer, Conv1D layer and max pooling\n",
    "\n",
    "embedding_test = embedding(text_vectorizer([\"this is a test sentence\"])) # turn target sequence into embedding\n",
    "conv_1d = tf.keras.layers.Conv1D(\n",
    "    filters=32,\n",
    "    kernel_size=5, # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
    "    activation=\"relu\",\n",
    "    padding=\"valid\"\n",
    ")\n",
    "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
    "max_pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \" get the feature with the highest value\"\n",
    "\n",
    "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
       "array([[[ 0.07367054,  0.11108577,  0.00069269, ..., -0.03596745,\n",
       "          0.04444727, -0.13694549],\n",
       "        [ 0.05598606,  0.05986897,  0.0436979 , ..., -0.07888574,\n",
       "          0.10396568, -0.11010505],\n",
       "        [ 0.09476115,  0.04155506, -0.03025755, ...,  0.10387169,\n",
       "         -0.09707789, -0.15093976],\n",
       "        ...,\n",
       "        [ 0.00758438,  0.02895361, -0.02393353, ...,  0.02125376,\n",
       "          0.02975926, -0.02440886],\n",
       "        [ 0.00758438,  0.02895361, -0.02393353, ...,  0.02125376,\n",
       "          0.02975926, -0.02440886],\n",
       "        [ 0.00758438,  0.02895361, -0.02393353, ...,  0.02125376,\n",
       "          0.02975926, -0.02440886]]], dtype=float32)>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
       "array([[[0.        , 0.        , 0.09550638, 0.        , 0.02521508,\n",
       "         0.07790277, 0.        , 0.00646562, 0.        , 0.06835645,\n",
       "         0.04034573, 0.09944518, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.06421302, 0.2850657 , 0.14311747,\n",
       "         0.        , 0.        , 0.08383233, 0.        , 0.14884904,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.13724537,\n",
       "         0.        , 0.01046613],\n",
       "        [0.        , 0.07177566, 0.01552044, 0.02833056, 0.        ,\n",
       "         0.13845006, 0.        , 0.10976503, 0.        , 0.06670243,\n",
       "         0.25861138, 0.        , 0.05047034, 0.        , 0.10392712,\n",
       "         0.        , 0.12180031, 0.        , 0.14432274, 0.25519305,\n",
       "         0.05765767, 0.21100582, 0.        , 0.10528903, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.13026097,\n",
       "         0.15853177, 0.        ],\n",
       "        [0.        , 0.        , 0.02646   , 0.01827931, 0.04245848,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.11186205, 0.        , 0.02250822, 0.03457043, 0.        ,\n",
       "         0.17195867, 0.0405653 , 0.        , 0.17483583, 0.        ,\n",
       "         0.10705525, 0.        , 0.        , 0.2512191 , 0.16068609,\n",
       "         0.02249219, 0.        , 0.02435349, 0.13212682, 0.        ,\n",
       "         0.08456421, 0.        ],\n",
       "        [0.        , 0.09488524, 0.        , 0.06123795, 0.07179818,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.2388422 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06662659, 0.02424839, 0.04520029, 0.07635925,\n",
       "         0.        , 0.        , 0.0274096 , 0.        , 0.09805631,\n",
       "         0.        , 0.        , 0.        , 0.13985011, 0.02585405,\n",
       "         0.19477013, 0.03069972],\n",
       "        [0.        , 0.12047786, 0.06104432, 0.08751666, 0.10508244,\n",
       "         0.00980086, 0.07140935, 0.        , 0.        , 0.        ,\n",
       "         0.03395895, 0.00573676, 0.01253812, 0.        , 0.        ,\n",
       "         0.05567152, 0.01202829, 0.        , 0.09260903, 0.04942352,\n",
       "         0.        , 0.        , 0.01863349, 0.02872843, 0.11400043,\n",
       "         0.        , 0.        , 0.        , 0.07106782, 0.05791591,\n",
       "         0.06064733, 0.06555618],\n",
       "        [0.        , 0.08228144, 0.04386004, 0.0575986 , 0.04555933,\n",
       "         0.03765444, 0.        , 0.        , 0.        , 0.01805396,\n",
       "         0.01035756, 0.04502701, 0.        , 0.        , 0.        ,\n",
       "         0.04911045, 0.08211678, 0.        , 0.11629224, 0.0910868 ,\n",
       "         0.        , 0.        , 0.        , 0.06032003, 0.07208708,\n",
       "         0.        , 0.        , 0.        , 0.10104815, 0.05345964,\n",
       "         0.045796  , 0.05972394],\n",
       "        [0.        , 0.08228144, 0.04386004, 0.0575986 , 0.04555933,\n",
       "         0.03765444, 0.        , 0.        , 0.        , 0.01805396,\n",
       "         0.01035756, 0.04502701, 0.        , 0.        , 0.        ,\n",
       "         0.04911045, 0.08211678, 0.        , 0.11629224, 0.0910868 ,\n",
       "         0.        , 0.        , 0.        , 0.06032003, 0.07208708,\n",
       "         0.        , 0.        , 0.        , 0.10104815, 0.05345964,\n",
       "         0.045796  , 0.05972394],\n",
       "        [0.        , 0.08228144, 0.04386004, 0.0575986 , 0.04555933,\n",
       "         0.03765444, 0.        , 0.        , 0.        , 0.01805396,\n",
       "         0.01035756, 0.04502701, 0.        , 0.        , 0.        ,\n",
       "         0.04911045, 0.08211678, 0.        , 0.11629224, 0.0910868 ,\n",
       "         0.        , 0.        , 0.        , 0.06032003, 0.07208708,\n",
       "         0.        , 0.        , 0.        , 0.10104815, 0.05345964,\n",
       "         0.045796  , 0.05972394],\n",
       "        [0.        , 0.08228144, 0.04386004, 0.0575986 , 0.04555933,\n",
       "         0.03765444, 0.        , 0.        , 0.        , 0.01805396,\n",
       "         0.01035756, 0.04502701, 0.        , 0.        , 0.        ,\n",
       "         0.04911045, 0.08211678, 0.        , 0.11629224, 0.0910868 ,\n",
       "         0.        , 0.        , 0.        , 0.06032003, 0.07208708,\n",
       "         0.        , 0.        , 0.        , 0.10104815, 0.05345964,\n",
       "         0.045796  , 0.05972394],\n",
       "        [0.        , 0.08228144, 0.04386004, 0.0575986 , 0.04555933,\n",
       "         0.03765444, 0.        , 0.        , 0.        , 0.01805396,\n",
       "         0.01035756, 0.04502701, 0.        , 0.        , 0.        ,\n",
       "         0.04911045, 0.08211678, 0.        , 0.11629224, 0.0910868 ,\n",
       "         0.        , 0.        , 0.        , 0.06032003, 0.07208708,\n",
       "         0.        , 0.        , 0.        , 0.10104815, 0.05345964,\n",
       "         0.045796  , 0.05972394],\n",
       "        [0.        , 0.08228144, 0.04386004, 0.0575986 , 0.04555933,\n",
       "         0.03765444, 0.        , 0.        , 0.        , 0.01805396,\n",
       "         0.01035756, 0.04502701, 0.        , 0.        , 0.        ,\n",
       "         0.04911045, 0.08211678, 0.        , 0.11629224, 0.0910868 ,\n",
       "         0.        , 0.        , 0.        , 0.06032003, 0.07208708,\n",
       "         0.        , 0.        , 0.        , 0.10104815, 0.05345964,\n",
       "         0.045796  , 0.05972394]]], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_1d_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 32), dtype=float32, numpy=\n",
       "array([[0.        , 0.12047786, 0.09550638, 0.08751666, 0.10508244,\n",
       "        0.13845006, 0.07140935, 0.10976503, 0.        , 0.06835645,\n",
       "        0.25861138, 0.09944518, 0.05047034, 0.03457043, 0.10392712,\n",
       "        0.17195867, 0.12180031, 0.06421302, 0.2850657 , 0.25519305,\n",
       "        0.10705525, 0.21100582, 0.08383233, 0.2512191 , 0.16068609,\n",
       "        0.02249219, 0.        , 0.02435349, 0.13985011, 0.13724537,\n",
       "        0.19477013, 0.06555618]], dtype=float32)>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pool_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(1,),dtype=tf.string)\n",
    "\n",
    "x = text_vectorizer(inputs)\n",
    "\n",
    "x = embedding(x)\n",
    "\n",
    "x = tf.keras.layers.Conv1D(filters=64,kernel_size=5,strides=1,activation=\"relu\",padding=\"valid\")(x)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "\n",
    "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/model_5_Conv1D/20220808-174414\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 4s 11ms/step - loss: 0.0823 - accuracy: 0.9727 - val_loss: 1.2165 - val_accuracy: 0.7375\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 17ms/step - loss: 0.0421 - accuracy: 0.9820 - val_loss: 1.4069 - val_accuracy: 0.7388\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.0395 - accuracy: 0.9818 - val_loss: 1.5515 - val_accuracy: 0.7415\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 3s 16ms/step - loss: 0.0362 - accuracy: 0.9829 - val_loss: 1.6558 - val_accuracy: 0.7349\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 2s 10ms/step - loss: 0.0348 - accuracy: 0.9831 - val_loss: 1.6841 - val_accuracy: 0.7507\n"
     ]
    }
   ],
   "source": [
    "model_5.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_model_5 = model_5.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences,val_labels),\n",
    "    callbacks = [create_tensorboard_callback(\n",
    "        dir_name=SAVE_DIR,\n",
    "        experiment_name=\"model_5_Conv1D\"\n",
    "    )]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.11905712e-01],\n",
       "       [7.42173851e-01],\n",
       "       [9.97375607e-01],\n",
       "       [1.20791174e-01],\n",
       "       [7.57184103e-02],\n",
       "       [9.16151464e-01],\n",
       "       [9.00730133e-01],\n",
       "       [9.92912948e-01],\n",
       "       [9.62242067e-01],\n",
       "       [2.63721406e-01],\n",
       "       [1.06967926e-01],\n",
       "       [6.74977005e-01],\n",
       "       [4.07397114e-02],\n",
       "       [2.01902509e-01],\n",
       "       [5.10357926e-03],\n",
       "       [1.15431644e-01],\n",
       "       [2.75212284e-02],\n",
       "       [7.12292641e-02],\n",
       "       [2.12650701e-01],\n",
       "       [4.72143531e-01],\n",
       "       [9.15862679e-01],\n",
       "       [3.75207402e-02],\n",
       "       [4.34702009e-01],\n",
       "       [6.85269907e-02],\n",
       "       [9.48652446e-01],\n",
       "       [9.98817861e-01],\n",
       "       [3.44959572e-02],\n",
       "       [5.64120561e-02],\n",
       "       [2.46519651e-02],\n",
       "       [2.17437938e-01],\n",
       "       [5.30524790e-01],\n",
       "       [2.58478701e-01],\n",
       "       [4.35751975e-01],\n",
       "       [1.82447672e-01],\n",
       "       [4.50340033e-01],\n",
       "       [7.23960921e-02],\n",
       "       [9.93427634e-01],\n",
       "       [1.54751897e-01],\n",
       "       [3.07736155e-02],\n",
       "       [9.98232961e-01],\n",
       "       [1.80658951e-01],\n",
       "       [1.20671764e-02],\n",
       "       [3.08234274e-01],\n",
       "       [4.55341972e-02],\n",
       "       [6.12730324e-01],\n",
       "       [9.82418001e-01],\n",
       "       [2.61457741e-01],\n",
       "       [9.32122052e-01],\n",
       "       [1.81359932e-01],\n",
       "       [6.06837928e-01],\n",
       "       [6.76125959e-02],\n",
       "       [4.70954746e-01],\n",
       "       [4.54999626e-01],\n",
       "       [2.61959843e-02],\n",
       "       [1.22133590e-01],\n",
       "       [3.48091945e-02],\n",
       "       [2.13991433e-01],\n",
       "       [9.54254627e-01],\n",
       "       [7.10489899e-02],\n",
       "       [2.69357208e-03],\n",
       "       [1.39417902e-01],\n",
       "       [9.53103602e-01],\n",
       "       [8.85720253e-01],\n",
       "       [1.34700939e-01],\n",
       "       [9.10393536e-01],\n",
       "       [9.75589335e-01],\n",
       "       [7.40505397e-01],\n",
       "       [3.06843787e-01],\n",
       "       [1.34418622e-01],\n",
       "       [1.39662385e-01],\n",
       "       [6.40597865e-02],\n",
       "       [3.62997465e-02],\n",
       "       [9.26729798e-01],\n",
       "       [1.49524420e-01],\n",
       "       [1.06592424e-01],\n",
       "       [3.75570625e-01],\n",
       "       [3.70419532e-01],\n",
       "       [7.91805446e-01],\n",
       "       [2.29054004e-01],\n",
       "       [5.61527848e-01],\n",
       "       [4.11789656e-01],\n",
       "       [2.39648983e-01],\n",
       "       [9.95121896e-01],\n",
       "       [9.47271064e-02],\n",
       "       [1.26801640e-01],\n",
       "       [8.72553959e-02],\n",
       "       [1.88897587e-02],\n",
       "       [9.93731469e-02],\n",
       "       [5.64226210e-01],\n",
       "       [8.93573046e-01],\n",
       "       [9.91631687e-01],\n",
       "       [5.76614821e-03],\n",
       "       [5.64065933e-01],\n",
       "       [1.95267871e-02],\n",
       "       [9.82122779e-01],\n",
       "       [7.47577667e-01],\n",
       "       [8.41637850e-01],\n",
       "       [9.64114070e-01],\n",
       "       [8.58145893e-01],\n",
       "       [9.52237129e-01],\n",
       "       [9.99326110e-01],\n",
       "       [1.82552844e-01],\n",
       "       [1.19464546e-02],\n",
       "       [9.08654630e-01],\n",
       "       [8.80308270e-01],\n",
       "       [8.56386274e-02],\n",
       "       [8.43794227e-01],\n",
       "       [9.75713968e-01],\n",
       "       [3.69919725e-02],\n",
       "       [3.72027934e-01],\n",
       "       [6.96905017e-01],\n",
       "       [3.37291621e-02],\n",
       "       [2.66690046e-01],\n",
       "       [1.30773559e-01],\n",
       "       [1.45772889e-01],\n",
       "       [3.32818180e-01],\n",
       "       [4.05806571e-01],\n",
       "       [6.70130849e-01],\n",
       "       [6.67889178e-01],\n",
       "       [7.46402219e-02],\n",
       "       [9.99534249e-01],\n",
       "       [5.94416820e-02],\n",
       "       [1.03421286e-01],\n",
       "       [7.43414819e-01],\n",
       "       [3.54523212e-01],\n",
       "       [2.71743953e-01],\n",
       "       [8.33773136e-01],\n",
       "       [8.10573623e-03],\n",
       "       [6.50958046e-02],\n",
       "       [7.93219626e-01],\n",
       "       [9.19502750e-02],\n",
       "       [9.99534249e-01],\n",
       "       [9.99814212e-01],\n",
       "       [9.98817861e-01],\n",
       "       [9.81257081e-01],\n",
       "       [6.97480664e-02],\n",
       "       [9.68344986e-01],\n",
       "       [1.74709663e-01],\n",
       "       [2.19437003e-01],\n",
       "       [8.15728530e-02],\n",
       "       [9.96079981e-01],\n",
       "       [2.99913436e-01],\n",
       "       [2.01902509e-01],\n",
       "       [9.53696191e-01],\n",
       "       [2.62188107e-01],\n",
       "       [5.19638896e-01],\n",
       "       [3.75315920e-02],\n",
       "       [6.98642293e-03],\n",
       "       [2.25846559e-01],\n",
       "       [9.79417264e-01],\n",
       "       [2.14547545e-01],\n",
       "       [7.80167580e-02],\n",
       "       [4.06602979e-01],\n",
       "       [1.52177319e-01],\n",
       "       [2.33797178e-01],\n",
       "       [9.88871992e-01],\n",
       "       [6.93322301e-01],\n",
       "       [3.89930129e-01],\n",
       "       [9.83354628e-01],\n",
       "       [1.69537533e-02],\n",
       "       [9.65034962e-01],\n",
       "       [5.63931912e-02],\n",
       "       [2.59264529e-01],\n",
       "       [9.90891874e-01],\n",
       "       [2.09180832e-01],\n",
       "       [5.28227165e-02],\n",
       "       [9.98427391e-01],\n",
       "       [3.16765606e-01],\n",
       "       [9.83325601e-01],\n",
       "       [2.29243934e-01],\n",
       "       [9.92789090e-01],\n",
       "       [8.37501049e-01],\n",
       "       [8.23061824e-01],\n",
       "       [2.39887554e-02],\n",
       "       [9.97670710e-01],\n",
       "       [6.21492080e-02],\n",
       "       [3.65977556e-01],\n",
       "       [3.66211623e-01],\n",
       "       [7.06132472e-01],\n",
       "       [9.93228912e-01],\n",
       "       [1.77201312e-02],\n",
       "       [8.66017401e-01],\n",
       "       [7.40550578e-01],\n",
       "       [9.65813935e-01],\n",
       "       [9.67135787e-01],\n",
       "       [3.57028574e-01],\n",
       "       [9.42786783e-02],\n",
       "       [9.99601781e-01],\n",
       "       [1.29326833e-02],\n",
       "       [2.42131576e-02],\n",
       "       [8.03234652e-02],\n",
       "       [9.04368341e-01],\n",
       "       [6.28086329e-02],\n",
       "       [1.87143788e-01],\n",
       "       [1.41448919e-02],\n",
       "       [6.80931807e-02],\n",
       "       [3.65569107e-02],\n",
       "       [2.19130039e-01],\n",
       "       [7.53703237e-01],\n",
       "       [6.43317923e-02],\n",
       "       [3.08962673e-01],\n",
       "       [8.75239253e-01],\n",
       "       [9.61087346e-01],\n",
       "       [3.19260240e-01],\n",
       "       [8.84022191e-02],\n",
       "       [9.99810636e-01],\n",
       "       [6.05261207e-01],\n",
       "       [9.22600031e-01],\n",
       "       [6.64683342e-01],\n",
       "       [8.38819265e-01],\n",
       "       [2.96041638e-01],\n",
       "       [9.80134904e-01],\n",
       "       [1.84854064e-02],\n",
       "       [1.96550280e-01],\n",
       "       [8.85244086e-03],\n",
       "       [4.34291176e-03],\n",
       "       [9.41173613e-01],\n",
       "       [7.80173421e-01],\n",
       "       [8.67644906e-01],\n",
       "       [1.95697024e-01],\n",
       "       [7.09095240e-01],\n",
       "       [7.74789974e-02],\n",
       "       [2.87169721e-02],\n",
       "       [1.35025740e-01],\n",
       "       [9.83105600e-01],\n",
       "       [1.62431762e-01],\n",
       "       [4.29357320e-01],\n",
       "       [9.94482934e-01],\n",
       "       [5.64927518e-01],\n",
       "       [6.27297938e-01],\n",
       "       [8.30388516e-02],\n",
       "       [1.83421925e-01],\n",
       "       [7.67227232e-01],\n",
       "       [2.50049263e-01],\n",
       "       [5.36937237e-01],\n",
       "       [1.50473610e-01],\n",
       "       [5.36535621e-01],\n",
       "       [3.38278770e-01],\n",
       "       [1.12755492e-01],\n",
       "       [7.77324066e-02],\n",
       "       [3.70384336e-01],\n",
       "       [2.12456778e-01],\n",
       "       [9.99853730e-01],\n",
       "       [9.87229884e-01],\n",
       "       [5.21492325e-02],\n",
       "       [1.77168120e-02],\n",
       "       [8.77569973e-01],\n",
       "       [9.20431390e-02],\n",
       "       [1.01514645e-01],\n",
       "       [3.57995868e-01],\n",
       "       [4.41798605e-02],\n",
       "       [5.48465252e-01],\n",
       "       [6.78314245e-04],\n",
       "       [4.14414734e-01],\n",
       "       [9.24378753e-01],\n",
       "       [2.31045306e-01],\n",
       "       [9.61844802e-01],\n",
       "       [9.98828113e-01],\n",
       "       [2.89649755e-01],\n",
       "       [1.40054554e-01],\n",
       "       [2.72314429e-01],\n",
       "       [2.53903270e-02],\n",
       "       [3.30288056e-03],\n",
       "       [9.83965516e-01],\n",
       "       [9.70360339e-01],\n",
       "       [6.18829608e-01],\n",
       "       [9.51979697e-01],\n",
       "       [5.12528904e-02],\n",
       "       [1.54226378e-01],\n",
       "       [6.80983718e-03],\n",
       "       [1.31480694e-01],\n",
       "       [3.80616821e-02],\n",
       "       [9.66330886e-01],\n",
       "       [9.27935317e-02],\n",
       "       [6.87165791e-03],\n",
       "       [9.73075867e-01],\n",
       "       [1.27994027e-02],\n",
       "       [1.03224494e-01],\n",
       "       [9.84210610e-01],\n",
       "       [3.84152308e-02],\n",
       "       [7.83749223e-02],\n",
       "       [6.50042854e-03],\n",
       "       [9.66780782e-01],\n",
       "       [6.18774951e-01],\n",
       "       [7.19379246e-01],\n",
       "       [6.59486234e-01],\n",
       "       [5.67851961e-01],\n",
       "       [5.57049289e-02],\n",
       "       [9.46212292e-01],\n",
       "       [3.37821953e-02],\n",
       "       [7.68786967e-01],\n",
       "       [4.10315901e-01],\n",
       "       [3.44880193e-01],\n",
       "       [3.09402704e-01],\n",
       "       [1.55200228e-01],\n",
       "       [7.50054359e-01],\n",
       "       [1.91084951e-01],\n",
       "       [6.06986403e-01],\n",
       "       [1.53290719e-01],\n",
       "       [7.18033671e-01],\n",
       "       [3.17825601e-02],\n",
       "       [7.66597018e-02],\n",
       "       [2.13269532e-01],\n",
       "       [9.83762980e-01],\n",
       "       [1.54346868e-01],\n",
       "       [9.64938626e-02],\n",
       "       [3.35154027e-01],\n",
       "       [2.17383265e-01],\n",
       "       [1.17577054e-01],\n",
       "       [2.61327326e-02],\n",
       "       [2.67150048e-02],\n",
       "       [9.80719864e-01],\n",
       "       [3.38001817e-01],\n",
       "       [2.74027467e-01],\n",
       "       [9.99710023e-01],\n",
       "       [5.36568165e-02],\n",
       "       [5.89089394e-01],\n",
       "       [2.22168639e-01],\n",
       "       [4.27552834e-02],\n",
       "       [1.70657188e-01],\n",
       "       [1.40707344e-01],\n",
       "       [1.07342154e-01],\n",
       "       [9.07418132e-01],\n",
       "       [2.25311637e-01],\n",
       "       [9.84472454e-01],\n",
       "       [8.64730477e-02],\n",
       "       [1.67618357e-02],\n",
       "       [9.94384408e-01],\n",
       "       [2.20395345e-02],\n",
       "       [9.96014595e-01],\n",
       "       [1.35472640e-01],\n",
       "       [3.97353843e-02],\n",
       "       [9.63444054e-01],\n",
       "       [3.53852175e-02],\n",
       "       [2.64842715e-02],\n",
       "       [9.81216133e-01],\n",
       "       [4.56176605e-03],\n",
       "       [1.72281042e-01],\n",
       "       [7.57576346e-01],\n",
       "       [9.12349939e-01],\n",
       "       [4.38294420e-03],\n",
       "       [1.70163900e-01],\n",
       "       [9.82513607e-01],\n",
       "       [9.58335400e-01],\n",
       "       [7.44940102e-01],\n",
       "       [3.99303734e-01],\n",
       "       [5.32058179e-01],\n",
       "       [4.09555286e-01],\n",
       "       [5.30493073e-02],\n",
       "       [8.15310404e-02],\n",
       "       [9.84341055e-02],\n",
       "       [6.48867369e-01],\n",
       "       [2.92790700e-02],\n",
       "       [3.64161700e-01],\n",
       "       [3.72397661e-01],\n",
       "       [9.90340672e-03],\n",
       "       [9.67640817e-01],\n",
       "       [9.98817861e-01],\n",
       "       [9.94075537e-01],\n",
       "       [3.15637849e-02],\n",
       "       [3.32400769e-01],\n",
       "       [1.06097661e-01],\n",
       "       [3.41733962e-01],\n",
       "       [7.48676538e-01],\n",
       "       [2.30484575e-01],\n",
       "       [1.48261664e-02],\n",
       "       [5.96709289e-02],\n",
       "       [5.02527729e-02],\n",
       "       [5.24385691e-01],\n",
       "       [1.08028864e-02],\n",
       "       [2.02230096e-01],\n",
       "       [4.30907607e-02],\n",
       "       [3.00879717e-01],\n",
       "       [3.84203255e-01],\n",
       "       [3.67013842e-01],\n",
       "       [1.82156488e-01],\n",
       "       [4.38481160e-02],\n",
       "       [3.88848037e-01],\n",
       "       [6.09925874e-02],\n",
       "       [9.96594608e-01],\n",
       "       [9.17135358e-01],\n",
       "       [4.45562661e-01],\n",
       "       [6.10640705e-01],\n",
       "       [1.72936842e-02],\n",
       "       [4.96841550e-01],\n",
       "       [9.89249587e-01],\n",
       "       [6.61329269e-01],\n",
       "       [1.62930384e-01],\n",
       "       [9.78101015e-01],\n",
       "       [1.89084083e-01],\n",
       "       [9.36332464e-01],\n",
       "       [3.18398863e-01],\n",
       "       [2.36493982e-02],\n",
       "       [5.15988290e-01],\n",
       "       [4.34452921e-01],\n",
       "       [9.95357573e-01],\n",
       "       [1.10742301e-01],\n",
       "       [3.66957337e-02],\n",
       "       [5.93857132e-02],\n",
       "       [2.30484575e-01],\n",
       "       [9.98774230e-01],\n",
       "       [2.37222090e-02],\n",
       "       [6.57259166e-01],\n",
       "       [9.74334717e-01],\n",
       "       [6.41145408e-02],\n",
       "       [9.99534249e-01],\n",
       "       [2.64268368e-02],\n",
       "       [3.27814668e-01],\n",
       "       [3.88220698e-02],\n",
       "       [7.57169902e-01],\n",
       "       [8.87751281e-01],\n",
       "       [5.64933866e-02],\n",
       "       [1.64864236e-03],\n",
       "       [2.41070792e-01],\n",
       "       [9.88574386e-01],\n",
       "       [8.11006129e-01],\n",
       "       [1.15134224e-01],\n",
       "       [3.88212740e-01],\n",
       "       [6.59549057e-01],\n",
       "       [2.46431381e-02],\n",
       "       [9.90890086e-01],\n",
       "       [4.10251021e-01],\n",
       "       [9.98634756e-01],\n",
       "       [9.07584071e-01],\n",
       "       [9.42109376e-02],\n",
       "       [3.69611770e-01],\n",
       "       [1.00803547e-01],\n",
       "       [9.16747868e-01],\n",
       "       [7.14974403e-01],\n",
       "       [3.44533652e-01],\n",
       "       [3.27849388e-02],\n",
       "       [2.63844550e-01],\n",
       "       [3.56038064e-02],\n",
       "       [6.46206811e-02],\n",
       "       [1.22961923e-01],\n",
       "       [3.17642331e-01],\n",
       "       [4.95614111e-01],\n",
       "       [1.23272978e-01],\n",
       "       [9.99078631e-01],\n",
       "       [9.83993769e-01],\n",
       "       [2.27502480e-01],\n",
       "       [7.42173851e-01],\n",
       "       [1.81154206e-01],\n",
       "       [3.19051370e-02],\n",
       "       [3.09117079e-01],\n",
       "       [6.11729085e-01],\n",
       "       [1.14546590e-01],\n",
       "       [1.92401335e-01],\n",
       "       [1.74771119e-02],\n",
       "       [4.16955143e-01],\n",
       "       [2.13947031e-03],\n",
       "       [9.29872930e-01],\n",
       "       [9.71287489e-01],\n",
       "       [9.92468655e-01],\n",
       "       [9.68128204e-01],\n",
       "       [7.42806911e-01],\n",
       "       [1.51418850e-01],\n",
       "       [5.13412952e-02],\n",
       "       [6.37125731e-01],\n",
       "       [8.81735802e-01],\n",
       "       [9.98028815e-01],\n",
       "       [2.82186130e-03],\n",
       "       [1.12262830e-01],\n",
       "       [1.13627903e-01],\n",
       "       [9.98718858e-01],\n",
       "       [9.99167204e-01],\n",
       "       [2.13445529e-01],\n",
       "       [9.54633579e-02],\n",
       "       [9.96257663e-01],\n",
       "       [5.08569740e-02],\n",
       "       [3.44527900e-01],\n",
       "       [9.81700838e-01],\n",
       "       [9.78165343e-02],\n",
       "       [3.77999917e-02],\n",
       "       [9.32800293e-01],\n",
       "       [2.91367799e-01],\n",
       "       [3.72437775e-01],\n",
       "       [9.61499810e-01],\n",
       "       [1.40265971e-02],\n",
       "       [4.38837633e-02],\n",
       "       [9.78642143e-03],\n",
       "       [1.71487499e-02],\n",
       "       [9.03586671e-02],\n",
       "       [9.69531894e-01],\n",
       "       [1.88401453e-02],\n",
       "       [4.02753532e-01],\n",
       "       [4.20718938e-01],\n",
       "       [7.09431618e-02],\n",
       "       [2.52256721e-01],\n",
       "       [7.90261924e-02],\n",
       "       [2.97800362e-01],\n",
       "       [9.97166455e-01],\n",
       "       [5.77582419e-01],\n",
       "       [1.14332378e-01],\n",
       "       [1.20444410e-01],\n",
       "       [1.35727599e-01],\n",
       "       [5.94127513e-02],\n",
       "       [6.77394867e-01],\n",
       "       [2.00477038e-02],\n",
       "       [8.83352160e-01],\n",
       "       [7.59478152e-01],\n",
       "       [5.36021173e-01],\n",
       "       [6.46197081e-01],\n",
       "       [7.43132114e-01],\n",
       "       [9.87673700e-02],\n",
       "       [2.78004169e-01],\n",
       "       [3.89032990e-01],\n",
       "       [9.25983250e-01],\n",
       "       [2.01944977e-01],\n",
       "       [2.26243481e-01],\n",
       "       [3.66078943e-01],\n",
       "       [1.02210641e-02],\n",
       "       [1.04664288e-01],\n",
       "       [3.03965986e-01],\n",
       "       [7.48323858e-01],\n",
       "       [1.30396083e-01],\n",
       "       [9.86820996e-01],\n",
       "       [9.09130991e-01],\n",
       "       [7.47577667e-01],\n",
       "       [9.80380118e-01],\n",
       "       [1.49026439e-01],\n",
       "       [6.32441118e-02],\n",
       "       [8.93209636e-01],\n",
       "       [1.64569825e-01],\n",
       "       [2.17932258e-02],\n",
       "       [9.48063657e-02],\n",
       "       [1.12889275e-01],\n",
       "       [1.08653889e-03],\n",
       "       [7.71280527e-01],\n",
       "       [7.76558936e-01],\n",
       "       [8.06789100e-01],\n",
       "       [9.24704432e-01],\n",
       "       [8.14303830e-02],\n",
       "       [1.46597549e-01],\n",
       "       [7.05431998e-01],\n",
       "       [1.39997695e-02],\n",
       "       [2.62141824e-01],\n",
       "       [1.44259959e-01],\n",
       "       [6.49184942e-01],\n",
       "       [5.14173687e-01],\n",
       "       [4.39439155e-02],\n",
       "       [4.96393107e-02],\n",
       "       [4.65909749e-01],\n",
       "       [1.07401483e-01],\n",
       "       [1.21974446e-01],\n",
       "       [1.06442347e-01],\n",
       "       [1.78845793e-01],\n",
       "       [9.98389602e-01],\n",
       "       [9.74400580e-01],\n",
       "       [3.19590837e-01],\n",
       "       [8.30729544e-01],\n",
       "       [9.87448633e-01],\n",
       "       [8.86882539e-04],\n",
       "       [9.59372818e-01],\n",
       "       [2.26290971e-01],\n",
       "       [4.26582694e-01],\n",
       "       [2.51392365e-01],\n",
       "       [8.72976258e-02],\n",
       "       [1.10727929e-01],\n",
       "       [2.54073869e-02],\n",
       "       [7.95739815e-02],\n",
       "       [7.81556368e-02],\n",
       "       [7.13872671e-01],\n",
       "       [2.37793043e-01],\n",
       "       [9.92359102e-01],\n",
       "       [3.94986011e-02],\n",
       "       [6.27619147e-01],\n",
       "       [4.89806265e-01],\n",
       "       [1.54613694e-02],\n",
       "       [5.50757982e-02],\n",
       "       [9.69164014e-01],\n",
       "       [6.47582710e-01],\n",
       "       [9.54786241e-01],\n",
       "       [2.66759753e-01],\n",
       "       [8.70949849e-02],\n",
       "       [3.90819728e-01],\n",
       "       [2.69785672e-01],\n",
       "       [2.89432585e-01],\n",
       "       [9.87448633e-01],\n",
       "       [1.18363714e-02],\n",
       "       [4.05802280e-02],\n",
       "       [1.28274828e-01],\n",
       "       [9.96285915e-01],\n",
       "       [1.80379853e-01],\n",
       "       [4.85167764e-02],\n",
       "       [7.20421910e-01],\n",
       "       [4.24844213e-02],\n",
       "       [3.09014730e-02],\n",
       "       [1.44955859e-01],\n",
       "       [2.00628251e-01],\n",
       "       [1.16102792e-01],\n",
       "       [2.96472400e-01],\n",
       "       [2.73540050e-01],\n",
       "       [1.84401095e-01],\n",
       "       [6.23244308e-02],\n",
       "       [3.20588499e-01],\n",
       "       [1.54225687e-02],\n",
       "       [9.25119400e-01],\n",
       "       [7.82124639e-01],\n",
       "       [4.79980856e-01],\n",
       "       [2.45634727e-02],\n",
       "       [2.13279761e-02],\n",
       "       [9.79203820e-01],\n",
       "       [6.87114656e-01],\n",
       "       [9.99400377e-01],\n",
       "       [2.13125199e-01],\n",
       "       [8.40177298e-01],\n",
       "       [1.06552586e-01],\n",
       "       [5.40927708e-01],\n",
       "       [6.96832299e-01],\n",
       "       [1.82039179e-02],\n",
       "       [9.73096192e-01],\n",
       "       [9.95174274e-02],\n",
       "       [4.96212780e-01],\n",
       "       [9.97783363e-01],\n",
       "       [1.58602834e-01],\n",
       "       [2.74526253e-02],\n",
       "       [2.59210587e-01],\n",
       "       [1.15299979e-02],\n",
       "       [4.25671935e-01],\n",
       "       [9.99810636e-01],\n",
       "       [2.46241078e-01],\n",
       "       [9.33052242e-01],\n",
       "       [2.05775589e-01],\n",
       "       [7.82442629e-01],\n",
       "       [2.44481668e-01],\n",
       "       [2.29202852e-01],\n",
       "       [1.57090910e-02],\n",
       "       [5.86629093e-01],\n",
       "       [1.49078490e-02],\n",
       "       [2.17427254e-01],\n",
       "       [9.42910910e-01],\n",
       "       [9.48067546e-01],\n",
       "       [9.93824601e-01],\n",
       "       [7.18931317e-01],\n",
       "       [4.10352275e-02],\n",
       "       [2.66894966e-01],\n",
       "       [9.71999951e-03],\n",
       "       [4.56868649e-01],\n",
       "       [3.44494015e-01],\n",
       "       [8.94907892e-01],\n",
       "       [3.79417837e-02],\n",
       "       [7.09386647e-01],\n",
       "       [7.78857768e-01],\n",
       "       [2.20101759e-01],\n",
       "       [1.97254792e-01],\n",
       "       [2.26243481e-01],\n",
       "       [1.45625591e-01],\n",
       "       [4.04369891e-01],\n",
       "       [6.68560266e-01],\n",
       "       [9.97915566e-01],\n",
       "       [8.14630762e-02],\n",
       "       [7.44091999e-03],\n",
       "       [1.68858543e-02],\n",
       "       [2.63233781e-01],\n",
       "       [1.72005847e-01],\n",
       "       [2.47797109e-02],\n",
       "       [7.94635355e-01],\n",
       "       [8.73136148e-02],\n",
       "       [1.56859711e-01],\n",
       "       [2.20885813e-01],\n",
       "       [2.15219125e-01],\n",
       "       [9.18917954e-01],\n",
       "       [1.29765034e-01],\n",
       "       [4.05952126e-01],\n",
       "       [2.90992677e-01],\n",
       "       [9.85442940e-03],\n",
       "       [1.00710511e-01],\n",
       "       [9.99632478e-01],\n",
       "       [7.95703530e-01],\n",
       "       [3.57830594e-03],\n",
       "       [3.25353861e-01],\n",
       "       [1.55990511e-01],\n",
       "       [5.20571843e-02],\n",
       "       [8.58039975e-01],\n",
       "       [4.52256203e-01],\n",
       "       [5.72476447e-01],\n",
       "       [2.97025561e-01],\n",
       "       [2.05765575e-01],\n",
       "       [6.04357839e-01],\n",
       "       [1.43430188e-01],\n",
       "       [4.34146151e-02],\n",
       "       [8.69245887e-01],\n",
       "       [1.56126842e-01],\n",
       "       [3.54231834e-01],\n",
       "       [9.76653755e-01],\n",
       "       [3.09478670e-01],\n",
       "       [3.66878569e-01],\n",
       "       [1.08653889e-03],\n",
       "       [2.90964335e-01],\n",
       "       [7.95059085e-01],\n",
       "       [9.99534249e-01],\n",
       "       [6.50987148e-01],\n",
       "       [3.94648984e-02],\n",
       "       [9.85505164e-01],\n",
       "       [3.16452861e-01],\n",
       "       [8.75649452e-01],\n",
       "       [3.16452861e-01],\n",
       "       [9.94218826e-01],\n",
       "       [8.17354862e-03],\n",
       "       [3.95027339e-01],\n",
       "       [7.44374990e-02],\n",
       "       [9.64437068e-01],\n",
       "       [1.99139744e-01],\n",
       "       [4.04034257e-01],\n",
       "       [5.31682894e-02],\n",
       "       [2.80949652e-01],\n",
       "       [9.64651778e-02],\n",
       "       [2.22183056e-02],\n",
       "       [2.13154063e-01],\n",
       "       [6.90810010e-02],\n",
       "       [8.78692716e-02],\n",
       "       [7.78561950e-01],\n",
       "       [2.29794346e-02],\n",
       "       [1.08779900e-01],\n",
       "       [2.95449682e-02],\n",
       "       [1.03172166e-02],\n",
       "       [1.39089495e-01],\n",
       "       [5.74773490e-01],\n",
       "       [6.56161457e-02],\n",
       "       [5.27375579e-01],\n",
       "       [1.29776433e-01],\n",
       "       [2.73850858e-01],\n",
       "       [8.81064296e-01],\n",
       "       [1.38281077e-01],\n",
       "       [3.28391157e-02],\n",
       "       [5.48203215e-02],\n",
       "       [4.35738126e-03],\n",
       "       [9.84830976e-01],\n",
       "       [1.03172166e-02],\n",
       "       [3.19617420e-01],\n",
       "       [9.90045011e-01],\n",
       "       [9.93191779e-01],\n",
       "       [9.97327328e-01],\n",
       "       [9.99871492e-01],\n",
       "       [9.99462306e-01],\n",
       "       [1.47459850e-01],\n",
       "       [8.65434781e-02],\n",
       "       [2.54927784e-01],\n",
       "       [4.58541453e-01],\n",
       "       [9.96203125e-01],\n",
       "       [4.49177921e-01],\n",
       "       [2.06420600e-01],\n",
       "       [4.89605665e-01],\n",
       "       [6.76355958e-01],\n",
       "       [2.62890905e-02],\n",
       "       [5.29123237e-03],\n",
       "       [8.29639211e-02],\n",
       "       [2.96707362e-01],\n",
       "       [6.22539455e-03],\n",
       "       [7.80164897e-02],\n",
       "       [4.55385834e-01],\n",
       "       [9.83589053e-01],\n",
       "       [1.93802342e-02],\n",
       "       [9.10488665e-01],\n",
       "       [7.24332035e-01],\n",
       "       [7.51225799e-02],\n",
       "       [3.19138676e-01],\n",
       "       [1.16676211e-01],\n",
       "       [7.53189206e-01],\n",
       "       [4.48827863e-01],\n",
       "       [1.02734445e-02]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_pred_probs = model_5.predict(val_sentences)\n",
    "model_1_pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
    "model_5_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 75.06561679790026,\n",
       " 'precision': 0.7515411879249408,\n",
       " 'recall': 0.7506561679790026,\n",
       " 'f1': 0.7485335105470684}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = calculate_results(y_true=val_labels,y_pred=model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"There's a flood in my street!\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[-0.01157032  0.02485909  0.02878048 -0.01271501  0.03971539  0.0882776\n",
      "  0.02680985  0.05589837 -0.0106873  -0.00597291  0.00639325 -0.0181952\n",
      "  0.00030816  0.09105889  0.05874643 -0.03180627  0.01512473 -0.05162929\n",
      "  0.00991365 -0.06865346 -0.04209305  0.02678981  0.03011008  0.00321067\n",
      " -0.0033797  -0.04787361  0.02266722 -0.00985925 -0.04063613 -0.0129209\n",
      " -0.04666385  0.056303   -0.03949255  0.00517688  0.02495828 -0.07014443\n",
      "  0.02871508  0.04947681 -0.00633976 -0.08960193  0.02807116 -0.00808363\n",
      " -0.01360604  0.0599865  -0.10361787 -0.05195372  0.00232956 -0.02332528\n",
      " -0.03758106  0.03327731], shape=(50,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
    "\n",
    "# Now we've built a few of our own models, let's try and use transfer learning for NLP,\n",
    "# specifically using TensorFlow Hub' Universal Sentence Encoder\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
    "\n",
    "embed_samples = embed([\n",
    "    sample_sentence,\n",
    "    \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"\n",
    "    ])\n",
    "\n",
    "print(embed_samples[0][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([512])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras layer using the USE pretrained layer from tensorflow hub\n",
    "\n",
    "sentence_encoder_layer = hub.KerasLayer(\n",
    "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
    "    input_shape=[],\n",
    "    dtype=tf.string,\n",
    "    trainable=False,\n",
    "    name=\"USE\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model using the Sequential API\n",
    "\n",
    "model_6 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "],name=\"mode_6_USE\")\n",
    "\n",
    "model_6.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mode_6_USE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " USE (KerasLayer)            (None, 512)               256797824 \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                32832     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 256,830,721\n",
      "Trainable params: 32,897\n",
      "Non-trainable params: 256,797,824\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20220808-192438\n",
      "Epoch 1/5\n",
      "215/215 [==============================] - 6s 22ms/step - loss: 0.5063 - accuracy: 0.7818 - val_loss: 0.4501 - val_accuracy: 0.7913\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 4s 18ms/step - loss: 0.4151 - accuracy: 0.8151 - val_loss: 0.4391 - val_accuracy: 0.8005\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.4016 - accuracy: 0.8228 - val_loss: 0.4349 - val_accuracy: 0.8110\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 4s 20ms/step - loss: 0.3933 - accuracy: 0.8273 - val_loss: 0.4321 - val_accuracy: 0.8136\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 5s 21ms/step - loss: 0.3864 - accuracy: 0.8288 - val_loss: 0.4337 - val_accuracy: 0.8163\n"
     ]
    }
   ],
   "source": [
    "model_6_history = model_6.fit(\n",
    "    train_sentences,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    validation_data=(val_sentences, val_labels),\n",
    "    callbacks =[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"tf_hub_sentence_encoder\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 18ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.15593371],\n",
       "       [0.7408709 ],\n",
       "       [0.9867578 ],\n",
       "       [0.19132991],\n",
       "       [0.77111936],\n",
       "       [0.73485774],\n",
       "       [0.97936183],\n",
       "       [0.9762175 ],\n",
       "       [0.9144001 ],\n",
       "       [0.09634778]], dtype=float32)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_pred_probs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.818446310697231,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8148082644367335}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results = calculate_results(y_true=val_labels,y_pred=model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6851"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model 7: TF Hub Pretrained USE but with 10% of training data\n",
    "\n",
    "# Transfer learning really helps when you don't have a large dataset.\n",
    "\n",
    "# To see how our model performs on a smaller dataset, let's replicate 'model_6' except we'll \n",
    "# train it on 10% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 761)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create subsets of 10% of the training data\n",
    "\n",
    "#train_10_percent = train_df_shuffled[[\"text\",\"target\"]].sample(frac=0.1,random_state=42)\n",
    "\n",
    "#train_sentences_10_percent = train_10_percent[\"text\"].to_list()\n",
    "#train_labels_10_percent    = train_10_percent[\"target\"].to_list()\n",
    "\n",
    "#len(train_sentences_10_percent), len(train_labels_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    413\n",
       "1    348\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data\n",
    "\n",
    "#train_10_percent[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20220808-194516\n",
      "Epoch 1/5\n",
      "24/24 [==============================] - 4s 77ms/step - loss: 0.6716 - accuracy: 0.6767 - val_loss: 0.6310 - val_accuracy: 0.7887\n",
      "Epoch 2/5\n",
      "24/24 [==============================] - 1s 42ms/step - loss: 0.5990 - accuracy: 0.7950 - val_loss: 0.5531 - val_accuracy: 0.8071\n",
      "Epoch 3/5\n",
      "24/24 [==============================] - 1s 40ms/step - loss: 0.5230 - accuracy: 0.8029 - val_loss: 0.4857 - val_accuracy: 0.8097\n",
      "Epoch 4/5\n",
      "24/24 [==============================] - 1s 43ms/step - loss: 0.4680 - accuracy: 0.8055 - val_loss: 0.4402 - val_accuracy: 0.8123\n",
      "Epoch 5/5\n",
      "24/24 [==============================] - 1s 37ms/step - loss: 0.4300 - accuracy: 0.8160 - val_loss: 0.4107 - val_accuracy: 0.8255\n"
     ]
    }
   ],
   "source": [
    "#model_7 = tf.keras.Sequential([\n",
    " #   sentence_encoder_layer,\n",
    "  #  tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "   # tf.keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "#])\n",
    "\n",
    "#model_7.compile(\n",
    " #   loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "  #  optimizer = tf.keras.optimizers.Adam(),\n",
    "   # metrics = [\"accuracy\"]\n",
    "#)\n",
    "\n",
    "#model_7_history = model_7.fit(\n",
    " #   train_sentences_10_percent,\n",
    "  #  train_labels_10_percent,\n",
    "   # epochs=5,\n",
    "    #validation_data=(val_sentences,val_labels),\n",
    "    #callbacks=[create_tensorboard_callback(\n",
    "     #   SAVE_DIR,\n",
    "      #  \"tf_hub_sentence_encoder_10_percent\"\n",
    "    #)]\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 17ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.2510033 ],\n",
       "       [0.8022451 ],\n",
       "       [0.90634525],\n",
       "       [0.33314672],\n",
       "       [0.7929546 ],\n",
       "       [0.8407144 ],\n",
       "       [0.90049875],\n",
       "       [0.9392289 ],\n",
       "       [0.8372308 ],\n",
       "       [0.081063  ],\n",
       "       [0.5018459 ],\n",
       "       [0.4234976 ],\n",
       "       [0.24910183],\n",
       "       [0.4506158 ],\n",
       "       [0.3506243 ],\n",
       "       [0.1318565 ],\n",
       "       [0.19119449],\n",
       "       [0.4418502 ],\n",
       "       [0.57918555],\n",
       "       [0.5420447 ],\n",
       "       [0.73903364],\n",
       "       [0.270529  ],\n",
       "       [0.63477534],\n",
       "       [0.25711897],\n",
       "       [0.7721224 ],\n",
       "       [0.8874032 ],\n",
       "       [0.17224544],\n",
       "       [0.2683001 ],\n",
       "       [0.17891893],\n",
       "       [0.28846258],\n",
       "       [0.5960932 ],\n",
       "       [0.6737712 ],\n",
       "       [0.43229657],\n",
       "       [0.6381244 ],\n",
       "       [0.5828526 ],\n",
       "       [0.08218466],\n",
       "       [0.9032388 ],\n",
       "       [0.12574236],\n",
       "       [0.2500454 ],\n",
       "       [0.9017818 ],\n",
       "       [0.350417  ],\n",
       "       [0.2943647 ],\n",
       "       [0.5491191 ],\n",
       "       [0.520558  ],\n",
       "       [0.2490406 ],\n",
       "       [0.76337945],\n",
       "       [0.21473747],\n",
       "       [0.87850666],\n",
       "       [0.43356994],\n",
       "       [0.8581842 ],\n",
       "       [0.10762195],\n",
       "       [0.69963896],\n",
       "       [0.20157872],\n",
       "       [0.10477329],\n",
       "       [0.19651335],\n",
       "       [0.10151847],\n",
       "       [0.214613  ],\n",
       "       [0.8390718 ],\n",
       "       [0.31033167],\n",
       "       [0.13544773],\n",
       "       [0.06761571],\n",
       "       [0.9062011 ],\n",
       "       [0.91729575],\n",
       "       [0.30493045],\n",
       "       [0.84315413],\n",
       "       [0.82265323],\n",
       "       [0.56979716],\n",
       "       [0.29796705],\n",
       "       [0.12009895],\n",
       "       [0.6842046 ],\n",
       "       [0.1118487 ],\n",
       "       [0.1280165 ],\n",
       "       [0.70744246],\n",
       "       [0.14833729],\n",
       "       [0.09204794],\n",
       "       [0.7168783 ],\n",
       "       [0.14082004],\n",
       "       [0.51270014],\n",
       "       [0.13587652],\n",
       "       [0.7379436 ],\n",
       "       [0.5485075 ],\n",
       "       [0.61319464],\n",
       "       [0.8674996 ],\n",
       "       [0.14076136],\n",
       "       [0.5847109 ],\n",
       "       [0.7335563 ],\n",
       "       [0.16064402],\n",
       "       [0.18879771],\n",
       "       [0.92756784],\n",
       "       [0.7587755 ],\n",
       "       [0.93019754],\n",
       "       [0.15216005],\n",
       "       [0.12018461],\n",
       "       [0.13494146],\n",
       "       [0.88554937],\n",
       "       [0.7707801 ],\n",
       "       [0.88179106],\n",
       "       [0.8070865 ],\n",
       "       [0.87317926],\n",
       "       [0.8473917 ],\n",
       "       [0.85022587],\n",
       "       [0.21469936],\n",
       "       [0.09757605],\n",
       "       [0.9028363 ],\n",
       "       [0.874811  ],\n",
       "       [0.0534009 ],\n",
       "       [0.7614071 ],\n",
       "       [0.82620555],\n",
       "       [0.23313351],\n",
       "       [0.67208755],\n",
       "       [0.45691043],\n",
       "       [0.2216149 ],\n",
       "       [0.29651827],\n",
       "       [0.4176795 ],\n",
       "       [0.5434645 ],\n",
       "       [0.3264791 ],\n",
       "       [0.48102763],\n",
       "       [0.43048355],\n",
       "       [0.745368  ],\n",
       "       [0.74595296],\n",
       "       [0.9074486 ],\n",
       "       [0.3755745 ],\n",
       "       [0.70973885],\n",
       "       [0.809253  ],\n",
       "       [0.64342576],\n",
       "       [0.40037477],\n",
       "       [0.19926892],\n",
       "       [0.3504999 ],\n",
       "       [0.19165084],\n",
       "       [0.31252164],\n",
       "       [0.25295776],\n",
       "       [0.9179946 ],\n",
       "       [0.8742993 ],\n",
       "       [0.89430255],\n",
       "       [0.7324999 ],\n",
       "       [0.4804287 ],\n",
       "       [0.8364513 ],\n",
       "       [0.33706212],\n",
       "       [0.34944978],\n",
       "       [0.17833944],\n",
       "       [0.92098534],\n",
       "       [0.2249424 ],\n",
       "       [0.4453146 ],\n",
       "       [0.6460293 ],\n",
       "       [0.37377176],\n",
       "       [0.27678832],\n",
       "       [0.06967422],\n",
       "       [0.16868277],\n",
       "       [0.33109424],\n",
       "       [0.9044371 ],\n",
       "       [0.47841942],\n",
       "       [0.10852236],\n",
       "       [0.39360473],\n",
       "       [0.13789804],\n",
       "       [0.19974628],\n",
       "       [0.78659356],\n",
       "       [0.49832004],\n",
       "       [0.25098503],\n",
       "       [0.8401588 ],\n",
       "       [0.2647369 ],\n",
       "       [0.7889785 ],\n",
       "       [0.23084012],\n",
       "       [0.14443888],\n",
       "       [0.904579  ],\n",
       "       [0.312496  ],\n",
       "       [0.27288488],\n",
       "       [0.940425  ],\n",
       "       [0.35090858],\n",
       "       [0.8973815 ],\n",
       "       [0.15946275],\n",
       "       [0.85973674],\n",
       "       [0.75956315],\n",
       "       [0.8833648 ],\n",
       "       [0.16143966],\n",
       "       [0.8885694 ],\n",
       "       [0.09958709],\n",
       "       [0.8770317 ],\n",
       "       [0.68037593],\n",
       "       [0.6618056 ],\n",
       "       [0.93527585],\n",
       "       [0.11361762],\n",
       "       [0.82688814],\n",
       "       [0.5197191 ],\n",
       "       [0.80884683],\n",
       "       [0.71602815],\n",
       "       [0.24284597],\n",
       "       [0.3189808 ],\n",
       "       [0.85481125],\n",
       "       [0.6614761 ],\n",
       "       [0.34807763],\n",
       "       [0.28511387],\n",
       "       [0.8634595 ],\n",
       "       [0.615713  ],\n",
       "       [0.4324178 ],\n",
       "       [0.25298455],\n",
       "       [0.24639125],\n",
       "       [0.1575596 ],\n",
       "       [0.48968932],\n",
       "       [0.3953086 ],\n",
       "       [0.1781803 ],\n",
       "       [0.19078177],\n",
       "       [0.8446405 ],\n",
       "       [0.7890966 ],\n",
       "       [0.15411161],\n",
       "       [0.24060151],\n",
       "       [0.91885304],\n",
       "       [0.21977551],\n",
       "       [0.67042136],\n",
       "       [0.8990298 ],\n",
       "       [0.7032074 ],\n",
       "       [0.10026882],\n",
       "       [0.84074426],\n",
       "       [0.10129631],\n",
       "       [0.2571602 ],\n",
       "       [0.14296728],\n",
       "       [0.13017847],\n",
       "       [0.81174904],\n",
       "       [0.74579155],\n",
       "       [0.6770964 ],\n",
       "       [0.07590052],\n",
       "       [0.6727467 ],\n",
       "       [0.21326226],\n",
       "       [0.12982075],\n",
       "       [0.2027353 ],\n",
       "       [0.92657685],\n",
       "       [0.3082239 ],\n",
       "       [0.38747233],\n",
       "       [0.8657999 ],\n",
       "       [0.70354563],\n",
       "       [0.5229587 ],\n",
       "       [0.7452975 ],\n",
       "       [0.29969028],\n",
       "       [0.8396015 ],\n",
       "       [0.1136809 ],\n",
       "       [0.6061246 ],\n",
       "       [0.4266495 ],\n",
       "       [0.5336513 ],\n",
       "       [0.43506318],\n",
       "       [0.88097453],\n",
       "       [0.0955851 ],\n",
       "       [0.3614369 ],\n",
       "       [0.5409684 ],\n",
       "       [0.8875043 ],\n",
       "       [0.8387405 ],\n",
       "       [0.17583263],\n",
       "       [0.30512407],\n",
       "       [0.6135754 ],\n",
       "       [0.12900066],\n",
       "       [0.16409287],\n",
       "       [0.76639366],\n",
       "       [0.2771816 ],\n",
       "       [0.67585343],\n",
       "       [0.13298236],\n",
       "       [0.5873552 ],\n",
       "       [0.7499106 ],\n",
       "       [0.17998192],\n",
       "       [0.7954549 ],\n",
       "       [0.9373633 ],\n",
       "       [0.17405424],\n",
       "       [0.23092899],\n",
       "       [0.7872318 ],\n",
       "       [0.2364132 ],\n",
       "       [0.31431296],\n",
       "       [0.90198517],\n",
       "       [0.69601303],\n",
       "       [0.7271329 ],\n",
       "       [0.8143949 ],\n",
       "       [0.17776524],\n",
       "       [0.31642348],\n",
       "       [0.08552286],\n",
       "       [0.32174915],\n",
       "       [0.31469086],\n",
       "       [0.8312993 ],\n",
       "       [0.13212013],\n",
       "       [0.47952002],\n",
       "       [0.8317373 ],\n",
       "       [0.44774154],\n",
       "       [0.09310216],\n",
       "       [0.9152787 ],\n",
       "       [0.4756562 ],\n",
       "       [0.13726687],\n",
       "       [0.26497748],\n",
       "       [0.8745385 ],\n",
       "       [0.37879583],\n",
       "       [0.14281818],\n",
       "       [0.63486975],\n",
       "       [0.486538  ],\n",
       "       [0.14570329],\n",
       "       [0.71159786],\n",
       "       [0.28616676],\n",
       "       [0.67288613],\n",
       "       [0.43910977],\n",
       "       [0.3594676 ],\n",
       "       [0.7951968 ],\n",
       "       [0.27855018],\n",
       "       [0.8386604 ],\n",
       "       [0.43578768],\n",
       "       [0.8799919 ],\n",
       "       [0.09097754],\n",
       "       [0.55826336],\n",
       "       [0.63678944],\n",
       "       [0.2303752 ],\n",
       "       [0.25924447],\n",
       "       [0.73083633],\n",
       "       [0.31118795],\n",
       "       [0.21783513],\n",
       "       [0.35489178],\n",
       "       [0.43136257],\n",
       "       [0.25550285],\n",
       "       [0.08637072],\n",
       "       [0.24642539],\n",
       "       [0.627769  ],\n",
       "       [0.6075841 ],\n",
       "       [0.3302932 ],\n",
       "       [0.9186974 ],\n",
       "       [0.13158216],\n",
       "       [0.8786014 ],\n",
       "       [0.44797692],\n",
       "       [0.15543315],\n",
       "       [0.3056495 ],\n",
       "       [0.18348494],\n",
       "       [0.12327331],\n",
       "       [0.8571871 ],\n",
       "       [0.10113814],\n",
       "       [0.58207726],\n",
       "       [0.2292989 ],\n",
       "       [0.23983593],\n",
       "       [0.87191933],\n",
       "       [0.14206298],\n",
       "       [0.88098586],\n",
       "       [0.6648656 ],\n",
       "       [0.08115926],\n",
       "       [0.838432  ],\n",
       "       [0.37448114],\n",
       "       [0.15984747],\n",
       "       [0.8006497 ],\n",
       "       [0.11793011],\n",
       "       [0.60358346],\n",
       "       [0.5619991 ],\n",
       "       [0.45160946],\n",
       "       [0.15368806],\n",
       "       [0.23378998],\n",
       "       [0.8052748 ],\n",
       "       [0.8708611 ],\n",
       "       [0.6342955 ],\n",
       "       [0.3523642 ],\n",
       "       [0.19745508],\n",
       "       [0.20490006],\n",
       "       [0.07508085],\n",
       "       [0.27085856],\n",
       "       [0.3106445 ],\n",
       "       [0.43188938],\n",
       "       [0.19049811],\n",
       "       [0.46979758],\n",
       "       [0.4680043 ],\n",
       "       [0.11915601],\n",
       "       [0.8875797 ],\n",
       "       [0.8845479 ],\n",
       "       [0.8764256 ],\n",
       "       [0.39367792],\n",
       "       [0.7102851 ],\n",
       "       [0.2687315 ],\n",
       "       [0.755105  ],\n",
       "       [0.4848426 ],\n",
       "       [0.63576126],\n",
       "       [0.13437009],\n",
       "       [0.21951248],\n",
       "       [0.18735684],\n",
       "       [0.21506794],\n",
       "       [0.12214479],\n",
       "       [0.634843  ],\n",
       "       [0.10407348],\n",
       "       [0.15852666],\n",
       "       [0.40701228],\n",
       "       [0.11750111],\n",
       "       [0.2090175 ],\n",
       "       [0.19435494],\n",
       "       [0.3836199 ],\n",
       "       [0.19241561],\n",
       "       [0.59949476],\n",
       "       [0.9162243 ],\n",
       "       [0.48299184],\n",
       "       [0.10786097],\n",
       "       [0.4730309 ],\n",
       "       [0.3105495 ],\n",
       "       [0.87775   ],\n",
       "       [0.4920474 ],\n",
       "       [0.192723  ],\n",
       "       [0.9340025 ],\n",
       "       [0.3359019 ],\n",
       "       [0.32778126],\n",
       "       [0.22191612],\n",
       "       [0.07493632],\n",
       "       [0.6877098 ],\n",
       "       [0.6828256 ],\n",
       "       [0.91309744],\n",
       "       [0.12525597],\n",
       "       [0.5653212 ],\n",
       "       [0.4058289 ],\n",
       "       [0.63575286],\n",
       "       [0.8944836 ],\n",
       "       [0.19609015],\n",
       "       [0.63367647],\n",
       "       [0.76772827],\n",
       "       [0.43021998],\n",
       "       [0.91884094],\n",
       "       [0.5242509 ],\n",
       "       [0.5221264 ],\n",
       "       [0.24009417],\n",
       "       [0.3114905 ],\n",
       "       [0.7732944 ],\n",
       "       [0.12901239],\n",
       "       [0.2989058 ],\n",
       "       [0.3921605 ],\n",
       "       [0.8578007 ],\n",
       "       [0.7880701 ],\n",
       "       [0.58369106],\n",
       "       [0.8874739 ],\n",
       "       [0.22300467],\n",
       "       [0.16125508],\n",
       "       [0.86144316],\n",
       "       [0.7638262 ],\n",
       "       [0.7643305 ],\n",
       "       [0.84419316],\n",
       "       [0.1298381 ],\n",
       "       [0.7272647 ],\n",
       "       [0.10874093],\n",
       "       [0.8666419 ],\n",
       "       [0.27675784],\n",
       "       [0.8107876 ],\n",
       "       [0.06058794],\n",
       "       [0.13460122],\n",
       "       [0.11748738],\n",
       "       [0.57919264],\n",
       "       [0.27244374],\n",
       "       [0.41202176],\n",
       "       [0.2788248 ],\n",
       "       [0.56393015],\n",
       "       [0.83079475],\n",
       "       [0.71126896],\n",
       "       [0.5795957 ],\n",
       "       [0.7948114 ],\n",
       "       [0.28404462],\n",
       "       [0.2309405 ],\n",
       "       [0.18117902],\n",
       "       [0.8570168 ],\n",
       "       [0.24542914],\n",
       "       [0.11314142],\n",
       "       [0.25021607],\n",
       "       [0.25559437],\n",
       "       [0.16876096],\n",
       "       [0.8466364 ],\n",
       "       [0.812012  ],\n",
       "       [0.7716192 ],\n",
       "       [0.91716266],\n",
       "       [0.92102313],\n",
       "       [0.14096425],\n",
       "       [0.38356578],\n",
       "       [0.52169806],\n",
       "       [0.86399794],\n",
       "       [0.9120327 ],\n",
       "       [0.1052561 ],\n",
       "       [0.2871548 ],\n",
       "       [0.58347756],\n",
       "       [0.92682594],\n",
       "       [0.87851626],\n",
       "       [0.16856755],\n",
       "       [0.14432669],\n",
       "       [0.8031703 ],\n",
       "       [0.116754  ],\n",
       "       [0.15825197],\n",
       "       [0.88147277],\n",
       "       [0.56761837],\n",
       "       [0.39737916],\n",
       "       [0.47018087],\n",
       "       [0.787127  ],\n",
       "       [0.830809  ],\n",
       "       [0.9271307 ],\n",
       "       [0.10407539],\n",
       "       [0.12540986],\n",
       "       [0.44183227],\n",
       "       [0.24714994],\n",
       "       [0.2479253 ],\n",
       "       [0.82094145],\n",
       "       [0.06370333],\n",
       "       [0.6460738 ],\n",
       "       [0.3620126 ],\n",
       "       [0.12181157],\n",
       "       [0.4939588 ],\n",
       "       [0.28879085],\n",
       "       [0.40941066],\n",
       "       [0.89104307],\n",
       "       [0.38051736],\n",
       "       [0.22841081],\n",
       "       [0.23365821],\n",
       "       [0.20079647],\n",
       "       [0.36626455],\n",
       "       [0.72178113],\n",
       "       [0.13799562],\n",
       "       [0.58421665],\n",
       "       [0.8337528 ],\n",
       "       [0.09920792],\n",
       "       [0.22576506],\n",
       "       [0.8421119 ],\n",
       "       [0.12092233],\n",
       "       [0.6860544 ],\n",
       "       [0.22247843],\n",
       "       [0.86393017],\n",
       "       [0.30662775],\n",
       "       [0.1751257 ],\n",
       "       [0.1581177 ],\n",
       "       [0.23739617],\n",
       "       [0.32760796],\n",
       "       [0.49659094],\n",
       "       [0.8265911 ],\n",
       "       [0.12195861],\n",
       "       [0.88153255],\n",
       "       [0.5298383 ],\n",
       "       [0.75427043],\n",
       "       [0.8783414 ],\n",
       "       [0.36818132],\n",
       "       [0.3891144 ],\n",
       "       [0.5609682 ],\n",
       "       [0.8647225 ],\n",
       "       [0.06699242],\n",
       "       [0.40812263],\n",
       "       [0.17287078],\n",
       "       [0.1770305 ],\n",
       "       [0.8144557 ],\n",
       "       [0.80761683],\n",
       "       [0.77030957],\n",
       "       [0.7886391 ],\n",
       "       [0.20737717],\n",
       "       [0.12185945],\n",
       "       [0.71680266],\n",
       "       [0.24760556],\n",
       "       [0.20710002],\n",
       "       [0.15816881],\n",
       "       [0.32099286],\n",
       "       [0.5339564 ],\n",
       "       [0.2507014 ],\n",
       "       [0.41895932],\n",
       "       [0.30765092],\n",
       "       [0.29938284],\n",
       "       [0.262259  ],\n",
       "       [0.43465975],\n",
       "       [0.3977961 ],\n",
       "       [0.9178322 ],\n",
       "       [0.8581317 ],\n",
       "       [0.5995496 ],\n",
       "       [0.7653904 ],\n",
       "       [0.71908104],\n",
       "       [0.36176756],\n",
       "       [0.7014976 ],\n",
       "       [0.1162454 ],\n",
       "       [0.8988101 ],\n",
       "       [0.12822694],\n",
       "       [0.45333108],\n",
       "       [0.4601148 ],\n",
       "       [0.1409716 ],\n",
       "       [0.22972916],\n",
       "       [0.4547652 ],\n",
       "       [0.88870656],\n",
       "       [0.8424945 ],\n",
       "       [0.79576886],\n",
       "       [0.22225581],\n",
       "       [0.71279716],\n",
       "       [0.5207354 ],\n",
       "       [0.18504529],\n",
       "       [0.25387278],\n",
       "       [0.6651407 ],\n",
       "       [0.65535855],\n",
       "       [0.91162044],\n",
       "       [0.49895975],\n",
       "       [0.31732064],\n",
       "       [0.39513788],\n",
       "       [0.2978588 ],\n",
       "       [0.57194704],\n",
       "       [0.67998886],\n",
       "       [0.61760473],\n",
       "       [0.1384754 ],\n",
       "       [0.19524515],\n",
       "       [0.9075716 ],\n",
       "       [0.0977148 ],\n",
       "       [0.11856915],\n",
       "       [0.9118107 ],\n",
       "       [0.46409664],\n",
       "       [0.16903998],\n",
       "       [0.48356944],\n",
       "       [0.11188966],\n",
       "       [0.27404508],\n",
       "       [0.41195965],\n",
       "       [0.7147224 ],\n",
       "       [0.09821301],\n",
       "       [0.47205117],\n",
       "       [0.82918084],\n",
       "       [0.19352812],\n",
       "       [0.86661315],\n",
       "       [0.851647  ],\n",
       "       [0.11831471],\n",
       "       [0.14053965],\n",
       "       [0.12450534],\n",
       "       [0.85602254],\n",
       "       [0.37005758],\n",
       "       [0.8621663 ],\n",
       "       [0.22844142],\n",
       "       [0.49413478],\n",
       "       [0.27256176],\n",
       "       [0.14429936],\n",
       "       [0.66917294],\n",
       "       [0.13381998],\n",
       "       [0.86657536],\n",
       "       [0.11790472],\n",
       "       [0.314884  ],\n",
       "       [0.89534575],\n",
       "       [0.3567663 ],\n",
       "       [0.13753785],\n",
       "       [0.47188738],\n",
       "       [0.12073848],\n",
       "       [0.55626434],\n",
       "       [0.9172828 ],\n",
       "       [0.271979  ],\n",
       "       [0.91263473],\n",
       "       [0.14431384],\n",
       "       [0.72870576],\n",
       "       [0.33732286],\n",
       "       [0.63051784],\n",
       "       [0.6209642 ],\n",
       "       [0.39045447],\n",
       "       [0.12715542],\n",
       "       [0.6836025 ],\n",
       "       [0.8341081 ],\n",
       "       [0.5321995 ],\n",
       "       [0.75578266],\n",
       "       [0.84504026],\n",
       "       [0.06373201],\n",
       "       [0.6271107 ],\n",
       "       [0.5520475 ],\n",
       "       [0.6638825 ],\n",
       "       [0.16924661],\n",
       "       [0.6579076 ],\n",
       "       [0.50597745],\n",
       "       [0.51242906],\n",
       "       [0.25033954],\n",
       "       [0.33307433],\n",
       "       [0.25822896],\n",
       "       [0.14356087],\n",
       "       [0.3308043 ],\n",
       "       [0.3249557 ],\n",
       "       [0.80566376],\n",
       "       [0.954618  ],\n",
       "       [0.10313446],\n",
       "       [0.30385992],\n",
       "       [0.14690539],\n",
       "       [0.28637928],\n",
       "       [0.29985932],\n",
       "       [0.13821885],\n",
       "       [0.7777617 ],\n",
       "       [0.20200233],\n",
       "       [0.48676243],\n",
       "       [0.17255662],\n",
       "       [0.14494967],\n",
       "       [0.8178514 ],\n",
       "       [0.24674618],\n",
       "       [0.09373162],\n",
       "       [0.15176216],\n",
       "       [0.22613496],\n",
       "       [0.39194217],\n",
       "       [0.88775826],\n",
       "       [0.5824864 ],\n",
       "       [0.22071859],\n",
       "       [0.23888355],\n",
       "       [0.16137584],\n",
       "       [0.09732134],\n",
       "       [0.91012514],\n",
       "       [0.44703555],\n",
       "       [0.69371   ],\n",
       "       [0.73176306],\n",
       "       [0.27435094],\n",
       "       [0.48531726],\n",
       "       [0.22350453],\n",
       "       [0.15714341],\n",
       "       [0.5340961 ],\n",
       "       [0.744843  ],\n",
       "       [0.17251375],\n",
       "       [0.81153613],\n",
       "       [0.1073329 ],\n",
       "       [0.41848662],\n",
       "       [0.17703046],\n",
       "       [0.08378065],\n",
       "       [0.86470807],\n",
       "       [0.9305977 ],\n",
       "       [0.34572008],\n",
       "       [0.1693035 ],\n",
       "       [0.91444796],\n",
       "       [0.7078844 ],\n",
       "       [0.70771164],\n",
       "       [0.6700733 ],\n",
       "       [0.76759195],\n",
       "       [0.36317953],\n",
       "       [0.3400978 ],\n",
       "       [0.679862  ],\n",
       "       [0.87203664],\n",
       "       [0.17638849],\n",
       "       [0.7253158 ],\n",
       "       [0.47582445],\n",
       "       [0.5434411 ],\n",
       "       [0.11425988],\n",
       "       [0.16584007],\n",
       "       [0.39221755],\n",
       "       [0.21980916],\n",
       "       [0.2596078 ],\n",
       "       [0.66901606],\n",
       "       [0.12001886],\n",
       "       [0.14399979],\n",
       "       [0.32561687],\n",
       "       [0.27983227],\n",
       "       [0.0843246 ],\n",
       "       [0.61392426],\n",
       "       [0.18787763],\n",
       "       [0.5856409 ],\n",
       "       [0.17779882],\n",
       "       [0.16617697],\n",
       "       [0.65128165],\n",
       "       [0.18575808],\n",
       "       [0.24994184],\n",
       "       [0.19965123],\n",
       "       [0.17509213],\n",
       "       [0.86572075],\n",
       "       [0.2455214 ],\n",
       "       [0.15166298],\n",
       "       [0.8718555 ],\n",
       "       [0.7509161 ],\n",
       "       [0.8555466 ],\n",
       "       [0.91629916],\n",
       "       [0.9357946 ],\n",
       "       [0.16262561],\n",
       "       [0.19734696],\n",
       "       [0.06239493],\n",
       "       [0.6087545 ],\n",
       "       [0.8429034 ],\n",
       "       [0.5961362 ],\n",
       "       [0.4753818 ],\n",
       "       [0.23492295],\n",
       "       [0.71691704],\n",
       "       [0.45903593],\n",
       "       [0.48640576],\n",
       "       [0.28219625],\n",
       "       [0.24738997],\n",
       "       [0.19179769],\n",
       "       [0.07460715],\n",
       "       [0.7350899 ],\n",
       "       [0.83869153],\n",
       "       [0.18758358],\n",
       "       [0.87150985],\n",
       "       [0.69009745],\n",
       "       [0.08573719],\n",
       "       [0.28154838],\n",
       "       [0.13782598],\n",
       "       [0.80203414],\n",
       "       [0.5099806 ],\n",
       "       [0.27243647]], dtype=float32)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_7_pred_prods = model_7.predict(val_sentences)\n",
    "#model_7_pred_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_7_preds = tf.squeeze(tf.round(model_7_pred_prods))\n",
    "#model_7_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 82.54593175853019,\n",
       " 'precision': 0.8256179935749094,\n",
       " 'recall': 0.8254593175853019,\n",
       " 'f1': 0.8249028706511805}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_7_results = calculate_results(y_true=val_labels,y_pred=model_7_preds)\n",
    "#model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from helper_functions import plot_loss_curves\n",
    "\n",
    "#plot_loss_curves(model_7_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(685, 685)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a better dataset split (no data leakage)\n",
    "\n",
    "train_10_percent_split = int(0.1 * len(train_sentences))\n",
    "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
    "\n",
    "\n",
    "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
    "len(train_labels_10_percent),len(train_sentences_10_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    406\n",
       "1    279\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of each label in the updated training data subset\n",
    "\n",
    "pd.Series(np.array(train_labels_10_percent)).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of targets in our subset of data\n",
    "\n",
    "train_df_shuffled[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent/20220808-200226\n",
      "Epoch 1/5\n",
      "22/22 [==============================] - 4s 91ms/step - loss: 0.6737 - accuracy: 0.6584 - val_loss: 0.6508 - val_accuracy: 0.7178\n",
      "Epoch 2/5\n",
      "22/22 [==============================] - 1s 48ms/step - loss: 0.6044 - accuracy: 0.7869 - val_loss: 0.5979 - val_accuracy: 0.7493\n",
      "Epoch 3/5\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.5287 - accuracy: 0.8117 - val_loss: 0.5422 - val_accuracy: 0.7756\n",
      "Epoch 4/5\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4666 - accuracy: 0.8190 - val_loss: 0.5069 - val_accuracy: 0.7743\n",
      "Epoch 5/5\n",
      "22/22 [==============================] - 1s 38ms/step - loss: 0.4234 - accuracy: 0.8248 - val_loss: 0.4937 - val_accuracy: 0.7782\n"
     ]
    }
   ],
   "source": [
    "model_7 = tf.keras.Sequential([\n",
    "    sentence_encoder_layer,\n",
    "    tf.keras.layers.Dense(64,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1,activation=\"sigmoid\")]\n",
    ")\n",
    "\n",
    "model_7.compile(\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "model_7_history = model_7.fit(\n",
    "    train_sentences_10_percent,\n",
    "    train_labels_10_percent,\n",
    "    epochs = 5,\n",
    "    validation_data = (val_sentences,val_labels),\n",
    "    callbacks=[create_tensorboard_callback(\n",
    "        SAVE_DIR,\n",
    "        \"tf_hub_sentence_encoder_10_percent\"\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.22181405],\n",
       "       [0.5880644 ],\n",
       "       [0.8906073 ],\n",
       "       [0.37894738],\n",
       "       [0.5482235 ],\n",
       "       [0.6881271 ],\n",
       "       [0.8631701 ],\n",
       "       [0.8033568 ],\n",
       "       [0.8298558 ],\n",
       "       [0.15552986],\n",
       "       [0.49213162],\n",
       "       [0.47934717],\n",
       "       [0.29891327],\n",
       "       [0.3175157 ],\n",
       "       [0.48035315],\n",
       "       [0.14860341],\n",
       "       [0.2722888 ],\n",
       "       [0.62267923],\n",
       "       [0.5674558 ],\n",
       "       [0.3413096 ],\n",
       "       [0.5514228 ],\n",
       "       [0.34919888],\n",
       "       [0.29112342],\n",
       "       [0.11106555],\n",
       "       [0.49120924],\n",
       "       [0.8242062 ],\n",
       "       [0.23169601],\n",
       "       [0.38229054],\n",
       "       [0.11400156],\n",
       "       [0.33148134],\n",
       "       [0.607839  ],\n",
       "       [0.78907055],\n",
       "       [0.41184196],\n",
       "       [0.30536878],\n",
       "       [0.4930635 ],\n",
       "       [0.1735495 ],\n",
       "       [0.85635257],\n",
       "       [0.09270827],\n",
       "       [0.12418848],\n",
       "       [0.87675685],\n",
       "       [0.15715908],\n",
       "       [0.2066139 ],\n",
       "       [0.56567264],\n",
       "       [0.43497708],\n",
       "       [0.2533918 ],\n",
       "       [0.78346664],\n",
       "       [0.2718638 ],\n",
       "       [0.8810237 ],\n",
       "       [0.3958015 ],\n",
       "       [0.8501542 ],\n",
       "       [0.12616734],\n",
       "       [0.5441282 ],\n",
       "       [0.4093753 ],\n",
       "       [0.11700567],\n",
       "       [0.12596577],\n",
       "       [0.05342017],\n",
       "       [0.18024263],\n",
       "       [0.66876626],\n",
       "       [0.1944603 ],\n",
       "       [0.2057656 ],\n",
       "       [0.07710275],\n",
       "       [0.773096  ],\n",
       "       [0.8425417 ],\n",
       "       [0.15652189],\n",
       "       [0.6625808 ],\n",
       "       [0.80337614],\n",
       "       [0.33329195],\n",
       "       [0.40736863],\n",
       "       [0.12541915],\n",
       "       [0.4016033 ],\n",
       "       [0.159506  ],\n",
       "       [0.14309914],\n",
       "       [0.47451216],\n",
       "       [0.0687694 ],\n",
       "       [0.05283789],\n",
       "       [0.6559023 ],\n",
       "       [0.26219174],\n",
       "       [0.3270135 ],\n",
       "       [0.1336499 ],\n",
       "       [0.5819661 ],\n",
       "       [0.77540964],\n",
       "       [0.5402494 ],\n",
       "       [0.69397634],\n",
       "       [0.30081356],\n",
       "       [0.4300483 ],\n",
       "       [0.5786828 ],\n",
       "       [0.12948272],\n",
       "       [0.24419631],\n",
       "       [0.88314897],\n",
       "       [0.6064166 ],\n",
       "       [0.90274197],\n",
       "       [0.08094191],\n",
       "       [0.1111149 ],\n",
       "       [0.09838048],\n",
       "       [0.8495849 ],\n",
       "       [0.55774146],\n",
       "       [0.81739795],\n",
       "       [0.69149166],\n",
       "       [0.9061619 ],\n",
       "       [0.6952493 ],\n",
       "       [0.837137  ],\n",
       "       [0.17041938],\n",
       "       [0.05736725],\n",
       "       [0.8688234 ],\n",
       "       [0.78693   ],\n",
       "       [0.12969524],\n",
       "       [0.5801584 ],\n",
       "       [0.29418874],\n",
       "       [0.12349905],\n",
       "       [0.54917246],\n",
       "       [0.5287612 ],\n",
       "       [0.21919471],\n",
       "       [0.2952327 ],\n",
       "       [0.31845158],\n",
       "       [0.30611974],\n",
       "       [0.53254026],\n",
       "       [0.39906842],\n",
       "       [0.69759107],\n",
       "       [0.5539269 ],\n",
       "       [0.6930979 ],\n",
       "       [0.7879201 ],\n",
       "       [0.26463333],\n",
       "       [0.34832922],\n",
       "       [0.67019373],\n",
       "       [0.5275845 ],\n",
       "       [0.42712966],\n",
       "       [0.16845219],\n",
       "       [0.1092636 ],\n",
       "       [0.10818302],\n",
       "       [0.5489796 ],\n",
       "       [0.2861877 ],\n",
       "       [0.7878607 ],\n",
       "       [0.68156415],\n",
       "       [0.83118206],\n",
       "       [0.5973436 ],\n",
       "       [0.48726103],\n",
       "       [0.84001297],\n",
       "       [0.31614453],\n",
       "       [0.30167183],\n",
       "       [0.11866531],\n",
       "       [0.8617915 ],\n",
       "       [0.1584864 ],\n",
       "       [0.322384  ],\n",
       "       [0.48025092],\n",
       "       [0.5078002 ],\n",
       "       [0.11985251],\n",
       "       [0.0646664 ],\n",
       "       [0.1676473 ],\n",
       "       [0.15056103],\n",
       "       [0.80411774],\n",
       "       [0.44632602],\n",
       "       [0.18398267],\n",
       "       [0.6381476 ],\n",
       "       [0.2317591 ],\n",
       "       [0.15983708],\n",
       "       [0.7837473 ],\n",
       "       [0.597444  ],\n",
       "       [0.17317313],\n",
       "       [0.82577586],\n",
       "       [0.3142555 ],\n",
       "       [0.6874886 ],\n",
       "       [0.21038537],\n",
       "       [0.21138331],\n",
       "       [0.8839882 ],\n",
       "       [0.17850846],\n",
       "       [0.19634347],\n",
       "       [0.92334574],\n",
       "       [0.50234014],\n",
       "       [0.6585057 ],\n",
       "       [0.1039694 ],\n",
       "       [0.87141746],\n",
       "       [0.67561567],\n",
       "       [0.8155962 ],\n",
       "       [0.2029338 ],\n",
       "       [0.77607876],\n",
       "       [0.09334745],\n",
       "       [0.7093441 ],\n",
       "       [0.40744737],\n",
       "       [0.46857095],\n",
       "       [0.9077463 ],\n",
       "       [0.07459775],\n",
       "       [0.67685485],\n",
       "       [0.4875022 ],\n",
       "       [0.7446265 ],\n",
       "       [0.77913004],\n",
       "       [0.25390086],\n",
       "       [0.23301026],\n",
       "       [0.8574536 ],\n",
       "       [0.3542484 ],\n",
       "       [0.30058208],\n",
       "       [0.23514517],\n",
       "       [0.7601492 ],\n",
       "       [0.3942963 ],\n",
       "       [0.35311165],\n",
       "       [0.2609692 ],\n",
       "       [0.266911  ],\n",
       "       [0.31908745],\n",
       "       [0.33853808],\n",
       "       [0.38737342],\n",
       "       [0.17814372],\n",
       "       [0.1618871 ],\n",
       "       [0.69930077],\n",
       "       [0.74886215],\n",
       "       [0.13951746],\n",
       "       [0.43650237],\n",
       "       [0.8953326 ],\n",
       "       [0.50547   ],\n",
       "       [0.63615364],\n",
       "       [0.8018957 ],\n",
       "       [0.7318159 ],\n",
       "       [0.09507753],\n",
       "       [0.7654986 ],\n",
       "       [0.17926496],\n",
       "       [0.27131754],\n",
       "       [0.09688725],\n",
       "       [0.17506093],\n",
       "       [0.58053946],\n",
       "       [0.60857964],\n",
       "       [0.54874754],\n",
       "       [0.15545426],\n",
       "       [0.46921232],\n",
       "       [0.13468723],\n",
       "       [0.14693421],\n",
       "       [0.16496044],\n",
       "       [0.817956  ],\n",
       "       [0.24635765],\n",
       "       [0.39001366],\n",
       "       [0.83452463],\n",
       "       [0.4927545 ],\n",
       "       [0.50711   ],\n",
       "       [0.70774126],\n",
       "       [0.10790591],\n",
       "       [0.76736665],\n",
       "       [0.10159563],\n",
       "       [0.6375799 ],\n",
       "       [0.40002146],\n",
       "       [0.30608216],\n",
       "       [0.22608268],\n",
       "       [0.8306253 ],\n",
       "       [0.12089095],\n",
       "       [0.44670665],\n",
       "       [0.3953293 ],\n",
       "       [0.8584777 ],\n",
       "       [0.6923575 ],\n",
       "       [0.09122242],\n",
       "       [0.470409  ],\n",
       "       [0.642731  ],\n",
       "       [0.1716827 ],\n",
       "       [0.1185824 ],\n",
       "       [0.51131207],\n",
       "       [0.13085398],\n",
       "       [0.5373826 ],\n",
       "       [0.07099646],\n",
       "       [0.3365618 ],\n",
       "       [0.60782546],\n",
       "       [0.14393768],\n",
       "       [0.71298665],\n",
       "       [0.91231936],\n",
       "       [0.11809179],\n",
       "       [0.21412778],\n",
       "       [0.67069334],\n",
       "       [0.17311345],\n",
       "       [0.2788948 ],\n",
       "       [0.8062625 ],\n",
       "       [0.58516777],\n",
       "       [0.7160632 ],\n",
       "       [0.8201469 ],\n",
       "       [0.15997475],\n",
       "       [0.17371532],\n",
       "       [0.08292881],\n",
       "       [0.31061643],\n",
       "       [0.45442268],\n",
       "       [0.75476277],\n",
       "       [0.11322377],\n",
       "       [0.45088378],\n",
       "       [0.8553961 ],\n",
       "       [0.6841786 ],\n",
       "       [0.08753508],\n",
       "       [0.866987  ],\n",
       "       [0.5252907 ],\n",
       "       [0.20558709],\n",
       "       [0.1493338 ],\n",
       "       [0.79179853],\n",
       "       [0.37768534],\n",
       "       [0.16765107],\n",
       "       [0.62389857],\n",
       "       [0.47351244],\n",
       "       [0.24263196],\n",
       "       [0.41764015],\n",
       "       [0.17023306],\n",
       "       [0.54004   ],\n",
       "       [0.465392  ],\n",
       "       [0.47739494],\n",
       "       [0.47929063],\n",
       "       [0.18246113],\n",
       "       [0.7803092 ],\n",
       "       [0.2885269 ],\n",
       "       [0.86891985],\n",
       "       [0.08294852],\n",
       "       [0.61789244],\n",
       "       [0.60977256],\n",
       "       [0.18109342],\n",
       "       [0.17324722],\n",
       "       [0.7262217 ],\n",
       "       [0.36791837],\n",
       "       [0.2937953 ],\n",
       "       [0.19575264],\n",
       "       [0.59270346],\n",
       "       [0.21860476],\n",
       "       [0.05421572],\n",
       "       [0.14242437],\n",
       "       [0.63080597],\n",
       "       [0.44619846],\n",
       "       [0.29722008],\n",
       "       [0.8446542 ],\n",
       "       [0.09955247],\n",
       "       [0.797708  ],\n",
       "       [0.5084591 ],\n",
       "       [0.13057451],\n",
       "       [0.4556379 ],\n",
       "       [0.14680465],\n",
       "       [0.18498556],\n",
       "       [0.8144689 ],\n",
       "       [0.08924139],\n",
       "       [0.5356546 ],\n",
       "       [0.2484716 ],\n",
       "       [0.18838178],\n",
       "       [0.7589577 ],\n",
       "       [0.21051115],\n",
       "       [0.844742  ],\n",
       "       [0.5082379 ],\n",
       "       [0.09631325],\n",
       "       [0.770118  ],\n",
       "       [0.2654077 ],\n",
       "       [0.13265646],\n",
       "       [0.56622773],\n",
       "       [0.08377427],\n",
       "       [0.46576256],\n",
       "       [0.19034104],\n",
       "       [0.3201039 ],\n",
       "       [0.19610506],\n",
       "       [0.14479703],\n",
       "       [0.83778644],\n",
       "       [0.67732054],\n",
       "       [0.4834578 ],\n",
       "       [0.20485714],\n",
       "       [0.22949134],\n",
       "       [0.25043517],\n",
       "       [0.07163579],\n",
       "       [0.2661007 ],\n",
       "       [0.37729824],\n",
       "       [0.5460992 ],\n",
       "       [0.13285677],\n",
       "       [0.25046214],\n",
       "       [0.39935908],\n",
       "       [0.09927256],\n",
       "       [0.8011877 ],\n",
       "       [0.8111775 ],\n",
       "       [0.6870244 ],\n",
       "       [0.43989003],\n",
       "       [0.47296524],\n",
       "       [0.16125308],\n",
       "       [0.5833467 ],\n",
       "       [0.49802625],\n",
       "       [0.6520218 ],\n",
       "       [0.10525777],\n",
       "       [0.24582924],\n",
       "       [0.21742773],\n",
       "       [0.38263354],\n",
       "       [0.1196269 ],\n",
       "       [0.4423716 ],\n",
       "       [0.10211435],\n",
       "       [0.06121755],\n",
       "       [0.40285483],\n",
       "       [0.11503305],\n",
       "       [0.17078343],\n",
       "       [0.18618797],\n",
       "       [0.30064848],\n",
       "       [0.22904779],\n",
       "       [0.33895162],\n",
       "       [0.78902644],\n",
       "       [0.72195977],\n",
       "       [0.08815698],\n",
       "       [0.60266536],\n",
       "       [0.4241705 ],\n",
       "       [0.6586479 ],\n",
       "       [0.41258472],\n",
       "       [0.1834764 ],\n",
       "       [0.89865744],\n",
       "       [0.3531591 ],\n",
       "       [0.10405837],\n",
       "       [0.26384646],\n",
       "       [0.08547772],\n",
       "       [0.72050023],\n",
       "       [0.54148114],\n",
       "       [0.878422  ],\n",
       "       [0.1229878 ],\n",
       "       [0.5007543 ],\n",
       "       [0.37032482],\n",
       "       [0.6579744 ],\n",
       "       [0.80330694],\n",
       "       [0.1229581 ],\n",
       "       [0.64426327],\n",
       "       [0.711253  ],\n",
       "       [0.5129687 ],\n",
       "       [0.78243744],\n",
       "       [0.28788245],\n",
       "       [0.47914904],\n",
       "       [0.10561519],\n",
       "       [0.39969933],\n",
       "       [0.8060908 ],\n",
       "       [0.06571908],\n",
       "       [0.16054097],\n",
       "       [0.20612949],\n",
       "       [0.8005207 ],\n",
       "       [0.6311302 ],\n",
       "       [0.49557453],\n",
       "       [0.8175393 ],\n",
       "       [0.19381423],\n",
       "       [0.18779093],\n",
       "       [0.8205849 ],\n",
       "       [0.74936664],\n",
       "       [0.66452926],\n",
       "       [0.6962989 ],\n",
       "       [0.1719203 ],\n",
       "       [0.6352848 ],\n",
       "       [0.13158202],\n",
       "       [0.691691  ],\n",
       "       [0.1568396 ],\n",
       "       [0.7619957 ],\n",
       "       [0.10377512],\n",
       "       [0.15962414],\n",
       "       [0.13454092],\n",
       "       [0.75104314],\n",
       "       [0.23434652],\n",
       "       [0.28823584],\n",
       "       [0.19999863],\n",
       "       [0.5395358 ],\n",
       "       [0.8397339 ],\n",
       "       [0.66433525],\n",
       "       [0.66070044],\n",
       "       [0.57365793],\n",
       "       [0.482984  ],\n",
       "       [0.26069283],\n",
       "       [0.18833652],\n",
       "       [0.68123496],\n",
       "       [0.17568915],\n",
       "       [0.14623313],\n",
       "       [0.44715112],\n",
       "       [0.16817361],\n",
       "       [0.11206967],\n",
       "       [0.73517853],\n",
       "       [0.7452867 ],\n",
       "       [0.695218  ],\n",
       "       [0.89642596],\n",
       "       [0.84594285],\n",
       "       [0.08356287],\n",
       "       [0.40788978],\n",
       "       [0.57054716],\n",
       "       [0.7999669 ],\n",
       "       [0.83717203],\n",
       "       [0.09869925],\n",
       "       [0.270853  ],\n",
       "       [0.4341504 ],\n",
       "       [0.9065783 ],\n",
       "       [0.8853908 ],\n",
       "       [0.3039008 ],\n",
       "       [0.19953994],\n",
       "       [0.7965639 ],\n",
       "       [0.13218665],\n",
       "       [0.08751883],\n",
       "       [0.79340607],\n",
       "       [0.48255506],\n",
       "       [0.42010215],\n",
       "       [0.46536386],\n",
       "       [0.6543684 ],\n",
       "       [0.8478575 ],\n",
       "       [0.90149754],\n",
       "       [0.12612289],\n",
       "       [0.09605471],\n",
       "       [0.42320675],\n",
       "       [0.17950527],\n",
       "       [0.2614316 ],\n",
       "       [0.79847246],\n",
       "       [0.05818286],\n",
       "       [0.47404644],\n",
       "       [0.24160545],\n",
       "       [0.14218605],\n",
       "       [0.33920586],\n",
       "       [0.32023546],\n",
       "       [0.46573535],\n",
       "       [0.7242091 ],\n",
       "       [0.19869839],\n",
       "       [0.37728685],\n",
       "       [0.47090736],\n",
       "       [0.2465095 ],\n",
       "       [0.44931054],\n",
       "       [0.7208505 ],\n",
       "       [0.23975228],\n",
       "       [0.60410917],\n",
       "       [0.8806343 ],\n",
       "       [0.10654135],\n",
       "       [0.40262014],\n",
       "       [0.74474335],\n",
       "       [0.13203989],\n",
       "       [0.7374621 ],\n",
       "       [0.24192478],\n",
       "       [0.8562739 ],\n",
       "       [0.21758378],\n",
       "       [0.26428983],\n",
       "       [0.08268864],\n",
       "       [0.11373602],\n",
       "       [0.2802823 ],\n",
       "       [0.5080591 ],\n",
       "       [0.79544723],\n",
       "       [0.18730259],\n",
       "       [0.8294005 ],\n",
       "       [0.5124663 ],\n",
       "       [0.54768145],\n",
       "       [0.76698035],\n",
       "       [0.49604633],\n",
       "       [0.23328511],\n",
       "       [0.6081912 ],\n",
       "       [0.82173026],\n",
       "       [0.09213093],\n",
       "       [0.54423195],\n",
       "       [0.17485902],\n",
       "       [0.22516365],\n",
       "       [0.7353785 ],\n",
       "       [0.77661574],\n",
       "       [0.5863818 ],\n",
       "       [0.80019337],\n",
       "       [0.11299783],\n",
       "       [0.18059291],\n",
       "       [0.3981693 ],\n",
       "       [0.23245129],\n",
       "       [0.10646078],\n",
       "       [0.3109502 ],\n",
       "       [0.15053779],\n",
       "       [0.45862907],\n",
       "       [0.24578267],\n",
       "       [0.4607222 ],\n",
       "       [0.3798556 ],\n",
       "       [0.33951512],\n",
       "       [0.24924092],\n",
       "       [0.4818847 ],\n",
       "       [0.5391849 ],\n",
       "       [0.87099403],\n",
       "       [0.7783396 ],\n",
       "       [0.6172644 ],\n",
       "       [0.70899355],\n",
       "       [0.48559865],\n",
       "       [0.24814643],\n",
       "       [0.6609496 ],\n",
       "       [0.05964877],\n",
       "       [0.8321994 ],\n",
       "       [0.13405007],\n",
       "       [0.4246677 ],\n",
       "       [0.58899695],\n",
       "       [0.07521888],\n",
       "       [0.11981054],\n",
       "       [0.51741296],\n",
       "       [0.8543168 ],\n",
       "       [0.81790245],\n",
       "       [0.63669574],\n",
       "       [0.1722167 ],\n",
       "       [0.6916158 ],\n",
       "       [0.45232803],\n",
       "       [0.15525673],\n",
       "       [0.26194316],\n",
       "       [0.5670826 ],\n",
       "       [0.64241207],\n",
       "       [0.86717457],\n",
       "       [0.37513307],\n",
       "       [0.29152256],\n",
       "       [0.25708783],\n",
       "       [0.29501674],\n",
       "       [0.58648944],\n",
       "       [0.42566353],\n",
       "       [0.60746276],\n",
       "       [0.23685555],\n",
       "       [0.13954762],\n",
       "       [0.73238784],\n",
       "       [0.13321358],\n",
       "       [0.08517289],\n",
       "       [0.84554636],\n",
       "       [0.29335517],\n",
       "       [0.09115287],\n",
       "       [0.60504353],\n",
       "       [0.09130924],\n",
       "       [0.27491888],\n",
       "       [0.55191016],\n",
       "       [0.46303138],\n",
       "       [0.16128744],\n",
       "       [0.4927182 ],\n",
       "       [0.79927176],\n",
       "       [0.23973677],\n",
       "       [0.7127118 ],\n",
       "       [0.8237391 ],\n",
       "       [0.07855287],\n",
       "       [0.16369535],\n",
       "       [0.17913811],\n",
       "       [0.76501346],\n",
       "       [0.4681862 ],\n",
       "       [0.8191222 ],\n",
       "       [0.21719752],\n",
       "       [0.3499451 ],\n",
       "       [0.19345884],\n",
       "       [0.14780979],\n",
       "       [0.5562081 ],\n",
       "       [0.17352204],\n",
       "       [0.7839405 ],\n",
       "       [0.1441136 ],\n",
       "       [0.14848784],\n",
       "       [0.8263453 ],\n",
       "       [0.38532552],\n",
       "       [0.12544668],\n",
       "       [0.5390641 ],\n",
       "       [0.0982141 ],\n",
       "       [0.5144994 ],\n",
       "       [0.8928667 ],\n",
       "       [0.33007613],\n",
       "       [0.8662954 ],\n",
       "       [0.2927734 ],\n",
       "       [0.50853753],\n",
       "       [0.16620292],\n",
       "       [0.5264442 ],\n",
       "       [0.3627733 ],\n",
       "       [0.5556084 ],\n",
       "       [0.1406509 ],\n",
       "       [0.73759025],\n",
       "       [0.7502469 ],\n",
       "       [0.5347848 ],\n",
       "       [0.57879126],\n",
       "       [0.82802755],\n",
       "       [0.10056269],\n",
       "       [0.66498864],\n",
       "       [0.38745415],\n",
       "       [0.6051873 ],\n",
       "       [0.18181892],\n",
       "       [0.5506761 ],\n",
       "       [0.28822953],\n",
       "       [0.649689  ],\n",
       "       [0.19268803],\n",
       "       [0.38503876],\n",
       "       [0.2692583 ],\n",
       "       [0.14128834],\n",
       "       [0.44093427],\n",
       "       [0.2129012 ],\n",
       "       [0.7264067 ],\n",
       "       [0.88919014],\n",
       "       [0.15429735],\n",
       "       [0.24628694],\n",
       "       [0.132226  ],\n",
       "       [0.21505764],\n",
       "       [0.20213574],\n",
       "       [0.12430643],\n",
       "       [0.8109585 ],\n",
       "       [0.12135307],\n",
       "       [0.2050738 ],\n",
       "       [0.18016939],\n",
       "       [0.17192818],\n",
       "       [0.7397385 ],\n",
       "       [0.17236327],\n",
       "       [0.16456988],\n",
       "       [0.1607931 ],\n",
       "       [0.35056782],\n",
       "       [0.31003055],\n",
       "       [0.8468578 ],\n",
       "       [0.46844658],\n",
       "       [0.18260647],\n",
       "       [0.28306758],\n",
       "       [0.15895136],\n",
       "       [0.04418202],\n",
       "       [0.8233086 ],\n",
       "       [0.38155928],\n",
       "       [0.72086966],\n",
       "       [0.5373605 ],\n",
       "       [0.1331101 ],\n",
       "       [0.47243395],\n",
       "       [0.49142218],\n",
       "       [0.09253635],\n",
       "       [0.31833553],\n",
       "       [0.58387953],\n",
       "       [0.28705475],\n",
       "       [0.8753432 ],\n",
       "       [0.06896002],\n",
       "       [0.39684054],\n",
       "       [0.22516358],\n",
       "       [0.14242278],\n",
       "       [0.8212627 ],\n",
       "       [0.7884417 ],\n",
       "       [0.1637454 ],\n",
       "       [0.19989848],\n",
       "       [0.8580517 ],\n",
       "       [0.648949  ],\n",
       "       [0.55188423],\n",
       "       [0.5851018 ],\n",
       "       [0.71568996],\n",
       "       [0.4733018 ],\n",
       "       [0.39392436],\n",
       "       [0.36322126],\n",
       "       [0.793991  ],\n",
       "       [0.237582  ],\n",
       "       [0.23389034],\n",
       "       [0.36263916],\n",
       "       [0.46894792],\n",
       "       [0.16780761],\n",
       "       [0.2706567 ],\n",
       "       [0.2806536 ],\n",
       "       [0.13400477],\n",
       "       [0.3295035 ],\n",
       "       [0.6623278 ],\n",
       "       [0.0992348 ],\n",
       "       [0.11275047],\n",
       "       [0.13408989],\n",
       "       [0.38681966],\n",
       "       [0.15300885],\n",
       "       [0.5775094 ],\n",
       "       [0.08568854],\n",
       "       [0.5125787 ],\n",
       "       [0.13064599],\n",
       "       [0.10614398],\n",
       "       [0.56710964],\n",
       "       [0.22086263],\n",
       "       [0.21496984],\n",
       "       [0.13368663],\n",
       "       [0.19263883],\n",
       "       [0.8197994 ],\n",
       "       [0.38165477],\n",
       "       [0.24062382],\n",
       "       [0.8500252 ],\n",
       "       [0.7061638 ],\n",
       "       [0.68149215],\n",
       "       [0.91569805],\n",
       "       [0.81325716],\n",
       "       [0.15846969],\n",
       "       [0.2616726 ],\n",
       "       [0.13201153],\n",
       "       [0.505454  ],\n",
       "       [0.71943146],\n",
       "       [0.2699854 ],\n",
       "       [0.43598256],\n",
       "       [0.21769974],\n",
       "       [0.6579658 ],\n",
       "       [0.35501626],\n",
       "       [0.56943256],\n",
       "       [0.250234  ],\n",
       "       [0.3314489 ],\n",
       "       [0.14932908],\n",
       "       [0.15856405],\n",
       "       [0.62218845],\n",
       "       [0.68810314],\n",
       "       [0.16292238],\n",
       "       [0.75884885],\n",
       "       [0.59741324],\n",
       "       [0.16128877],\n",
       "       [0.20029315],\n",
       "       [0.27762285],\n",
       "       [0.6058553 ],\n",
       "       [0.5617082 ],\n",
       "       [0.28843328]], dtype=float32)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_pred_prods = model_7.predict(val_sentences)\n",
    "model_7_pred_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(762,), dtype=float32, numpy=\n",
       "array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       0., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1., 0.,\n",
       "       1., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 0.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_preds = tf.squeeze(tf.round(model_7_pred_prods))\n",
    "model_7_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 77.82152230971128,\n",
       " 'precision': 0.7804499491198106,\n",
       " 'recall': 0.7782152230971129,\n",
       " 'f1': 0.7760126933653841}"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_results = calculate_results(y_true=val_labels,y_pred=model_7_preds)\n",
    "model_7_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Be very careful when creating training/val/test splits that you don't leak data across the,\n",
    "#   datasets, otherwise your model evaluation metrics will be wrong. If something looks too good \n",
    "#   to be true (a model trained on 10% of data outperforming the same model trained on 100% data)\n",
    "#   trust your gut and go back through to find where the error may lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing the performance of each of our models\n",
    "\n",
    "# Combine model results into a DataFrame\n",
    "\n",
    "all_model_results = pd.DataFrame({\n",
    "    \"baseline\":baseline_results,\n",
    "    \"1_simple_dense\":model_1_results,\n",
    "    \"2_lstm\":model_2_results,\n",
    "    \"3_gru\":model_3_results,\n",
    "    \"4_bidirectional\":model_4_results,\n",
    "    \"5_conv1d\":model_6_results,\n",
    "    \"6_tf_hub_use_encoder\":model_6_results,\n",
    "    \"7_tf_hub_use_encoder_10_percent\":model_7_results\n",
    "    })\n",
    "all_model_results = all_model_results.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the accuracy to the same scale as other metrics\n",
    "\n",
    "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.811139</td>\n",
       "      <td>0.792651</td>\n",
       "      <td>0.786219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_simple_dense</th>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.794743</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.783640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_lstm</th>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.770226</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.765130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_gru</th>\n",
       "      <td>0.776903</td>\n",
       "      <td>0.779882</td>\n",
       "      <td>0.776903</td>\n",
       "      <td>0.774350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_bidirectional</th>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.755729</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.754782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5_conv1d</th>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.818446</td>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.814808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6_tf_hub_use_encoder</th>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.818446</td>\n",
       "      <td>0.816273</td>\n",
       "      <td>0.814808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7_tf_hub_use_encoder_10_percent</th>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.780450</td>\n",
       "      <td>0.778215</td>\n",
       "      <td>0.776013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 accuracy  precision    recall        f1\n",
       "baseline                         0.792651   0.811139  0.792651  0.786219\n",
       "1_simple_dense                   0.787402   0.794743  0.787402  0.783640\n",
       "2_lstm                           0.767717   0.770226  0.767717  0.765130\n",
       "3_gru                            0.776903   0.779882  0.776903  0.774350\n",
       "4_bidirectional                  0.755906   0.755729  0.755906  0.754782\n",
       "5_conv1d                         0.816273   0.818446  0.816273  0.814808\n",
       "6_tf_hub_use_encoder             0.816273   0.818446  0.816273  0.814808\n",
       "7_tf_hub_use_encoder_10_percent  0.778215   0.780450  0.778215  0.776013"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x247b9fc5960>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot and compare all of the model results\n",
    "\n",
    "all_model_results.plot(kind=\"bar\", figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sort model results by f1-score\n",
    "\n",
    "all_model_results.sort_values(\"f1\",ascending=False)[\"f1\"].plot(kind=\"bar\",figsize=(10,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Uploading our model training logs to TensorBoard.dev\n",
    "\n",
    "# View TensorBoard logs of transfer learning modelling experiments (plus all of our other models)\n",
    "\n",
    "# Upload TensorBoard dev records\n",
    "\n",
    "!tensorboard dev upload --logdir ./model_logs/ \\\n",
    "    --one_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# See the previous TensorBoard Dev experiments you've run\n",
    "\n",
    "!tensorboard dev list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you need to delete an experiment from TensorBoard, you can run the following:\n",
    "\n",
    "# !tensorboard dev delete --experiment_id experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading a trained model\n",
    "\n",
    "# There are two main formats to save a model to in TensorFlow:\n",
    "\n",
    "# 1. The HDF5 format\n",
    "# 2. The 'SavedModel' format (this is the default when using TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.818446310697231,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8148082644367335}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save TF Hub Sentence Encoder model to HDF5 format\n",
    "\n",
    "model_6.save(\"model_6.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\Me-ScriptsnShit\\TensorFlow\\NLP\\NLP.ipynb Hücre 130\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y244sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load model with custom Hub Layer (required HDF5 format)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y244sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_hub\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mhub\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y244sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m loaded_model_6 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m\"\u001b[39;49m\u001b[39mmodel_6.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m,custom_objects\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mKerasLayer\u001b[39;49m\u001b[39m\"\u001b[39;49m:hub\u001b[39m.\u001b[39;49mKerasLayer})\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:153\u001b[0m, in \u001b[0;36mKerasLayer.__init__\u001b[1;34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_shape \u001b[39m=\u001b[39m data_structures\u001b[39m.\u001b[39mNoDependency(\n\u001b[0;32m    150\u001b[0m       _convert_nest_to_shapes(output_shape))\n\u001b[0;32m    152\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func \u001b[39m=\u001b[39m load_module(handle, tags, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_options)\n\u001b[0;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_training_argument \u001b[39m=\u001b[39m func_has_training_argument(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func)\n\u001b[0;32m    155\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_func, \u001b[39m\"\u001b[39m\u001b[39m_is_hub_module_v1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\keras_layer.py:449\u001b[0m, in \u001b[0;36mload_module\u001b[1;34m(handle, tags, load_options)\u001b[0m\n\u001b[0;32m    447\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:  \u001b[39m# Expected before TF2.4.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     set_load_options \u001b[39m=\u001b[39m load_options\n\u001b[1;32m--> 449\u001b[0m \u001b[39mreturn\u001b[39;00m module_v2\u001b[39m.\u001b[39;49mload(handle, tags\u001b[39m=\u001b[39;49mtags, options\u001b[39m=\u001b[39;49mset_load_options)\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:106\u001b[0m, in \u001b[0;36mload\u001b[1;34m(handle, tags, options)\u001b[0m\n\u001b[0;32m    103\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mcompat\u001b[39m.\u001b[39mv1\u001b[39m.\u001b[39msaved_model\u001b[39m.\u001b[39mload_v2(\n\u001b[0;32m    104\u001b[0m       module_path, tags\u001b[39m=\u001b[39mtags, options\u001b[39m=\u001b[39moptions)\n\u001b[0;32m    105\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 106\u001b[0m   obj \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49msaved_model\u001b[39m.\u001b[39;49mload_v2(module_path, tags\u001b[39m=\u001b[39;49mtags)\n\u001b[0;32m    107\u001b[0m obj\u001b[39m.\u001b[39m_is_hub_module_v1 \u001b[39m=\u001b[39m is_hub_module_v1  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]"
     ]
    }
   ],
   "source": [
    "# Load model with custom Hub Layer (required HDF5 format)\n",
    "import tensorflow_hub as hub\n",
    "loaded_model_6 = tf.keras.models.load_model(\"model_6.h5\",custom_objects={\"KerasLayer\":hub.KerasLayer})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does our loaded model perform\n",
    "\n",
    "loaded_model_6.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[26667,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReadVariableOp]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32md:\\Me-ScriptsnShit\\TensorFlow\\NLP\\NLP.ipynb Hücre 132\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y246sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Save TF Hub Sentence Encoder model to SavedModel format (default)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y246sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model_6\u001b[39m.\u001b[39;49msave(\u001b[39m\"\u001b[39;49m\u001b[39mmodel_6_SavedModel_format\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[26667,320] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ReadVariableOp]"
     ]
    }
   ],
   "source": [
    "# Save TF Hub Sentence Encoder model to SavedModel format (default)\n",
    "\n",
    "model_6.save(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavedModel_loaded_model_6 = tf.keras.models.load_model(\"model_6_SavedModel_format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SavedModel_loaded_model_6.evaluate(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Finding the most wrong examples\n",
    "\n",
    "# * If our best model still isn't perfect, what examples is it getting wrong\n",
    "# * And of these wrong examples which ones is it getting *most* wrong (those will prediction\n",
    "#   probabilities closest to the opposite class)\n",
    "\n",
    "# For example if a sample should have a label of 0 but our model predicts a prediction probability of 0.999\n",
    "# (really close to 1) and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a pretrained model from Google Storage\n",
    "\n",
    "unzip_data(\"08_model_6_USE_feature_extractor.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32md:\\Me-ScriptsnShit\\TensorFlow\\NLP\\NLP.ipynb Hücre 137\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y253sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Create DataFrame with validation sentences and best performing model predictions\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y253sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y253sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Import previously trained model from Google Storage\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y253sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model_6_pretrained \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m\"\u001b[39;49m\u001b[39m08_model_6_USE_feature_extractor\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Me-ScriptsnShit/TensorFlow/NLP/NLP.ipynb#Y253sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model_6_pretrained\u001b[39m.\u001b[39mevaluate(val_sentences, val_labels)\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\NAS\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:7164\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[0;32m   7163\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7164\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run Identity: Dst tensor is not initialized. [Op:Identity]"
     ]
    }
   ],
   "source": [
    "# Create DataFrame with validation sentences and best performing model predictions\n",
    "\n",
    "# Import previously trained model from Google Storage\n",
    "\n",
    "model_6_pretrained = tf.keras.models.load_model(\"08_model_6_USE_feature_extractor\")\n",
    "model_6_pretrained.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 25ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions with the loaded model from Google Storage\n",
    "\n",
    "model_6_pred_probs = model_6.predict(val_sentences)\n",
    "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
    "model_6_preds[:10] # these should be in label format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DFR EP016 Monthly Meltdown - On Dnbheaven 2015...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FedEx no longer to transport bioterror germs i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.740871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gunmen kill four in El Salvador bus attack: Su...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.986758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@camilacabello97 Internally and externally scr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Radiation emergency #preparedness starts with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.771119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target  pred  pred_prob\n",
       "0  DFR EP016 Monthly Meltdown - On Dnbheaven 2015...       0   0.0   0.155934\n",
       "1  FedEx no longer to transport bioterror germs i...       0   1.0   0.740871\n",
       "2  Gunmen kill four in El Salvador bus attack: Su...       1   1.0   0.986758\n",
       "3  @camilacabello97 Internally and externally scr...       1   0.0   0.191330\n",
       "4  Radiation emergency #preparedness starts with ...       1   1.0   0.771119"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame with validation sentences,validation labels and best performing model prediction labels + probabilities\n",
    "\n",
    "val_df = pd.DataFrame({\n",
    "    \"text\":val_sentences,\n",
    "    \"target\":val_labels,\n",
    "    \"pred\":model_6_preds,\n",
    "    \"pred_prob\":tf.squeeze(model_6_pred_probs)})\n",
    "\n",
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>? High Skies - Burning Buildings ? http://t.co...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.931079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@madonnamking RSPCA site multiple 7 story high...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.865880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>FedEx will no longer transport bioterror patho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.860719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Ashes 2015: AustraliaÛªs collapse at Trent Br...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.827728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>@SonofLiberty357 all illuminated by the bright...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.823788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>@AshGhebranious civil rights continued in the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.822217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>@noah_anyname That's where the concentration c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.791791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>A look at state actions a year after Ferguson'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.778076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>My phone looks like it was in a car ship airpl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.768571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "31   ? High Skies - Burning Buildings ? http://t.co...       0   1.0   \n",
       "49   @madonnamking RSPCA site multiple 7 story high...       0   1.0   \n",
       "759  FedEx will no longer transport bioterror patho...       0   1.0   \n",
       "209  Ashes 2015: AustraliaÛªs collapse at Trent Br...       0   1.0   \n",
       "393  @SonofLiberty357 all illuminated by the bright...       0   1.0   \n",
       "251  @AshGhebranious civil rights continued in the ...       0   1.0   \n",
       "628  @noah_anyname That's where the concentration c...       0   1.0   \n",
       "109  [55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES W...       0   1.0   \n",
       "695  A look at state actions a year after Ferguson'...       0   1.0   \n",
       "474  My phone looks like it was in a car ship airpl...       0   1.0   \n",
       "\n",
       "     pred_prob  \n",
       "31    0.931079  \n",
       "49    0.865880  \n",
       "759   0.860719  \n",
       "209   0.827728  \n",
       "393   0.823788  \n",
       "251   0.822217  \n",
       "628   0.815620  \n",
       "109   0.791791  \n",
       "695   0.778076  \n",
       "474   0.768571  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the wrong predictions and sort by prediction probabilities\n",
    "\n",
    "most_wrong = val_df[val_df[\"target\"] != val_df[\"pred\"]].sort_values(\"pred_prob\",ascending=False)\n",
    "most_wrong[:10] # these are false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>@SoonerMagic_ I mean I'm a fan but I don't nee...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.040074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Why are you deluged with low self-image? Take ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>I get to smoke my shit in peace</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Reddit Will Now QuarantineÛ_ http://t.co/pkUA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ron &amp;amp; Fez - Dave's High School Crush https...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  target  pred  \\\n",
       "411  @SoonerMagic_ I mean I'm a fan but I don't nee...       1   0.0   \n",
       "38   Why are you deluged with low self-image? Take ...       1   0.0   \n",
       "233                    I get to smoke my shit in peace       1   0.0   \n",
       "244  Reddit Will Now QuarantineÛ_ http://t.co/pkUA...       1   0.0   \n",
       "23   Ron &amp; Fez - Dave's High School Crush https...       1   0.0   \n",
       "\n",
       "     pred_prob  \n",
       "411   0.040074  \n",
       "38    0.034439  \n",
       "233   0.033025  \n",
       "244   0.032141  \n",
       "23    0.023705  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_wrong.tail() # these are false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's remind ourselves of the target labels..\n",
    "\n",
    "# * 0 = not disaster\n",
    "# * 1 = disaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0, Pred: 1.0, Prob: 0.9310788512229919\n",
      "Text:\n",
      "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8658801317214966\n",
      "Text:\n",
      "@madonnamking RSPCA site multiple 7 story high rise buildings next to low density character residential in an area that floods\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8607189059257507\n",
      "Text:\n",
      "FedEx will no longer transport bioterror pathogens in wake of anthrax lab mishaps http://t.co/lHpgxc4b8J\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8277279138565063\n",
      "Text:\n",
      "Ashes 2015: AustraliaÛªs collapse at Trent Bridge among worst in history: England bundled out Australia for 60 ... http://t.co/t5TrhjUAU0\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.823788046836853\n",
      "Text:\n",
      "@SonofLiberty357 all illuminated by the brightly burning buildings all around the town!\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8222169876098633\n",
      "Text:\n",
      "@AshGhebranious civil rights continued in the 60s. And what about trans-generational trauma? if anything we should listen to the Americans.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.8156200051307678\n",
      "Text:\n",
      "@noah_anyname That's where the concentration camps and mass murder come in. \n",
      " \n",
      "EVERY. FUCKING. TIME.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7917907238006592\n",
      "Text:\n",
      "[55436] 1950 LIONEL TRAINS SMOKE LOCOMOTIVES WITH MAGNE-TRACTION INSTRUCTIONS http://t.co/xEZBs3sq0y http://t.co/C2x0QoKGlY\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7780764102935791\n",
      "Text:\n",
      "A look at state actions a year after Ferguson's upheaval http://t.co/GZEkQWzijq\n",
      "\n",
      "----\n",
      "\n",
      "Target: 0, Pred: 1.0, Prob: 0.7685707807540894\n",
      "Text:\n",
      "My phone looks like it was in a car ship airplane accident. Terrible\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false positives (model predicted 1 when should've been 0)\n",
    "\n",
    "for row in most_wrong[:10].itertuples():\n",
    "    _, text, target, pred, pred_prob = row\n",
    "    print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"----\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1, Pred: 0.0, Prob: 0.051897916942834854\n",
      "Text:\n",
      "Next May I'll be free...from school from obligations like family.... Best of all that damn curfew...\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.05083673447370529\n",
      "Text:\n",
      "You can never escape me. Bullets don't harm me. Nothing harms me. But I know pain. I know pain. Sometimes I share it. With someone like you.\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.048782456666231155\n",
      "Text:\n",
      "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.044237662106752396\n",
      "Text:\n",
      "@willienelson We need help! Horses will die!Please RT &amp; sign petition!Take a stand &amp; be a voice for them! #gilbert23 https://t.co/e8dl1lNCVu\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.043758321553468704\n",
      "Text:\n",
      "going to redo my nails and watch behind the scenes of desolation of smaug ayyy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.04007368162274361\n",
      "Text:\n",
      "@SoonerMagic_ I mean I'm a fan but I don't need a girl sounding off like a damn siren\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.03443947434425354\n",
      "Text:\n",
      "Why are you deluged with low self-image? Take the quiz: http://t.co/XsPqdOrIqj http://t.co/CQYvFR4UCy\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.03302513062953949\n",
      "Text:\n",
      "I get to smoke my shit in peace\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.032140955328941345\n",
      "Text:\n",
      "Reddit Will Now QuarantineÛ_ http://t.co/pkUAMXw6pm #onlinecommunities #reddit #amageddon #freespeech #Business http://t.co/PAWvNJ4sAP\n",
      "\n",
      "----\n",
      "\n",
      "Target: 1, Pred: 0.0, Prob: 0.02370537258684635\n",
      "Text:\n",
      "Ron &amp; Fez - Dave's High School Crush https://t.co/aN3W16c8F6 via @YouTube\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check the false negatives (model predicted 0 when should've been 1)\n",
    "\n",
    "for row in most_wrong[-10:].itertuples():\n",
    "    _, text, target, pred, pred_prob = row\n",
    "    print(f\"Target: {target}, Pred: {pred}, Prob: {pred_prob}\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "Pred: 1, Prob: 0.9413477778434753\n",
      "Text: \n",
      "IRIN Asia | Red tape tangles Nepal reconstruction | Nepal | Disaster Risk Reduction | Natural Disasters http://t.co/q7LG6ncf7G\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "Pred: 1, Prob: 0.7520865797996521\n",
      "Text: \n",
      "Green Line trains resume service after South Side derailment: Green Line service has resumed more than four h... http://t.co/dJztc7apf1\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Pred: 1, Prob: 0.9608497023582458\n",
      "Text: \n",
      "Pic of 16yr old PKK suicide bomber who detonated bomb in Turkey Army trench released: Harun Ìàekdar a member o... http://t.co/fMoqK26hIm\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Pred: 1, Prob: 0.8183940052986145\n",
      "Text: \n",
      "Concealed Carrier Rescues Hostage Captures Naked Attacker http://t.co/uLy5hM6PqR\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "Pred: 0, Prob: 0.05819382891058922\n",
      "Text: \n",
      "I've spent the day  traumatised about the fact that there is loads of good music out there and I'm probably not going to hear it all\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Pred: 1, Prob: 0.9267597794532776\n",
      "Text: \n",
      "Stockton Shooting Kills One Officers Investigating: STOCKTON ÛÓ\n",
      "Stockton police are investigating a shooting t... http://t.co/7vnrB5kurU\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Pred: 0, Prob: 0.0429285503923893\n",
      "Text: \n",
      "GUNNAR Optiks -Heroes of the Storm Siege Gaming Glasses - Onyx/Fire wow blizzard - Full reÛ_ http://t.co/YEUQp0VKwU http://t.co/OuGM0yxQMo\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Pred: 0, Prob: 0.3615073263645172\n",
      "Text: \n",
      "Community first responders #CFR The Radio Ham: Tony Hancock http://t.co/MMSoOOOa70\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Pred: 0, Prob: 0.03365030512213707\n",
      "Text: \n",
      "Businesses a e deluged with invoices. Make yours standwout with colour or shape and it's likely to rise to the top of the pay' pile.\n",
      "\n",
      "----\n",
      "\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Pred: 0, Prob: 0.06618866324424744\n",
      "Text: \n",
      "Show no love and fear no ops\n",
      "\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Making predictions on the test dataset and visualizing them\n",
    "\n",
    "test_sentences = test_df[\"text\"].to_list()\n",
    "test_samples = random.sample(test_sentences, 10)\n",
    "\n",
    "for test_samples in test_samples:\n",
    "    pred_prob = tf.squeeze(model_6.predict([test_samples])) #our model expect a list as input\n",
    "    pred = tf.round(pred_prob)\n",
    "    print(f\"Pred: {int(pred)}, Prob: {pred_prob}\")\n",
    "    print(f\"Text: \\n{test_samples}\\n\")\n",
    "    print(\"----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The speed/score tradeoff\n",
    "\n",
    "# Let's make a function to measure the time of prediction\n",
    "\n",
    "import time\n",
    "\n",
    "def pred_timer(model, samples):\n",
    "    \"\"\"\n",
    "    Times how long a model takes to make predictions on samples.\n",
    "    \"\"\"\n",
    "\n",
    "    start_time = time.perf_counter() # get start time\n",
    "    model.predict(samples)           # make predictions\n",
    "    end_time = time.perf_counter()   # get finish time\n",
    "    total_time = end_time-start_time # calculuate how long predictions took to make\n",
    "    time_per_pred = total_time/len(samples)\n",
    "\n",
    "    return total_time, time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0972063000081107, 0.001439903280850539)"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate TF Hub Sentence Encoder time per pred\n",
    "\n",
    "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model_6,val_sentences)\n",
    "\n",
    "model_6_total_pred_time, model_6_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4874945000046864, 0.0006397565616859402)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate our baseline model times per pred\n",
    "\n",
    "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model_0,val_sentences)\n",
    "baseline_total_pred_time, baseline_time_per_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 81.62729658792651,\n",
       " 'precision': 0.818446310697231,\n",
       " 'recall': 0.8162729658792651,\n",
       " 'f1': 0.8148082644367335}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6_results = calculate_results(y_true=val_labels,y_pred=model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"],label=\"baseline\")\n",
    "plt.scatter(model_6_time_per_pred,model_6_results[\"f1\"],label=\"tf_hub_sentence_encoder\")\n",
    "plt.legend()\n",
    "plt.title(\"F1-scoer versus time per prediction\")\n",
    "plt.xlabel(\"Time per prediction\")\n",
    "plt.ylabel(\"F1-score\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e15f063e7e42353c9736ef962fc7c67de892cf5c7bb88439fb47c3c850fa6062"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
